{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is aimed at summarzing the REPET output at different levels of the nomenclature and to plot this out. Parts of it are really slow.\n",
    "\n",
    "\n",
    "This is no adapted to myrtle rust genome MRv01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-26T06:32:12.235657Z",
     "start_time": "2019-08-26T06:32:10.928395Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/benjamin/anaconda3/lib/python3.5/site-packages/Bio/SearchIO/__init__.py:211: BiopythonExperimentalWarning: Bio.SearchIO is an experimental submodule which may undergo significant changes prior to its future official release.\n",
      "  BiopythonExperimentalWarning)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "from Bio import SeqIO\n",
    "import pysam\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "from Bio.Seq import Seq\n",
    "from Bio import SearchIO\n",
    "from pybedtools import BedTool\n",
    "import numpy as np\n",
    "import pybedtools\n",
    "import multiprocessing\n",
    "import re\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from ipywidgets import widgets\n",
    "from IPython.display import display\n",
    "from sklearn.externals.joblib import Parallel, delayed\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-26T06:32:12.286083Z",
     "start_time": "2019-08-26T06:32:12.238988Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ID_filter_gff(_feature, _id):\n",
    "    \"\"\"\n",
    "    This filter parses out the top level id form the 9th gff column form a REPET gff file.\n",
    "    It has a specific search pattern for each feature type in column 2.\n",
    "    _type is defined by the feature '_'.join(feature.split(\"_\")[-2:])\n",
    "    This function expects that the variable genome either ends with primary_v1 and that the 2 second of the _x_x_Sx starts with S.\n",
    "    \"\"\"\n",
    "    _type = '_'.join(_feature.split(\"_\")[-2:])\n",
    "    if _type == 'REPET_TEs':\n",
    "        if genome.endswith('primary_v1'):\n",
    "            TE_pattern = r'ID=[A-Z,a-z,0-9,-]*_[A-Z,a-z,0-9]*_S[0-9]*_([^;| ]*)'\n",
    "        TE_prog = re.compile(TE_pattern)\n",
    "        TE_match = TE_prog.search(_id)\n",
    "\n",
    "        try:\n",
    "            return TE_match.group(1)\n",
    "        except AttributeError:\n",
    "            print(_id)\n",
    "\n",
    "    if _type == 'REPET_SSRs':\n",
    "        if genome.endswith('primary_v1'):\n",
    "            SSR_pattern = 'ID=[A-Z,a-z,0-9,-]*_[A-Z,a-z,0-9]*_S[0-9]*_([A-Z,a-z,0-9,-]*)'\n",
    "\n",
    "        SSR_prog = re.compile(SSR_pattern)\n",
    "        SSR_match = SSR_prog.search(_id)\n",
    "        return SSR_match.group(1)\n",
    "    if _type == 'REPET_tblastx' or _type == 'REPET_blastx':\n",
    "        if genome.endswith('primary_v1'):\n",
    "            blast_prog = re.compile(r'ID=[A-Z,a-z,0-9,-]*_[A-Z,a-z,0-9]*_S[0-9]*_([^;| ]*)')\n",
    "\n",
    "        #blast_prog = re.compile(blast_pattern)\n",
    "        blast_match = blast_prog.search(_id)\n",
    "        return blast_match.group(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-26T06:32:12.446923Z",
     "start_time": "2019-08-26T06:32:12.374865Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def blast_hit_gff(_feature, _row8, _id):\n",
    "    \"\"\"\n",
    "    This filter parses the blast hit for REPET_TEs from the new 'ID' column. If no blast hit available returns Pastec ids.\n",
    "    If the result is blast already the value is simple parse the blast hit.\n",
    "    SSRs also get SSR\n",
    "    !!!Requires the three_letter_dict to be defined previously.!!!\n",
    "    _type is defined by the feature '_'.join(feature.split(\"_\")[-2:])\n",
    "    \"\"\"\n",
    "    _type = '_'.join(_feature.split(\"_\")[-2:])\n",
    "    if _type == 'REPET_TEs':\n",
    "        #split the pastec_cat into the first three letter code\n",
    "        #the spliting of the 'ID' column needs to be done differently depending on the h or p contigs.\n",
    "        #h contigs contain one additional '_' in the contig id\n",
    "\n",
    "        pastec_cat = _id.split('_')[0]\n",
    "        if 'TE_BLR' in _row8:\n",
    "            #hit_list = [x.split(';')[3] for x in _row8]\n",
    "            blast_hit_pattern = r'TE_BLR\\w*: (\\S*)[ |;]'\n",
    "            blast_hit_prog = re.compile(blast_hit_pattern)\n",
    "            TE_match = blast_hit_prog.findall(_row8)\n",
    "            first_sub_class = ':'.join(TE_match[0][:-1].split(':')[1:])\n",
    "            if len([x for x in TE_match if first_sub_class in x]) == len(TE_match):\n",
    "                if ';' in first_sub_class:\n",
    "                    return first_sub_class.split(';')[0]\n",
    "                else:\n",
    "                    return first_sub_class\n",
    "#fix this here to include the there letter code of the first bit of the ID similar to the blast hits\n",
    "#e.g. ClassI:?:? and so on. a dict might be the easiest here.\n",
    "            \n",
    "            else:\n",
    "                return three_letter_dict[pastec_cat]\n",
    "        else:\n",
    "            return three_letter_dict[pastec_cat]\n",
    "    if _type == 'REPET_SSRs':\n",
    "        return 'SSR'\n",
    "        \n",
    "\n",
    "        return SSR_match.group(1)\n",
    "    if _type == 'REPET_tblastx' or _type == 'REPET_blastx':\n",
    "        return ':'.join(_id.split(':')[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-26T06:32:13.216235Z",
     "start_time": "2019-08-26T06:32:13.173928Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def TE_classification_filter(_id, level = 0):\n",
    "    \"\"\"\n",
    "    This function pulls out the class == level1, Order == level2, Superfamily == leve3.\n",
    "    If SSR or noCat return these values.\n",
    "    \n",
    "    \"\"\"\n",
    "    if len(_id.split(':')) == 1:\n",
    "        return _id\n",
    "    if level == 0:\n",
    "        _class = _id.split(':')[0]\n",
    "        if _class == 'ClassI':\n",
    "            return 'Retrotransposon'\n",
    "        if _class == 'ClassII':\n",
    "            return 'DNA_transposon'\n",
    "    elif level == 1:\n",
    "        _order = _id.split(':')[1]\n",
    "        if _order == '?':\n",
    "            return 'noCat'\n",
    "        else:\n",
    "            return _order\n",
    "    elif level == 2:\n",
    "        _superfamily = _id.split(':')[2]\n",
    "        if _superfamily == '?':\n",
    "            return 'noCat'\n",
    "        else:\n",
    "            return _superfamily\n",
    "    else:\n",
    "        print('Something wrong! Check if level is 0, 1 or 2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-26T06:32:13.988308Z",
     "start_time": "2019-08-26T06:32:13.955476Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# subset the id and safe in specific folder\n",
    "# return the subsetted file as bedtool\n",
    "def subset_id(_id, bed_fh, repet_prefix, genome_file_fh):\n",
    "    '''A function that takes the a ID, e.g. from the ID column 9 of a gff,\n",
    "    a bed file handle, e.g. the gff frame, a certain file prefix, and a genome_file handle.\n",
    "    It saves out the coverage file and the gff file for the specific ID.'''\n",
    "    #ClassI are retrotransposon form blast\n",
    "    if 'ClassI:' in _id:\n",
    "        out_path = TE_path_dict['Retrotransposon']   \n",
    "    #ClassII are DNA_transponson\n",
    "    elif 'ClassII' in _id:\n",
    "        out_path = TE_path_dict['DNA_transposon'] \n",
    "    #The rest with '_' should be REPET_TEs\n",
    "    elif _id == 'noCat':\n",
    "        out_path = TE_path_dict['noCat']\n",
    "    #everything without '_' at the end should be SSR\n",
    "    elif _id == 'SSR':\n",
    "        out_path = TE_path_dict['SSR']\n",
    "    cov_fh = os.path.join(out_path,'%s.%s.cov' %(repet_prefix,_id))\n",
    "    gff_fh = cov_fh.replace('.cov', '.gff')\n",
    "    result = pybedtools.BedTool(bed_fh).filter(id_filter, _id).saveas(gff_fh)\n",
    "    result.genome_coverage(dz=True,g=genome_file_fh).saveas(cov_fh)\n",
    "    print('Done with callculating coverage of %s.'% _id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-26T06:32:14.826173Z",
     "start_time": "2019-08-26T06:32:14.819034Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Next, we create a function to pass only features for a particular\n",
    "# featuretype.  This is similar to a \"grep\" operation when applied to every\n",
    "# feature in a BedTool\n",
    "def id_filter(feature, _id):\n",
    "    if feature[8] == _id:\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-26T06:32:15.780366Z",
     "start_time": "2019-08-26T06:32:15.703381Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def samcov_slurp(file_name, mean=False, fil=True):\n",
    "    \"\"\"\n",
    "    Function that slurps in the the file via the file_name and tests if looks a samcov file.\n",
    "    If this is the case it makes a dataframe out of the samcov file and calculates the following values.\n",
    "    Ave_cov per window, which is the average coverage for each genomic interval. \n",
    "    Norm_cov per window, is the normalized coverage for each genomic interavl. This\n",
    "    can be either calculated by via the mean coverage of the dataframe or via a provided mean.\n",
    "    \"\"\"\n",
    "    if file_name.endswith('.samcov') == False:\n",
    "        print(\"%s Might not be a samcov file. Please check\" % file_name)\n",
    "        return False\n",
    "        \n",
    "    samcov_header_bed_3 = ['contig', 'start', 'stop', 'total_cov']\n",
    "    samcov_header_bed_6 = ['contig', 'start', 'stop', 'ID', 'score', 'strand','total_cov']\n",
    "    df = pd.read_csv(file_name, sep='\\t', header=None)\n",
    "    if len(df.columns) == 4:\n",
    "        df.rename(columns=dict(zip(df.columns, samcov_header_bed_3)), inplace=True)\n",
    "    elif len(df.columns) == 7:\n",
    "        df.rename(columns=dict(zip(df.columns, samcov_header_bed_6)), inplace=True)\n",
    "    else:\n",
    "        print(\"%s Might not be a samcov file. Please check\" % file_name)\n",
    "        return False\n",
    "    \n",
    "    df['interval_size'] = (df.stop-df.start)\n",
    "    df['ave_cov'] = df.total_cov/df['interval_size']\n",
    "    if mean == False:\n",
    "        df_mean = sum(df.total_cov)/sum(df.interval_size)\n",
    "        df['norm_cov'] = df['ave_cov']/df_mean\n",
    "    else:\n",
    "        df['norm_cov'] = df['ave_cov']/mean\n",
    "    #rounder = pd.Series([0,0,0,0,2], index = df.columns)\n",
    "    df.ave_cov = df.ave_cov.round()\n",
    "    if fil == True:\n",
    "        low = 0 #these were defined empirical based on the iqr caculations using 0.01 \n",
    "        high = 400 #and 0.99 as cut off.\n",
    "        df = df[(df.ave_cov >= low) & (df.ave_cov <= high)]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-26T06:32:16.523459Z",
     "start_time": "2019-08-26T06:32:16.514846Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_samtools_bedcov(window_bed_fn, bam_fn, output_fh):\n",
    "    \"\"\"Runs samtools bedcov as a subprocess so we can paralize the different runs saving some time.\n",
    "    Input: \n",
    "    The window_bed fn for which the samtools bedcov should be calculated.\n",
    "    The bam_fn file that contains the read mapping.\n",
    "    The output_fn where the output is saved to.\n",
    "    These should be absolute path\"\"\"\n",
    "    cmd = r'samtools bedcov %s %s > %s' % (window_bed_fn, bam_fn,output_fh)\n",
    "    stderr = subprocess.check_output(cmd, shell=True, stderr=subprocess.STDOUT)\n",
    "    print('Done with %s' % cmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Description\n",
    "This notebook runs on myrtle rust genome MR_v01. The repeat database was \n",
    "MR_P2A_300Mb_denovoLibTEs_filtered_Blastclust.fa which was produced by running TEdenovo on a subsampled genome of 300Mb of the unscaffolded genome. The classif_table in the SQL was MR_P2A_300Mb_consensus_classif.\n",
    "\n",
    "All REPET gff files got combined as follows using the the naming convention GENOME.DENOVODATABASE.REPET.gff.  \n",
    "\n",
    "The local folder for this analysis is .\n",
    "\n",
    "\n",
    "APSI_primary_v1.MR_P2A_300Mb.REPET.gff3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change following input here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-26T06:32:20.027781Z",
     "start_time": "2019-08-26T06:32:20.016958Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "source_dir = '../../../genome_v03/genome/'\n",
    "genome = 'APSI_primary_v1'\n",
    "#in case the genome version for the REPET run had a different ID.\n",
    "genome_repet = 'MR_P2_a0'\n",
    "Tenovodb = 'MR_P2A_300Mb'\n",
    "out_dir = '../../TE_analysis/'\n",
    "repet_db_dir = '../../../../databases/REPET/'\n",
    "#This needs to be updated here according to genome\n",
    "TE_postanalysis_dir = '../../../genome_v03/REPET/TEannot/primary'\n",
    "#...\n",
    "input_dir = '../../REPET/TEannot/primary/MR_P2_a0_GFF3chr/'\n",
    "#threads to use for multithreading\n",
    "threads = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-26T06:32:23.463258Z",
     "start_time": "2019-08-26T06:32:23.458542Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##OUTPATH for figures\n",
    "OUTPATH='../../figures/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-26T06:32:24.160596Z",
     "start_time": "2019-08-26T06:32:24.155751Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(out_dir):\n",
    "    os.mkdir(out_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-27T01:29:46.676347Z",
     "start_time": "2019-08-27T01:29:46.661984Z"
    }
   },
   "outputs": [],
   "source": [
    "###here are some input files for the mapping rate coverage analysis using SRM\n",
    "genome_fh = os.path.join(source_dir, '%s.fa' %genome)\n",
    "genome_file_fh = os.path.join(source_dir, '%s.genome_file' %genome)\n",
    "TE_gff_fh = os.path.join(out_dir,'%s.%s.REPET.gff3' % (genome, Tenovodb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-26T06:32:49.403727Z",
     "start_time": "2019-08-26T06:32:49.397411Z"
    },
    "code_folding": [],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#now generate the genmoe files if not present yet\n",
    "if not os.path.exists(genome_file_fh):\n",
    "    !samtools faidx {genome_fh}\n",
    "    !cat {genome_fh}.fai | sort -k1,1n | cut -f 1,2 > {genome_file_fh}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-26T06:32:50.628607Z",
     "start_time": "2019-08-26T06:32:50.165161Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#remove all commenting lines from the initial repet file\n",
    "!grep -v \"^#\" {input_dir}/{genome}.{Tenovodb}.REPET.gff3 > {out_dir}/{genome}.{Tenovodb}.REPET.gff3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-26T06:33:18.919426Z",
     "start_time": "2019-08-26T06:33:18.909185Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../../TE_analysis/APSI_primary_v1.MR_P2A_300Mb.REPET.gff3'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.join(out_dir, '%s.%s.REPET.gff3'%(genome,Tenovodb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-26T06:32:56.781839Z",
     "start_time": "2019-08-26T06:32:54.389071Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#read in repet_gff file\n",
    "repet_gff = pd.read_csv(os.path.join(out_dir, '%s.%s.REPET.gff3'%(genome,Tenovodb)), sep='\\t', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-26T06:32:57.517873Z",
     "start_time": "2019-08-26T06:32:57.512549Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TE_post_analysis_p_header = 'TE      length  covg    frags   fullLgthFrags   copies  fullLgthCopies  meanId  sdId    minId   q25Id   medId   q75Id   maxId   meanLgth        sdLgth  minLgth q25Lgth medLgth q75Lgth maxLgth meanLgthPerc    sdLgthPerc      minLgthPerc  q25LgthPerc     medLgthPerc     q75LgthPerc     maxLgthPerc'.split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-26T06:32:58.295690Z",
     "start_time": "2019-08-26T06:32:58.290782Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TE_post_analysis_p_header = [x for x in TE_post_analysis_p_header if x != '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-26T06:33:44.422350Z",
     "start_time": "2019-08-26T06:33:44.280315Z"
    }
   },
   "outputs": [],
   "source": [
    "!ls {TE_postanalysis_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-26T06:33:48.115278Z",
     "start_time": "2019-08-26T06:33:48.080294Z"
    },
    "code_folding": [],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#this needs to be fixed up to pick the proper summary table\n",
    "#this reads in the REPET summary dataframe\n",
    "REPET_sdf = pd.read_csv(os.path.join(TE_postanalysis_dir,\\\n",
    "                    '%s_chr_allTEs_nr_noSSR_join_path.annotStatsPerTE.tab' % genome_repet),\\\n",
    "                        names = TE_post_analysis_p_header, header=None, sep='\\t', skiprows=1 )\n",
    "#this pulls out the TE classificaiton from the TE column\n",
    "REPET_sdf['Code'] = REPET_sdf['TE'].apply(lambda x: x.split('_')[0])\n",
    "code_keys = REPET_sdf['Code'].unique()\n",
    "code_keys.sort()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-26T06:33:48.828735Z",
     "start_time": "2019-08-26T06:33:48.822547Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#load the previous code_dict from file in the repet database folder\n",
    "with open(os.path.join(repet_db_dir, 'code_dict.dict'), 'r') as file:\n",
    "    code_dict = json.loads(file.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-26T06:33:50.930478Z",
     "start_time": "2019-08-26T06:33:50.919209Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#now check if all code keys to long classifications are already in the dict\n",
    "#if this isn't the case get the missing keys\n",
    "execute_cell = False\n",
    "if set(code_keys).issubset(set(code_dict.keys()))  == False:\n",
    "    execute_cell = True\n",
    "    missing_keys = []\n",
    "    for x in code_keys:\n",
    "        if x not in code_dict.keys():\n",
    "            missing_keys.append(x)\n",
    "            print('Please add the following key value pair to the dictionary and save it out: %s'%x)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-26T06:33:52.053973Z",
     "start_time": "2019-08-26T06:33:52.038368Z"
    }
   },
   "outputs": [],
   "source": [
    "#now get some user input for the missing code: long namenclature pairing via a widget\n",
    "dict_parings = 'Nothing new'\n",
    "if execute_cell == True:\n",
    "    dict_parings = widgets.Text()\n",
    "    print('These are the new required additions to the dictionary\\n\\n')\n",
    "    print(missing_keys)\n",
    "    print('Please enter as key:value, key:value') #define how the widget should be filled\n",
    "    ##TO DO, write a test for this being entered correctly###\n",
    "    print('\\n\\n')\n",
    "    print(code_dict)\n",
    "else:\n",
    "    print(dict_parings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dict_parings = {'DMX-incomp-chim' : 'DNA_transposon Maverick', 'RIX-comp-chim': 'Retrotransposon LINE'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-26T06:33:53.607875Z",
     "start_time": "2019-08-26T06:33:53.588519Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#now add the new key: value pair to the dictionary\n",
    "if dict_parings != 'Nothing new':\n",
    "    code_dict.update(dict_parings)\n",
    "    print(\"Updating the code_dict\")\n",
    "    with open(os.path.join(repet_db_dir, 'code_dict.dict'), 'w') as file:\n",
    "        file.write(json.dumps(code_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-26T06:33:54.479185Z",
     "start_time": "2019-08-26T06:33:54.415664Z"
    }
   },
   "outputs": [],
   "source": [
    "#quick summary for each category based on the REPET summary dataframe\n",
    "REPET_sdf['Code long'] = REPET_sdf['Code'].apply(lambda x: code_dict[x])\n",
    "REPET_sdf_sum_df = pd.pivot_table(REPET_sdf, values=['covg', 'copies'], index='Code long', aggfunc=np.sum)\n",
    "REPET_sdf_mean_df = pd.pivot_table(REPET_sdf, values='length', index='Code long', aggfunc=np.mean)\n",
    "print('quick summary for each category based on the REPET summary dataframe')\n",
    "pd.concat([REPET_sdf_sum_df,REPET_sdf_mean_df], axis=1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-26T06:34:32.764177Z",
     "start_time": "2019-08-26T06:34:29.864432Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#now read in all actuall REPET GFF file\n",
    "REPET_gff_df = pd.read_csv(os.path.join(out_dir,'%s.%s.REPET.gff3' % (genome, Tenovodb))\\\n",
    "                           , sep='\\t', header = None)\n",
    "#filter out host genes\n",
    "REPET_gff_df = REPET_gff_df[~REPET_gff_df[8].str.contains(\"Potential\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "REPET_gff_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-26T06:34:52.758461Z",
     "start_time": "2019-08-26T06:34:36.239301Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "REPET_gff_df['ID'] = REPET_gff_df.apply(lambda row: ID_filter_gff(row[1], row[8]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-26T06:34:56.538264Z",
     "start_time": "2019-08-26T06:34:55.891266Z"
    }
   },
   "outputs": [],
   "source": [
    "code_keys_gff = REPET_gff_df[REPET_gff_df[1].str.contains('REPET_TE')]['ID'].unique()\n",
    "code_keys_gff = list({x.split('_')[0] for x in code_keys_gff})\n",
    "three_letter_code = list({x for x in code_keys_gff})\n",
    "three_letter_code.sort()\n",
    "three_letter_values = []\n",
    "for x in three_letter_code:\n",
    "    if 'MITE' in x:\n",
    "        _value = \"ClassII:MITE:?\"\n",
    "        three_letter_values.append(_value)\n",
    "        continue\n",
    "    if 'LARD' in x:\n",
    "        _value = 'ClassI:LARD:?'\n",
    "        three_letter_values.append(_value)\n",
    "        continue\n",
    "    if 'TRIM' in x:\n",
    "        _value = 'ClassI:TRIM:?'\n",
    "        three_letter_values.append(_value)\n",
    "        continue\n",
    "    _value =''\n",
    "    if x[0] == 'D':\n",
    "        _value = _value + 'ClassII:'\n",
    "    if x[0] == 'R':\n",
    "        _value = _value + 'ClassI:'\n",
    "    if x[0] != 'D' and x[0] != 'R':\n",
    "        _value = 'noCat'\n",
    "        three_letter_values.append(_value)\n",
    "        continue\n",
    "    if x[1] == 'T':\n",
    "        _value = _value + 'TIR:?'\n",
    "    if x[1] == 'H':\n",
    "        _value = _value + 'Helitron:?'\n",
    "    if x[1] == 'M':\n",
    "        _value = _value + 'Maverick:?'\n",
    "    if x[0:2] == 'DY':\n",
    "        _value = _value + ':Crypton:?'\n",
    "    if x[1] == 'X':\n",
    "        _value = _value + '?:?'\n",
    "    if x[1] == 'I':\n",
    "        _value = _value + 'LINE:?'\n",
    "    if x[1] == 'L':\n",
    "        _value = _value + 'LTR:?'\n",
    "    if x[1] == 'P':\n",
    "        _value = _value + 'Penelope:?'\n",
    "    if x[1] == 'S':\n",
    "        _value = _value + 'SINE:?'\n",
    "    if x[0:2] == 'RY':\n",
    "        _value = _value + 'DIRS:?'    \n",
    "    three_letter_values.append(_value)\n",
    "\n",
    "if len(three_letter_code) == len(three_letter_values):\n",
    "    print(\"Aas\")\n",
    "    three_letter_dict = dict(zip(three_letter_code, three_letter_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-26T06:34:57.502788Z",
     "start_time": "2019-08-26T06:34:57.496178Z"
    }
   },
   "outputs": [],
   "source": [
    "#this three letter dict is required for the blast_hit_gff function to work and needs to be generated\n",
    "three_letter_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-26T06:35:21.521790Z",
     "start_time": "2019-08-26T06:35:03.131889Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "REPET_gff_df['Class:Order:Superfamily'] = REPET_gff_df.apply(lambda row: blast_hit_gff(row[1], row[8], row['ID']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-26T06:35:38.678685Z",
     "start_time": "2019-08-26T06:35:37.346956Z"
    }
   },
   "outputs": [],
   "source": [
    "#generate a dict that can be used to rename the Class:Order:Superfamily column \n",
    "#considering that partial matches ([2] == match_part) might contain different\n",
    "#IDs even though they are the same TE only partial.\n",
    "_tmp_subset = REPET_gff_df[~REPET_gff_df[1].str.contains('SSR')].loc[:, 'ID':].sort_values(by=['ID','Class:Order:Superfamily'])\\\n",
    ".drop_duplicates(subset='ID', keep ='last')\n",
    "\n",
    "TE_COS_dict = dict(zip(_tmp_subset.loc[:, 'ID'], _tmp_subset.loc[:, 'Class:Order:Superfamily' ]))\n",
    "\n",
    "_tmp_subset = REPET_gff_df[REPET_gff_df[1].str.contains('SSR')].loc[:, 'ID':].sort_values(by=['ID','Class:Order:Superfamily'])\\\n",
    ".drop_duplicates(subset='ID', keep ='last')\n",
    "\n",
    "_tmp_dict = dict(zip(_tmp_subset.loc[:, 'ID'], _tmp_subset.loc[:, 'Class:Order:Superfamily' ]))\n",
    "\n",
    "TE_COS_dict.update(_tmp_dict)\n",
    "#remove all backslashes from the values as this will conflict with the output later on\n",
    "for x in TE_COS_dict.keys():\n",
    "    if '/' in TE_COS_dict[x]:\n",
    "        value = TE_COS_dict[x]\n",
    "        print(value)\n",
    "        TE_COS_dict[x] = value.replace('/','_')\n",
    "        print(TE_COS_dict[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-26T06:35:43.312191Z",
     "start_time": "2019-08-26T06:35:38.680679Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "REPET_gff_df.to_csv(os.path.join(out_dir,'%s.%s.REPET.long.df' % (genome, Tenovodb)),\n",
    "                    sep='\\t', header = None, index=None )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-26T06:35:43.525616Z",
     "start_time": "2019-08-26T06:35:43.314893Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "REPET_gff_df['Class:Order:Superfamily'] = REPET_gff_df['ID'].apply(lambda x: TE_COS_dict[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-26T06:35:43.567490Z",
     "start_time": "2019-08-26T06:35:43.527663Z"
    }
   },
   "outputs": [],
   "source": [
    "print('These are the unique Class:Order:Superfamily classifiers of this dataframe:')\n",
    "print(REPET_gff_df['Class:Order:Superfamily'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-26T06:36:00.483071Z",
     "start_time": "2019-08-26T06:35:44.917709Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#have a rough summary of the coverage not considering overlaps.\n",
    "REPET_gff_df.drop_duplicates(subset=[3,4,'ID'], inplace =True) \n",
    "#this drops all duplicates in the df that completey overlap and have the same ID. Avoid double counting.\n",
    "REPET_gff_df['Length'] = REPET_gff_df[4] - REPET_gff_df[3]\n",
    "REPET_gff_df['Class'] = REPET_gff_df.apply(lambda row: TE_classification_filter(row['Class:Order:Superfamily'], 0), axis=1)\n",
    "REPET_gff_df['Order'] = REPET_gff_df.apply(lambda row: TE_classification_filter(row['Class:Order:Superfamily'], 1), axis=1)\n",
    "REPET_gff_df['Superfamily'] = REPET_gff_df.apply(lambda row: TE_classification_filter(row['Class:Order:Superfamily'], 2), axis=1)\n",
    "REPET_gff_df_COS = REPET_gff_df.groupby(by=['Class','Order','Superfamily'])['Length'].sum()\n",
    "REPET_gff_df_S = REPET_gff_df.groupby(by=['Class:Order:Superfamily'])['Length'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-26T06:36:04.293456Z",
     "start_time": "2019-08-26T06:36:04.283239Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"This is the summary of overlapping coverage according to Class, Order, Superfamily\")\n",
    "print(REPET_gff_df_COS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-26T06:36:27.160647Z",
     "start_time": "2019-08-26T06:36:27.067261Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"This is the summary of unqiue TE insertions for each Class, Order, Superfamily\")\n",
    "print(REPET_gff_df.groupby(by=['Class','Order','Superfamily'])['Length'].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-26T06:36:29.475932Z",
     "start_time": "2019-08-26T06:36:29.468350Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"This is the summary of overlapping coverage according to Superfamily\")\n",
    "print(REPET_gff_df_S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-26T06:36:30.866717Z",
     "start_time": "2019-08-26T06:36:30.323680Z"
    }
   },
   "outputs": [],
   "source": [
    "num_unique_TEs = len(REPET_gff_df[~REPET_gff_df[1].str.contains('SSR')]['ID'].unique())\n",
    "num_unique_TE_super = len(REPET_gff_df[~REPET_gff_df[1].str.contains('SSR')]['Class:Order:Superfamily'].unique())\n",
    "\n",
    "print('This is the number of unique TEs: %i\\nThis is the number of unique TE superfamilies: %i' % (num_unique_TEs, num_unique_TE_super))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-26T06:36:38.483680Z",
     "start_time": "2019-08-26T06:36:38.444799Z"
    }
   },
   "outputs": [],
   "source": [
    "print('This is the count of unique TEs in each category')\n",
    "print(REPET_gff_df.groupby(by=['Class:Order:Superfamily'])['Length'].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-26T06:36:43.501971Z",
     "start_time": "2019-08-26T06:36:43.213243Z"
    }
   },
   "outputs": [],
   "source": [
    "REPET_gff_wo_SSRs_df = REPET_gff_df[~REPET_gff_df[1].str.contains('SSR')]\n",
    "print('This is the relative number of identified element in each category')\n",
    "REPET_gff_wo_SSRs_df.groupby(by=['Class:Order:Superfamily'])['Length'].count()/REPET_gff_wo_SSRs_df.groupby(by=['Class:Order:Superfamily'])['Length'].count().sum()*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-26T06:37:06.462352Z",
     "start_time": "2019-08-26T06:37:03.263560Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "REPET_gff_df.to_csv(os.path.join(out_dir,'%s.%s.REPET.long_v2.df' % (genome, Tenovodb)),\\\n",
    "                    sep='\\t', header = None, index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-26T06:37:23.518314Z",
     "start_time": "2019-08-26T06:37:22.195143Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#make new gff files where the ID column is the superfamily level\n",
    "REPET_gff_superfamily = REPET_gff_df.iloc[:,:]\n",
    "REPET_gff_superfamily[8] = REPET_gff_df['Class:Order:Superfamily']\n",
    "REPET_gff_superfamily.iloc[:,0:9].to_csv(\\\n",
    "    os.path.join(out_dir,'%s.%s.REPET.superfamily.gff' % (genome, Tenovodb)),\\\n",
    "                                         sep='\\t', header = None, index=None,columns=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-26T06:37:25.990300Z",
     "start_time": "2019-08-26T06:37:24.529205Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#make new gff file where the ID column is the TE level\n",
    "REPET_gff_TE = REPET_gff_df.iloc[:,:]\n",
    "REPET_gff_TE[8] = REPET_gff_TE['ID']\n",
    "REPET_gff_TE.iloc[:,0:9].to_csv(\\\n",
    "    os.path.join(out_dir,'%s.%s.REPET.TE.gff' % (genome, Tenovodb)),\\\n",
    "    sep='\\t', header = None, index=None,columns=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-26T06:37:37.629745Z",
     "start_time": "2019-08-26T06:37:37.615529Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#generate the directory structure to safe specific coverage files\n",
    "TE_types = ['Retrotransposon', 'DNA_transposon', 'noCat', 'SSR']\n",
    "TE_path = [os.path.join(out_dir, x) for x in TE_types]\n",
    "TE_path_dict = dict(zip(TE_types, TE_path))\n",
    "for TE_type in TE_types:\n",
    "    new_path = os.path.join(out_dir, TE_type)\n",
    "    if not os.path.exists(new_path):\n",
    "        os.mkdir(new_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-26T06:37:40.679193Z",
     "start_time": "2019-08-26T06:37:40.673438Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "REPET_sf_gff_fh = os.path.join(out_dir,'%s.%s.REPET.superfamily.gff' % (genome, Tenovodb))\n",
    "REPET_TE_gff_fh = os.path.join(out_dir,'%s.%s.REPET.TE.gff' % (genome, Tenovodb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-26T06:37:52.658548Z",
     "start_time": "2019-08-26T06:37:52.640413Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#define some prefixes used to aggregate coverages\n",
    "#and the genome file for bedtools\n",
    "repet_prefix_TE = '%s.%s.REPET.TE' % (genome, Tenovodb)\n",
    "repet_prefix_S =  '%s.%s.REPET.superfamily' % (genome, Tenovodb)\n",
    "genome_file_fh = os.path.join(source_dir, '%s.genome_file' % genome)\n",
    "genome_df = pd.read_csv(genome_file_fh, sep='\\t', header=None,names=['contig', 'length'])\n",
    "genome_size = genome_df['length'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-26T06:38:00.184395Z",
     "start_time": "2019-08-26T06:38:00.177984Z"
    }
   },
   "outputs": [],
   "source": [
    "genome_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-26T06:38:36.459457Z",
     "start_time": "2019-08-26T06:38:27.441864Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#generate the bedobjects\n",
    "RE_TE_gff = pybedtools.BedTool(REPET_TE_gff_fh)\n",
    "g_TE = RE_TE_gff.remove_invalid().saveas(REPET_TE_gff_fh.replace('gff', 'bedobject'))\n",
    "#use the blast filtered dataframe as well\n",
    "RE_S_gff = pybedtools.BedTool(REPET_sf_gff_fh)\n",
    "g_S = RE_S_gff.remove_invalid().saveas(REPET_sf_gff_fh.replace('gff', 'bedobject'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genome_file_fh.replace('.genome_file', '.REPET.genome_file')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genome_file_REPET_fh = genome_file_fh.replace('.genome_file', '.REPET.genome_file')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(genome_file_fh) as infile:\n",
    "    with open(genome_file_REPET_fh, 'w') as outfile:\n",
    "        for line in infile:\n",
    "            line =line.rstrip()\n",
    "            line = line.replace('APSI_P0', 'ApsiP_S00')\n",
    "            print(line, file=outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-26T06:39:46.853206Z",
     "start_time": "2019-08-26T06:38:39.984915Z"
    }
   },
   "outputs": [],
   "source": [
    "#use simple loop to loop over the bedcov genome coverage per classification. Keep track if everything is already done.\n",
    "jobs = []\n",
    "superfamily_bed_fh = REPET_sf_gff_fh.replace('gff', 'bedobject')\n",
    "superfamilies = REPET_gff_df['Class:Order:Superfamily'].unique()\n",
    "Parallel(n_jobs=threads)(delayed(subset_id)(ID, superfamily_bed_fh, repet_prefix_S, genome_file_REPET_fh)\\\n",
    "                      for ID in superfamilies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_gff_files = []\n",
    "for path in TE_path:\n",
    "    gff_files = [os.path.join(path, x) for x in os.listdir(path) if x.endswith('.gff') and x.startswith(genome)]\n",
    "    for file in gff_files:\n",
    "        class_gff_files.append(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "superfamilies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_cov_dict = {}\n",
    "order_cov_dict = {}\n",
    "superfamily_cov_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [os.path.basename(x) for x in TE_path]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _class in classes[:1]:\n",
    "    _class_df_list = []\n",
    "    tmp_path = [x for x in TE_path if _class is in x]\n",
    "    gff_files = [os.path.join(tmp_path, x) for x in os.listdir(tmp_path) if x.endswith('.gff')]\n",
    "    for gff_file in gff_files:\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TE_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_gff_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_cov_files = []\n",
    "for path in TE_path:\n",
    "    cov_files = [os.path.join(path, x) for x in os.listdir(path) if x.endswith('.cov') and x.startswith(genome)]\n",
    "    for file in cov_files:\n",
    "        class_cov_files.append(file)\n",
    "\n",
    "#make a large summary dataframe from all the cov files where the last \n",
    "df_list =[]\n",
    "class_cov_files.sort()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in class_cov_files:\n",
    "    #print(file)\n",
    "    tmp_df = pd.read_csv(file, sep='\\t', header = None)\n",
    "    tmp_df[\"Class:Order:Superfamily\"] = file.split('.')[-2]\n",
    "    tmp_df.drop_duplicates(inplace=True) #drop all the duplicates meaning same position in the genome and same superfamily\n",
    "    df_list.append(tmp_df)\n",
    "    print(file.split('.')[-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-26T06:43:52.694325Z",
     "start_time": "2019-08-26T06:40:50.902959Z"
    }
   },
   "outputs": [],
   "source": [
    "class_cov_files = []\n",
    "for path in TE_path:\n",
    "    cov_files = [os.path.join(path, x) for x in os.listdir(path) if x.endswith('.cov') and x.startswith(genome)]\n",
    "    for file in cov_files:\n",
    "        class_cov_files.append(file)\n",
    "\n",
    "#make a large summary dataframe from all the cov files where the last \n",
    "df_list =[]\n",
    "class_cov_files.sort()\n",
    "for file in class_cov_files:\n",
    "    #print(file)\n",
    "    tmp_df = pd.read_csv(file, sep='\\t', header = None)\n",
    "    tmp_df[\"Class:Order:Superfamily\"] = file.split('.')[-2]\n",
    "    tmp_df.drop_duplicates(inplace=True) #drop all the duplicates meaning same position in the genome and same superfamily\n",
    "    df_list.append(tmp_df)\n",
    "    print(file.split('.')[-2])\n",
    "\n",
    "df_REPET_classification = pd.concat(df_list)\n",
    "df_REPET_classification.to_csv(out_dir+'/'+ repet_prefix_S +'.cov', sep='\\t', header =None, index=None)\n",
    "\n",
    "cov_per_superfamily = df_REPET_classification.pivot_table(values=1, columns= \"Class:Order:Superfamily\", aggfunc='count')\n",
    "#cov_per_contig_per_superfamily = df_REPET_classification.groupby([0, \"Class:Order:Superfamily\"])[1].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-26T06:44:26.274327Z",
     "start_time": "2019-08-26T06:43:58.812006Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cov_all_TEs = df_REPET_classification.drop_duplicates([0,1]) #this gets ride of the overlap between different TE families and classes\n",
    "cov_all_TEs = len(cov_all_TEs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-26T06:44:31.573576Z",
     "start_time": "2019-08-26T06:44:31.567515Z"
    }
   },
   "outputs": [],
   "source": [
    "cov_all_TEs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('hello')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-26T06:44:53.018627Z",
     "start_time": "2019-08-26T06:44:52.994940Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#make superfamily df and add columns for Class, order and superfamily\n",
    "cov_per_superfamily['cov_all_TEs'] = cov_all_TEs\n",
    "cov_per_superfamily_df = cov_per_superfamily.T\n",
    "cov_per_superfamily_df.rename(columns={1: 'bp'}, inplace=True)\n",
    "cov_per_superfamily_df['%'] = cov_per_superfamily_df['bp']/genome_size*100\n",
    "cov_per_superfamily_df['Class:Order:Superfamily'] = cov_per_superfamily_df.index\n",
    "\n",
    "cov_per_superfamily_df['Class'] = cov_per_superfamily_df.apply(lambda row: TE_classification_filter(row['Class:Order:Superfamily'], 0), axis=1)\n",
    "cov_per_superfamily_df['Order'] = cov_per_superfamily_df.apply(lambda row: TE_classification_filter(row['Class:Order:Superfamily'], 1), axis=1)\n",
    "cov_per_superfamily_df['Superfamily'] = cov_per_superfamily_df.apply(lambda row: TE_classification_filter(row['Class:Order:Superfamily'], 2), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-26T06:51:47.742245Z",
     "start_time": "2019-08-26T06:51:47.733788Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cov_per_superfamily_df.to_csv(out_dir+'/'+repet_prefix_S+'.tab', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-26T06:51:47.723461Z",
     "start_time": "2019-08-26T06:44:59.373915Z"
    }
   },
   "outputs": [],
   "source": [
    "for file in class_cov_files:\n",
    "    tmp_df = pd.read_csv(file, sep='\\t', header = None)\n",
    "    tmp_df[\"Class\"] = file.split('.')[-2].split(':')[0] #parse out the Class from the file name\n",
    "    tmp_df.drop_duplicates(inplace=True) #drop all the duplicates meaning same position in the genome and same Class\n",
    "    df_list.append(tmp_df)\n",
    "    #print(file.split('.')[-2].split(':')[0])\n",
    "\n",
    "df_REPET_classification_class = pd.concat(df_list)\n",
    "df_REPET_classification_class.drop_duplicates(inplace=True)\n",
    "df_REPET_classification_class.to_csv(out_dir+'/'+ repet_prefix_S.replace('superfamily', 'Class') +'.cov', sep='\\t', header =None, index=None)\n",
    "\n",
    "cov_per_class = df_REPET_classification_class.pivot_table(values=1, columns= \"Class\", aggfunc='count')\n",
    "#cov_per_contig_per_class = df_REPET_classification_class.groupby([0, \"Class\"])[1].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-26T06:55:07.308227Z",
     "start_time": "2019-08-26T06:51:47.744875Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#make a large summary dataframe from all the cov files where the last \n",
    "df_list =[]\n",
    "class_cov_files.sort()\n",
    "for file in class_cov_files:\n",
    "    tmp_df = pd.read_csv(file, sep='\\t', header = None)\n",
    "    if ':' in file:\n",
    "        tmp_df[\"Order\"] = ':'.join(file.split('.')[-2].split(':')[0:2]) #parse out the order from the file name\n",
    "        #print(':'.join(file.split('.')[-2].split(':')[0:2]))\n",
    "    else:\n",
    "        tmp_df[\"Order\"] = file.split('.')[-2].split(':')[0]\n",
    "        #print(file.split('.')[-2].split(':')[0])\n",
    "    tmp_df.drop_duplicates(inplace=True) #drop all the duplicates meaning same position in the genome and same Order\n",
    "    df_list.append(tmp_df)\n",
    "\n",
    "df_REPET_orderification_order = pd.concat(df_list)\n",
    "df_REPET_orderification_order.drop_duplicates(inplace=True)\n",
    "df_REPET_orderification_order.to_csv(out_dir+'/'+ repet_prefix_S.replace('superfamily', 'Order') +'.cov', sep='\\t', header =None, index=None)\n",
    "\n",
    "cov_per_order = df_REPET_orderification_order.pivot_table(values=1, columns= \"Order\", aggfunc='count')\n",
    "#cov_per_contig_per_order = df_REPET_orderification_order.groupby([0, \"Order\"])[1].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-26T06:55:07.323350Z",
     "start_time": "2019-08-26T06:55:07.312864Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cov_per_order['cov_all_TEs'] = cov_all_TEs\n",
    "cov_per_order_df = cov_per_order.T\n",
    "cov_per_order_df.rename(columns={1: 'bp'}, inplace=True)\n",
    "\n",
    "cov_per_order_df['%'] = round(cov_per_order_df['bp']/genome_size*100, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-26T06:55:07.332543Z",
     "start_time": "2019-08-26T06:55:07.325360Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cov_per_class['cov_all_TEs'] = cov_all_TEs\n",
    "cov_per_class_df = cov_per_class.T\n",
    "cov_per_class_df.rename(columns={1: 'bp'}, inplace=True)\n",
    "\n",
    "cov_per_class_df['%'] = round(cov_per_class_df['bp']/genome_size*100, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-26T06:55:07.338076Z",
     "start_time": "2019-08-26T06:55:07.334501Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cov_per_class_df.rename(index={'cov_all_TEs': 'Total RE coverage'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-26T06:55:07.345551Z",
     "start_time": "2019-08-26T06:55:07.340391Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cov_per_class_df.sort_values('bp', ascending=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-26T06:55:07.360719Z",
     "start_time": "2019-08-26T06:55:07.348018Z"
    }
   },
   "outputs": [],
   "source": [
    "cov_per_class_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-26T07:07:37.456004Z",
     "start_time": "2019-08-26T07:07:35.880263Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.style.use('seaborn-talk')\n",
    "fig, (ax0, ax1, ax2) = plt.subplots(nrows=3, ncols=1, figsize=(12,15))\n",
    "fig.suptitle(\"Repetitive elements in P. striformis f. sp. tritici %s\" % genome, fontsize=14, fontweight = 'bold')\n",
    "\n",
    "#color cycle from color blind people \n",
    "CB_color_cycle = ['#377eb8', '#ff7f00', '#4daf4a',\n",
    "                  '#f781bf', '#a65628', '#984ea3',\n",
    "'#999999', '#e41a1c', '#dede00']\n",
    "\n",
    "#plot the overall genome coverage by repetitive element category\n",
    "cov_per_class_df.plot(kind='barh', y='%', ax=ax0,  color='r')\n",
    "ax0.set_xlim([-5,60])\n",
    "ax0.legend().set_visible(False)\n",
    "ax0.set_yticklabels(list(cov_per_class_df.index),fontsize=10, fontweight='bold')\n",
    "ax0.set_ylabel(ylabel='RE categories', fontsize=14, fontweight='bold')\n",
    "\n",
    "#plot class I \n",
    "classI_df = cov_per_superfamily_df[cov_per_superfamily_df['Class'] == 'Retrotransposon'].sort_values('%',\\\n",
    "                                                            ascending=True)\n",
    "#pick out the colors to do color matching on the order level\n",
    "tmp_cn = len(classI_df['Order'].unique())\n",
    "tmp_colors = CB_color_cycle[0:tmp_cn]\n",
    "tmp_col_dict = dict(zip(classI_df['Order'].unique(), tmp_colors))\n",
    "classI_df['Color'] = classI_df['Order'].apply(lambda x: tmp_col_dict[x])\n",
    "ax1.barh(np.arange(len(classI_df.index)), classI_df['%'],\n",
    "        color=classI_df['Color'], ecolor='black')\n",
    "ax1.set_yticks(np.arange(len(classI_df.index)))\n",
    "ax1.set_xlim([-2,25])\n",
    "ax1.set_yticklabels(list(classI_df.index),fontsize=10, fontweight='bold')\n",
    "ax1.set_ylabel(ylabel='Class:Order:Superfamily', fontsize=14, fontweight='bold')\n",
    "ax1.set_title('ClassI: Retrotransposons', fontsize=14, fontweight='bold')\n",
    "\n",
    "#add tick lables\n",
    "\n",
    "for p, value in zip(ax1.patches, classI_df['%']):\n",
    "    ax1.annotate('{0:.3f}'.format(value), (18,p.get_y() * 1.005),fontsize=10, fontweight='bold' )\n",
    "\n",
    "#plot class II\n",
    "classII_df = cov_per_superfamily_df[cov_per_superfamily_df['Class'] == 'DNA_transposon'].sort_values('%',\\\n",
    "                                                                                        ascending=True)\n",
    "\n",
    "#pick out the colors to do color matching on the order level\n",
    "tmp_cn = len(classII_df['Order'].unique())\n",
    "tmp_colors = CB_color_cycle[0:tmp_cn]\n",
    "tmp_col_dict = dict(zip(classII_df['Order'].unique(), tmp_colors))\n",
    "classII_df['Color'] = classII_df['Order'].apply(lambda x: tmp_col_dict[x])\n",
    "\n",
    "#plot the class II out\n",
    "\n",
    "ax2.barh(np.arange(len(classII_df.index)), classII_df['%'],\n",
    "        color=classII_df['Color'], ecolor='black')\n",
    "\n",
    "ax2.set_xlim([-2,25])\n",
    "ax2.set_yticks(np.arange(len(classII_df.index)))\n",
    "\n",
    "ax2.set_yticklabels(list(classII_df.index),fontsize=10, fontweight='bold')\n",
    "ax2.set_ylabel(ylabel='Class:Order:Superfamily', fontsize=14, fontweight='bold')\n",
    "ax2.set_title('ClassII: DNA transposons', fontsize=14, fontweight='bold')\n",
    "ax2.set_xlabel('% genome coverage', fontsize=14, fontweight='bold')\n",
    "\n",
    "#add tick lables\n",
    "\n",
    "for p, value in zip(ax2.patches, classII_df['%']):\n",
    "    ax2.annotate('{0:.3f}'.format(value), (18 ,p.get_y() * 1.005),fontsize=10, fontweight='bold' )\n",
    "\n",
    "    \n",
    "##OUTPATH for figures\n",
    "   \n",
    "fig.savefig(os.path.join(out_dir, genome+'.REPET_summary_pc.seaborn-talk.png'), dpi=600, bbox_inches=\"tight\")\n",
    "outfn = os.path.join(OUTPATH, genome+'.REPET_summary_pc.seaborn-talk.tiff')\n",
    "fig.savefig(outfn, dpi=600, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-26T07:09:51.489226Z",
     "start_time": "2019-08-26T07:09:18.032575Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.style.use('seaborn-talk')\n",
    "fig, (ax0, ax1, ax2) = plt.subplots(nrows=3, ncols=1, figsize=(12,15))\n",
    "fig.suptitle(\"Repetitive elements in P. striformis f. sp. tritici %s\" % genome, fontsize=14, fontweight = 'bold')\n",
    "\n",
    "#color cycle from color blind people \n",
    "CB_color_cycle = ['#377eb8', '#ff7f00', '#4daf4a',\n",
    "                  '#f781bf', '#a65628', '#984ea3',\n",
    "'#999999', '#e41a1c', '#dede00']\n",
    "\n",
    "#plot the overall genome coverage by repetitive element category\n",
    "cov_per_class_df.plot(kind='barh', y='bp', ax=ax0,  color='r')\n",
    "ax0.set_xlim([-5,50000000])\n",
    "ax0.legend().set_visible(False)\n",
    "ax0.set_yticklabels(list(cov_per_class_df.index),fontsize=10, fontweight='bold')\n",
    "ax0.set_ylabel(ylabel='RE categories', fontsize=14, fontweight='bold')\n",
    "\n",
    "#plot class I \n",
    "classI_df = cov_per_superfamily_df[cov_per_superfamily_df['Class'] == 'Retrotransposon'].sort_values('%',\\\n",
    "                                                            ascending=True)\n",
    "#pick out the colors to do color matching on the order level\n",
    "tmp_cn = len(classI_df['Order'].unique())\n",
    "tmp_colors = CB_color_cycle[0:tmp_cn]\n",
    "tmp_col_dict = dict(zip(classI_df['Order'].unique(), tmp_colors))\n",
    "classI_df['Color'] = classI_df['Order'].apply(lambda x: tmp_col_dict[x])\n",
    "ax1.barh(np.arange(len(classI_df.index)), classI_df['bp'],\n",
    "        color=classI_df['Color'], ecolor='black')\n",
    "ax1.set_yticks(np.arange(len(classI_df.index)))\n",
    "ax1.set_xlim([-2,14000000])\n",
    "ax1.set_yticklabels(list(classI_df.index),fontsize=10, fontweight='bold')\n",
    "ax1.set_ylabel(ylabel='Class:Order:Superfamily', fontsize=14, fontweight='bold')\n",
    "ax1.set_title('ClassI: Retrotransposons', fontsize=14, fontweight='bold')\n",
    "\n",
    "#add tick lables\n",
    "\n",
    "for p, value in zip(ax1.patches, classI_df['bp']):\n",
    "    ax1.annotate('{0:.2E}'.format(value), (14000000,p.get_y() * 1.005),fontsize=10, fontweight='bold' )\n",
    "\n",
    "#plot class II\n",
    "classII_df = cov_per_superfamily_df[cov_per_superfamily_df['Class'] == 'DNA_transposon'].sort_values('%',\\\n",
    "                                                                                        ascending=True)\n",
    "\n",
    "#pick out the colors to do color matching on the order level\n",
    "tmp_cn = len(classII_df['Order'].unique())\n",
    "tmp_colors = CB_color_cycle[0:tmp_cn]\n",
    "tmp_col_dict = dict(zip(classII_df['Order'].unique(), tmp_colors))\n",
    "classII_df['Color'] = classII_df['Order'].apply(lambda x: tmp_col_dict[x])\n",
    "\n",
    "#plot the class II out\n",
    "\n",
    "ax2.barh(np.arange(len(classII_df.index)), classII_df['bp'],\n",
    "        color=classII_df['Color'], ecolor='black')\n",
    "\n",
    "ax2.set_xlim([-2,14000000])\n",
    "ax2.set_yticks(np.arange(len(classII_df.index)))\n",
    "\n",
    "ax2.set_yticklabels(list(classII_df.index),fontsize=10, fontweight='bold')\n",
    "ax2.set_ylabel(ylabel='Class:Order:Superfamily', fontsize=14, fontweight='bold')\n",
    "ax2.set_title('ClassII: DNA transposons', fontsize=14, fontweight='bold')\n",
    "ax2.set_xlabel('bp genome coverage', fontsize=14, fontweight='bold')\n",
    "\n",
    "#add tick lables\n",
    "\n",
    "for p, value in zip(ax2.patches, classII_df['bp']):\n",
    "    ax2.annotate('{0:.2E}'.format(value), (14000000 ,p.get_y() * 1.005),fontsize=10, fontweight='bold' )\n",
    "    \n",
    "fig.savefig(os.path.join(out_dir, genome+'.REPET_summary_bpcov.seaborn-talk.png'), dpi=600, bbox_inches=\"tight\")\n",
    "\n",
    "outfn = os.path.join(OUTPATH, genome+'.REPET_summary_bpcov.seaborn-talk.tiff')\n",
    "fig.savefig(outfn, dpi=600, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now some analysis of the divergence of the TEs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-26T07:05:27.278615Z",
     "start_time": "2019-08-26T07:05:26.991766Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#now get the summary of allTEs == TEs specificaly identified by TEdenovo from REPET\n",
    "REPET_denovoTEs_df = pd.read_csv(\\\n",
    "        os.path.join(TE_postanalysis_dir, '%s_chr_allTEs_nr_noSSR_join_path.annotStatsPerTE.tab' % genome_repet),\\\n",
    "                                names = TE_post_analysis_p_header, header=None, sep='\\t', skiprows=1 )\n",
    "\n",
    "#now get in the summary of all bankBLRx TEs == TEs identified by repbase20.05_ntSeq_cleaned_TE\n",
    "REPET_nt_repbase_df = pd.read_csv(\\\n",
    "    os.path.join(TE_postanalysis_dir, '%s_chr_bankBLRx_path.annotStatsPerTE.tab' % genome_repet) ,\\\n",
    "    names = TE_post_analysis_p_header, header=None, sep='\\t', skiprows=1 )\n",
    "\n",
    "#now get in the summary of all bankBLRtx TEs == TEs identified by repbase20.05_aaSeq_cleaned_TE\n",
    "REPET_aa_repbase_df = pd.read_csv(\\\n",
    "    os.path.join(TE_postanalysis_dir, '%s_chr_bankBLRtx_path.annotStatsPerTE.tab' % genome_repet) ,\\\n",
    "    names = TE_post_analysis_p_header, header=None, sep='\\t', skiprows=1 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-26T07:05:28.200215Z",
     "start_time": "2019-08-26T07:05:28.178349Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#generate a df that contains all TEs: TEdenovo, blastx, blastn\n",
    "REPET_all_TEs_df = pd.concat([REPET_denovoTEs_df ,REPET_nt_repbase_df,\\\n",
    "                                       REPET_aa_repbase_df], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-26T07:05:29.092590Z",
     "start_time": "2019-08-26T07:05:29.056652Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "REPET_all_TEs_df = REPET_all_TEs_df[REPET_all_TEs_df.copies > 0]\n",
    "REPET_all_TEs_df = REPET_all_TEs_df[~REPET_all_TEs_df.TE.str.startswith(\"Potential\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-26T07:05:30.098882Z",
     "start_time": "2019-08-26T07:05:30.048396Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#update the TE_COS_dict with missing values that come mostly from blastx and blastn searches.\n",
    "missing_TE_keys = list(set(REPET_all_TEs_df.TE.unique())- set(TE_COS_dict.keys()))\n",
    "missing_TE_values  = [x[x.find(':')+1:] for x in missing_TE_keys]\n",
    "TE_COS_dict.update(dict(zip(missing_TE_keys ,missing_TE_values )))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-26T07:05:31.094809Z",
     "start_time": "2019-08-26T07:05:30.910808Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get the Class/order/superfamily column to the dataframe based on the TE_COS_dict\n",
    "REPET_all_TEs_df[\"COS\"] = REPET_all_TEs_df[\"TE\"].apply(lambda x: TE_COS_dict[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-26T07:05:32.080202Z",
     "start_time": "2019-08-26T07:05:32.047468Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#using the formula T=D/t in arXiv:1209.0176 [q-bio] to approximate TE age\n",
    "# where D = (100-meanId)/100 and \n",
    "# t the substitution rate per site per year\n",
    "# generations per year are estimate at 15 10.1111/j.1365-294X.2007.03513.x\n",
    "# estimate of subsitution rate per year = 2 * 10-9 10.1093/oxfordjournals.molbev.a004056 and\n",
    "# 10.1016/j.fbr.2010.03.001\n",
    "REPET_all_TEs_df['TE_age_Mya'] = (((100-REPET_all_TEs_df.meanId)/100)\\\n",
    "                                        /(2*10**-9))/10**6\n",
    "REPET_all_TEs_df['TE_age'] = (((100-REPET_all_TEs_df.meanId)/100)\\\n",
    "                                        /(2*10**-9))\n",
    "REPET_all_TEs_df = REPET_all_TEs_df[REPET_all_TEs_df.copies > 5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-26T07:05:33.220792Z",
     "start_time": "2019-08-26T07:05:33.201220Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "REPET_ClassI_TEs_df = REPET_all_TEs_df[REPET_all_TEs_df.COS.str.startswith('ClassI:')]\n",
    "REPET_ClassII_TEs_df = REPET_all_TEs_df[REPET_all_TEs_df.COS.str.startswith('ClassII:')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-26T07:05:34.889667Z",
     "start_time": "2019-08-26T07:05:34.880081Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "font = {'family' : 'normal',\n",
    "        'weight' : 'bold',\n",
    "        'size'   : 20}\n",
    "label_config_x = {'fontsize'            : 'large',\n",
    "      'verticalalignment'   : 'top',\n",
    "      'horizontalalignment' : 'center'\n",
    "      }\n",
    "label_config_y = {'fontsize'            : 'large',\n",
    "      'verticalalignment'   : 'bottom',\n",
    "      'horizontalalignment' : 'center'\n",
    "      }\n",
    "matplotlib.rc('font', **font)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-26T07:05:36.939338Z",
     "start_time": "2019-08-26T07:05:35.685419Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.set(style=\"ticks\")\n",
    "\n",
    "# Initialize the figure with a logarithmic x axis\n",
    "f, ax = plt.subplots(figsize=(7, 6))\n",
    "ax.set_xscale(\"log\")\n",
    "\n",
    "REPET_ClassI_TEs_df.sort_values(by='COS', inplace=True)\n",
    "sns.boxplot(x='TE_age', y='COS', data=REPET_ClassI_TEs_df,palette=\"vlag\")\n",
    "\n",
    "plt.xlim(5*10**4, 10**9)\n",
    "plt.ylabel(\"Class:Order:Superfamily\",fontsize = 12, weight= 'bold')\n",
    "plt.xlabel(\"Age [years]\",fontsize = 12, weight= 'bold')\n",
    "\n",
    "ax.xaxis.grid(True)\n",
    "sns.despine(trim=True, left=True)\n",
    "out_fn = os.path.join(out_dir, '%s_%s_ClassI_age.png' % (genome, Tenovodb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-26T07:05:48.299483Z",
     "start_time": "2019-08-26T07:05:39.985585Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.set(style=\"ticks\")\n",
    "\n",
    "# Initialize the figure with a logarithmic x axis\n",
    "f, ax = plt.subplots(figsize=(7, 6))\n",
    "ax.set_xscale(\"log\")\n",
    "\n",
    "REPET_ClassI_TEs_df.sort_values(by='COS', inplace=True)\n",
    "sns.boxplot(x='TE_age', y='COS', data=REPET_ClassI_TEs_df,palette=\"vlag\")\n",
    "\n",
    "plt.xlim(5*10**6, 10**9)\n",
    "plt.ylabel(\"Class:Order:Superfamily\",fontsize = 12, weight= 'bold')\n",
    "plt.xlabel(\"Age [years]\",fontsize = 12, weight= 'bold')\n",
    "\n",
    "ax.xaxis.grid(True)\n",
    "sns.despine(trim=True, left=True)\n",
    "out_fn = os.path.join(out_dir, '%s_%s_ClassI_age.png' % (genome, Tenovodb))\n",
    "f.savefig(out_fn, dpi=600,bbox_inches=\"tight\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-26T07:05:56.224097Z",
     "start_time": "2019-08-26T07:05:48.301791Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.set(style=\"ticks\")\n",
    "\n",
    "# Initialize the figure with a logarithmic x axis\n",
    "f, ax = plt.subplots(figsize=(7, 6))\n",
    "ax.set_xscale(\"log\")\n",
    "\n",
    "REPET_ClassII_TEs_df.sort_values(by='COS', inplace=True)\n",
    "sns.boxplot(x='TE_age', y='COS', data=REPET_ClassII_TEs_df,palette=\"vlag\")\n",
    "\n",
    "plt.xlim(5*10**6, 10**9)\n",
    "plt.ylabel(\"Class:Order:Superfamily\",fontsize = 12, weight= 'bold')\n",
    "plt.xlabel(\"Age [years]\",fontsize = 12, weight= 'bold')\n",
    "\n",
    "ax.xaxis.grid(True)\n",
    "sns.despine(trim=True, left=True)\n",
    "out_fn = os.path.join(out_dir, '%s_%s_ClassII_age.png' % (genome, Tenovodb))\n",
    "f.savefig(out_fn, dpi=600,bbox_inches=\"tight\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-26T07:06:05.526292Z",
     "start_time": "2019-08-26T07:06:04.564158Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.set(style=\"ticks\")\n",
    "\n",
    "# Initialize the figure with a logarithmic x axis\n",
    "f, ax = plt.subplots(figsize=(7, 6))\n",
    "ax.set_xscale(\"log\")\n",
    "\n",
    "REPET_ClassII_TEs_df.sort_values(by='COS', inplace=True)\n",
    "sns.boxplot(x='TE_age', y='COS', data=REPET_ClassII_TEs_df,palette=\"vlag\")\n",
    "\n",
    "plt.xlim(5*10**4, 10**9)\n",
    "plt.ylabel(\"Class:Order:Superfamily\",fontsize = 12, weight= 'bold')\n",
    "plt.xlabel(\"Age [years]\",fontsize = 12, weight= 'bold')\n",
    "\n",
    "ax.xaxis.grid(True)\n",
    "sns.despine(trim=True, left=True)\n",
    "out_fn = os.path.join(out_dir, '%s_%s_ClassII_age.png' % (genome, Tenovodb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-26T07:06:08.256125Z",
     "start_time": "2019-08-26T07:06:08.224432Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub_df_young_many = REPET_all_TEs_df[(REPET_all_TEs_df.copies > 50) &( REPET_all_TEs_df.TE_age_Mya < 100)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-26T07:06:08.912733Z",
     "start_time": "2019-08-26T07:06:08.903437Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub_df_young_many_by_COS_sum = sub_df_young_many.groupby('COS').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-26T07:06:09.625337Z",
     "start_time": "2019-08-26T07:06:09.617984Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub_df_young_many_by_COS_sum['Class'] = 'noCat'\n",
    "sub_df_young_many_by_COS_sum[\"Index\"] = sub_df_young_many_by_COS_sum.index\n",
    "sub_df_young_many_by_COS_sum['Order'] = 'noCat'\n",
    "sub_df_young_many_by_COS_sum['Class:Order'] = 'noCat'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-26T07:06:10.870203Z",
     "start_time": "2019-08-26T07:06:10.802438Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#generate Class column or noCat\n",
    "sub_df_young_many_by_COS_sum.loc[\\\n",
    "sub_df_young_many_by_COS_sum[sub_df_young_many_by_COS_sum.index.str.contains(':')].index\\\n",
    "                                 , \"Class\"] =\\\n",
    "sub_df_young_many_by_COS_sum[sub_df_young_many_by_COS_sum.index.str.contains(':')].Index.apply\\\n",
    "(lambda x: x.split(':')[0])\n",
    "\n",
    "#generate Order column or noCat\n",
    "sub_df_young_many_by_COS_sum.loc[\\\n",
    "sub_df_young_many_by_COS_sum[sub_df_young_many_by_COS_sum.index.str.contains(':')].index\\\n",
    "                                 , \"Order\"] =\\\n",
    "sub_df_young_many_by_COS_sum[sub_df_young_many_by_COS_sum.index.str.contains(':')].Index.apply\\\n",
    "(lambda x: x.split(':')[1])\n",
    "\n",
    "\n",
    "#generate Class order column\n",
    "sub_df_young_many_by_COS_sum.loc[\\\n",
    "sub_df_young_many_by_COS_sum[sub_df_young_many_by_COS_sum.index.str.contains(':')].index\\\n",
    "                                 , \"Class:Order\"] =\\\n",
    "sub_df_young_many_by_COS_sum[sub_df_young_many_by_COS_sum.index.str.contains(':')]['Class']\\\n",
    "+ ':' +\\\n",
    "sub_df_young_many_by_COS_sum[sub_df_young_many_by_COS_sum.index.str.contains(':')]['Order']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-26T07:06:12.346169Z",
     "start_time": "2019-08-26T07:06:12.320964Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get color column sorted\n",
    "colors = sns.color_palette('cubehelix', n_colors=\\\n",
    "                           len(sub_df_young_many_by_COS_sum['Class:Order'].unique()))\n",
    "color_dict = dict(zip(sub_df_young_many_by_COS_sum['Class:Order'].unique(), colors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-26T07:06:12.864770Z",
     "start_time": "2019-08-26T07:06:12.856284Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub_df_young_many_by_COS_sum['color'] = sub_df_young_many_by_COS_sum['Class:Order'].apply(\\\n",
    "        lambda x: color_dict[x])\n",
    "color_index_dict = dict(zip(sub_df_young_many_by_COS_sum.Index, sub_df_young_many_by_COS_sum.color))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-26T07:06:31.061043Z",
     "start_time": "2019-08-26T07:06:29.397369Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.set(style=\"ticks\")\n",
    "#sns.set_style(\"whitegrid\")\n",
    "# Initialize the figure with a logarithmic x axis\n",
    "f, ax = plt.subplots(figsize=(7, 6))\n",
    "sns.barplot(sub_df_young_many_by_COS_sum.index, sub_df_young_many_by_COS_sum.covg/10**6,\\\n",
    "           palette=color_index_dict)\n",
    "plt.ylim(0, 2.5)\n",
    "plt.ylabel(\"Coverage [Mb]\",**font)\n",
    "plt.xlabel(\"\",**font)\n",
    "sns.despine(trim=True)\n",
    "\n",
    "#change the colors of the legend\n",
    "key_list = list(color_dict.keys())\n",
    "key_list.sort()\n",
    "plt.legend(key_list, loc=(1, 0.1))\n",
    "leg = ax.get_legend()\n",
    "for (x,y) in zip(key_list, leg.legendHandles):\n",
    "    y.set_color(color_dict[x])\n",
    "    \n",
    "\n",
    "\n",
    "for l in ax.get_xticklabels():\n",
    "    l.set_rotation(90)\n",
    "    l.set_fontsize(16)\n",
    "for l in ax.get_yticklabels():\n",
    "    l.set_fontsize(16)\n",
    "    \n",
    "plt.legend(frameon=False)\n",
    "#['top','bottom','left','right']\n",
    "for axis in ['bottom','left']:\n",
    "    ax.spines[axis].set_linewidth(2)\n",
    "for axis in ['top','right']:\n",
    "    ax.spines[axis].set_linewidth(0)\n",
    "ax.tick_params(width=2)    \n",
    "    \n",
    "out_fn = os.path.join(OUTPATH, 'SF2C_%s_%s_TEs_young_and_plenty.tiff'  % (genome, Tenovodb))\n",
    "f.savefig(out_fn, dpi=600, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For haplotigs run up to here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-26T06:51:47.730247Z",
     "start_time": "2019-08-26T06:51:47.726270Z"
    }
   },
   "source": [
    "### Now on to do the coverage analysis for the TEs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-08-27T01:29:55.297Z"
    }
   },
   "outputs": [],
   "source": [
    "g_window_1k200_bed = BedTool().window_maker(g=genome_file_fh, w=window_size, s=slide_size)\n",
    "\n",
    "#sort the TE gff file for easier handling with bedtools and convert some to bed files\n",
    "TE_gff_sorted_fh = TE_gff_fh.replace('.gff3', '.sorted.gff3')\n",
    "TE_gff_superfamily_fh = os.path.join(out_dir,'%s.%s.REPET.superfamily.gff' % (genome, Tenovodb))\n",
    "TE_gff_superfamily_sorted_fh = TE_gff_superfamily_fh.replace('.gff', '.sorted.bed')\n",
    "TE_gff_TEfamily_fh = os.path.join(out_dir,'%s.%s.REPET.TE.gff' % (genome, Tenovodb))\n",
    "TE_gff_TEfamily_sorted_fh = TE_gff_TEfamily_fh.replace('.gff', '.sorted.bed') \n",
    "\n",
    "gff3sort_pl = '/home/benjamin/genome_assembly/PST79/FALCON/p_assemblies/v9_1/Pst_104E_v12/get_homologues/gff3sort/gff3sort.pl'\n",
    "cmd1 = 'perl %s %s > %s' %(gff3sort_pl, TE_gff_fh , TE_gff_sorted_fh)\n",
    "cmd2 = \"perl %s %s | awk -v OFS='\\t' '{print $1, $4, $5, $9, $8, $7 }' > %s \" % (gff3sort_pl, TE_gff_superfamily_fh,TE_gff_superfamily_sorted_fh )\n",
    "cmd3 = \"perl %s %s | awk -v OFS='\\t' '{print $1, $4, $5, $9, $8, $7 }' > %s \" % (gff3sort_pl, TE_gff_TEfamily_fh ,TE_gff_TEfamily_sorted_fh )\n",
    "\n",
    "\n",
    "subprocess.check_output(cmd1, shell=True, stderr=subprocess.STDOUT)\n",
    "subprocess.check_output(cmd2, shell=True, stderr=subprocess.STDOUT)\n",
    "subprocess.check_output(cmd3, shell=True, stderr=subprocess.STDOUT)\n",
    "\n",
    "#generate the bed objects that are windows that will be used for the coverage analysis\n",
    "TE_bed = BedTool(fn=TE_gff_sorted_fh)\n",
    "g_TE_1k200_bed = g_window_1k200_bed.intersect(TE_bed)\n",
    "g_noTE_1k200_bed = g_window_1k200_bed.subtract(TE_bed)\n",
    "\n",
    "#now read in the bam files as beds\n",
    "pbam_bed = BedTool(fn=pbam_fh)\n",
    "\n",
    "#define outfile names to write out the coverage files\n",
    "TE_cov_dir = os.path.join(out_dir, 'TE_COV')\n",
    "if not os.path.exists(TE_cov_dir):\n",
    "    os.mkdir(TE_cov_dir)\n",
    "#really we want to do samtools bedcov    \n",
    "g_TE_1k200_samcovfh = os.path.join(TE_cov_dir, '%s.%s.g_TE_%ik%i.samcov' % (genome, Tenovodb, window_size/1000, slide_size ))\n",
    "g_noTE_1k200_samcovfh = os.path.join(TE_cov_dir, '%s.%s.g_noTE_%ik%i.samcov' % (genome, Tenovodb, window_size/1000, slide_size ))\n",
    "g_window_1k200_samcovfh = os.path.join(TE_cov_dir, '%s.%s.g_window_%ik%i.samcov' % (genome, Tenovodb, window_size/1000, slide_size ))\n",
    "TE_gff_superfamily_samcovfh = os.path.join(TE_cov_dir, TE_gff_superfamily_sorted_fh.split('/')[-1].replace('.bed','.samcov'))\n",
    "TE_gff_TEfamily_samcovfh = os.path.join(TE_cov_dir,TE_gff_TEfamily_sorted_fh.split('/')[-1].replace('.bed','.samcov'))\n",
    "\n",
    "g_window_1k200_bed.saveas(g_window_1k200_samcovfh.replace('.samcov', '.bed'))\n",
    "g_TE_1k200_bed.saveas(g_TE_1k200_samcovfh.replace('.samcov', '.bed'))\n",
    "g_noTE_1k200_bed.saveas(g_noTE_1k200_samcovfh.replace('.samcov', '.bed'))\n",
    "\n",
    "#make the BUSCOs bed file\n",
    "busco_df = pd.read_csv(protein_busco_fh, comment='#', header=None, sep='\\t')\n",
    "single_buscos = busco_df[busco_df[1] == 'Complete'][2].tolist()\n",
    "gene_bed_fh = os.path.join(source_dir, 'DK_0911_v04LT_p_ctg.gene.bed')\n",
    "gene_bed_df = pd.read_csv(gene_bed_fh, sep='\\t', header=None)\n",
    "single_busco_bed_fh = os.path.join(out_dir, '%s.sBUSCO.bed'%genome)\n",
    "single_busco_samcov_fh = os.path.join(TE_cov_dir, single_busco_bed_fh.split('/')[-1].replace('bed', 'samcov'))\n",
    "gene_bed_df[gene_bed_df[3].isin(single_buscos)].to_csv(single_busco_bed_fh, sep='\\t', header=None, index=None)\n",
    "\n",
    "beds = [g_TE_1k200_samcovfh.replace('.samcov', '.bed'),\\\n",
    "        g_noTE_1k200_samcovfh.replace('.samcov', '.bed'),\\\n",
    "        g_window_1k200_samcovfh.replace('.samcov', '.bed') ,\\\n",
    "       single_busco_bed_fh,\\\n",
    "       TE_gff_superfamily_sorted_fh,\\\n",
    "        TE_gff_TEfamily_sorted_fh]\n",
    "outs = [g_TE_1k200_samcovfh, g_noTE_1k200_samcovfh, g_window_1k200_samcovfh,\\\n",
    "        single_busco_samcov_fh, TE_gff_superfamily_samcovfh,  TE_gff_TEfamily_samcovfh]\n",
    "Parallel(n_jobs=len(beds))(delayed(run_samtools_bedcov)(bed, pbam_fh, out)\\\n",
    "                      for bed, out in zip(beds, outs))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-27T03:24:03.323295Z",
     "start_time": "2019-08-27T03:21:56.198611Z"
    }
   },
   "outputs": [],
   "source": [
    "#now make the BUSCO dataframe\n",
    "sBUSCO_df = samcov_slurp( single_busco_samcov_fh, fil=False)\n",
    "\n",
    "sBUSCO_df['contig_number'] = [int(x[-1]) for x in sBUSCO_df.contig.str.split('_')]\n",
    "\n",
    "sBUSCO_df.plot(x='contig_number', y='norm_cov', kind='scatter')\n",
    "\n",
    "sBUSCO_df['norm_cov'].plot(kind='kde')\n",
    "\n",
    "sBUSCO_mean = sum(sBUSCO_df.total_cov)/sum(sBUSCO_df.interval_size)\n",
    "print('The single BUSCO mean coverage is %0.2f.' % sBUSCO_mean)\n",
    "\n",
    "g_TE_1k200_samcov_df = samcov_slurp(g_TE_1k200_samcovfh, mean=sBUSCO_mean ,fil=False)\n",
    "g_noTE_1k200_samcov_df = samcov_slurp(g_noTE_1k200_samcovfh,mean=sBUSCO_mean, fil=False)\n",
    "g_window_1k200_samcov_df = samcov_slurp(g_window_1k200_samcovfh,mean=sBUSCO_mean,fil=False)\n",
    "TE_gff_superfamily_samcov_df = samcov_slurp(TE_gff_superfamily_samcovfh,mean=sBUSCO_mean,fil=False)\n",
    "TE_gff_TEfamily_samcov_df = samcov_slurp(TE_gff_TEfamily_samcovfh,mean=sBUSCO_mean,fil=False)\n",
    "\n",
    "sBUSCO_df['norm_cov'].plot(kind='kde',color='k')\n",
    "g_TE_1k200_samcov_df['norm_cov'].plot(kind='kde',color='r')\n",
    "g_window_1k200_samcov_df['norm_cov'].plot(kind='kde')\n",
    "\n",
    "sBUSCO_df['norm_cov'].plot(kind='hist',color='k', bins=100)\n",
    "\n",
    "TE_gff_superfamily_samcov_df['log10_ncov'] = np.log10(TE_gff_superfamily_samcov_df['norm_cov'])\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(12,15))\n",
    "order = pd.concat([classI_df.sort_values('bp', ascending=False)['Class:Order:Superfamily'],  \\\n",
    "                   classII_df.sort_values('bp', ascending=False)['Class:Order:Superfamily']])\n",
    "sns.boxplot(x='ID', y='log10_ncov', data=TE_gff_superfamily_samcov_df, ax=ax, order=order)\n",
    "plt.xticks(rotation=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-27T03:24:39.900635Z",
     "start_time": "2019-08-27T03:24:39.303472Z"
    }
   },
   "outputs": [],
   "source": [
    "genome_size = pd.read_csv(genome_file_fh, sep='\\t',header=None)[1].sum()\n",
    "mean_genome = sum(g_window_1k200_samcov_df.total_cov)/sum(g_window_1k200_samcov_df.interval_size)\n",
    "\n",
    "print(genome_size)\n",
    "\n",
    "print(int(genome_size *(mean_genome/sBUSCO_mean)))\n",
    "\n",
    "mean_TEs = sum(g_TE_1k200_samcov_df.total_cov)/sum(g_TE_1k200_samcov_df.interval_size)\n",
    "\n",
    "mean_sfamily_TEs = sum(TE_gff_superfamily_samcov_df.total_cov)/sum(TE_gff_superfamily_samcov_df.interval_size)\n",
    "\n",
    "print(mean_sfamily_TEs)\n",
    "\n",
    "print(mean_TEs)\n",
    "\n",
    "print(sBUSCO_mean)\n",
    "\n",
    "print(mean_genome)\n",
    "\n",
    "print(sum(g_noTE_1k200_samcov_df.total_cov)/sum(g_noTE_1k200_samcov_df.interval_size))\n",
    "\n",
    "print(sum(g_TE_1k200_samcov_df.total_cov)/sum(g_TE_1k200_samcov_df.interval_size))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-27T03:25:21.839579Z",
     "start_time": "2019-08-27T03:25:21.699508Z"
    }
   },
   "outputs": [],
   "source": [
    "TE_gff_superfamily_samcov_df.pivot_table(values='norm_cov', columns='ID', aggfunc=[np.mean, np.count_nonzero])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
