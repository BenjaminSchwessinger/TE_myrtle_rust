{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is aimed at summarzing the REPET output at different levels of the nomenclature and to plot this out. Parts of it are really slow.\n",
    "\n",
    "\n",
    "This is no adapted to myrtle rust genome MRv01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-26T06:32:12.235657Z",
     "start_time": "2019-08-26T06:32:10.928395Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/benjamin/anaconda3/lib/python3.5/site-packages/Bio/SearchIO/__init__.py:211: BiopythonExperimentalWarning: Bio.SearchIO is an experimental submodule which may undergo significant changes prior to its future official release.\n",
      "  BiopythonExperimentalWarning)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "from Bio import SeqIO\n",
    "import pysam\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "from Bio.Seq import Seq\n",
    "from Bio import SearchIO\n",
    "from pybedtools import BedTool\n",
    "import numpy as np\n",
    "import pybedtools\n",
    "import multiprocessing\n",
    "import re\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from ipywidgets import widgets\n",
    "from IPython.display import display\n",
    "from sklearn.externals.joblib import Parallel, delayed\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-26T06:32:12.286083Z",
     "start_time": "2019-08-26T06:32:12.238988Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ID_filter_gff(_feature, _id):\n",
    "    \"\"\"\n",
    "    This filter parses out the top level id form the 9th gff column form a REPET gff file.\n",
    "    It has a specific search pattern for each feature type in column 2.\n",
    "    _type is defined by the feature '_'.join(feature.split(\"_\")[-2:])\n",
    "    This function expects that the variable genome either ends with primary_v1 and that the 2 second of the _x_x_Sx starts with S.\n",
    "    \"\"\"\n",
    "    _type = '_'.join(_feature.split(\"_\")[-2:])\n",
    "    if _type == 'REPET_TEs':\n",
    "        if genome.endswith('primary_v1'):\n",
    "            TE_pattern = r'ID=[A-Z,a-z,0-9,-]*_[A-Z,a-z,0-9]*_S[0-9]*_([^;| ]*)'\n",
    "        TE_prog = re.compile(TE_pattern)\n",
    "        TE_match = TE_prog.search(_id)\n",
    "\n",
    "        try:\n",
    "            return TE_match.group(1)\n",
    "        except AttributeError:\n",
    "            print(_id)\n",
    "\n",
    "    if _type == 'REPET_SSRs':\n",
    "        if genome.endswith('primary_v1'):\n",
    "            SSR_pattern = 'ID=[A-Z,a-z,0-9,-]*_[A-Z,a-z,0-9]*_S[0-9]*_([A-Z,a-z,0-9,-]*)'\n",
    "\n",
    "        SSR_prog = re.compile(SSR_pattern)\n",
    "        SSR_match = SSR_prog.search(_id)\n",
    "        return SSR_match.group(1)\n",
    "    if _type == 'REPET_tblastx' or _type == 'REPET_blastx':\n",
    "        if genome.endswith('primary_v1'):\n",
    "            blast_prog = re.compile(r'ID=[A-Z,a-z,0-9,-]*_[A-Z,a-z,0-9]*_S[0-9]*_([^;| ]*)')\n",
    "\n",
    "        #blast_prog = re.compile(blast_pattern)\n",
    "        blast_match = blast_prog.search(_id)\n",
    "        return blast_match.group(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-26T06:32:12.446923Z",
     "start_time": "2019-08-26T06:32:12.374865Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def blast_hit_gff(_feature, _row8, _id):\n",
    "    \"\"\"\n",
    "    This filter parses the blast hit for REPET_TEs from the new 'ID' column. If no blast hit available returns Pastec ids.\n",
    "    If the result is blast already the value is simple parse the blast hit.\n",
    "    SSRs also get SSR\n",
    "    !!!Requires the three_letter_dict to be defined previously.!!!\n",
    "    _type is defined by the feature '_'.join(feature.split(\"_\")[-2:])\n",
    "    \"\"\"\n",
    "    _type = '_'.join(_feature.split(\"_\")[-2:])\n",
    "    if _type == 'REPET_TEs':\n",
    "        #split the pastec_cat into the first three letter code\n",
    "        #the spliting of the 'ID' column needs to be done differently depending on the h or p contigs.\n",
    "        #h contigs contain one additional '_' in the contig id\n",
    "\n",
    "        pastec_cat = _id.split('_')[0]\n",
    "        if 'TE_BLR' in _row8:\n",
    "            #hit_list = [x.split(';')[3] for x in _row8]\n",
    "            blast_hit_pattern = r'TE_BLR\\w*: (\\S*)[ |;]'\n",
    "            blast_hit_prog = re.compile(blast_hit_pattern)\n",
    "            TE_match = blast_hit_prog.findall(_row8)\n",
    "            first_sub_class = ':'.join(TE_match[0][:-1].split(':')[1:])\n",
    "            if len([x for x in TE_match if first_sub_class in x]) == len(TE_match):\n",
    "                if ';' in first_sub_class:\n",
    "                    return first_sub_class.split(';')[0]\n",
    "                else:\n",
    "                    return first_sub_class\n",
    "#fix this here to include the there letter code of the first bit of the ID similar to the blast hits\n",
    "#e.g. ClassI:?:? and so on. a dict might be the easiest here.\n",
    "            \n",
    "            else:\n",
    "                return three_letter_dict[pastec_cat]\n",
    "        else:\n",
    "            return three_letter_dict[pastec_cat]\n",
    "    if _type == 'REPET_SSRs':\n",
    "        return 'SSR'\n",
    "        \n",
    "\n",
    "        return SSR_match.group(1)\n",
    "    if _type == 'REPET_tblastx' or _type == 'REPET_blastx':\n",
    "        return ':'.join(_id.split(':')[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-26T06:32:13.216235Z",
     "start_time": "2019-08-26T06:32:13.173928Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def TE_classification_filter(_id, level = 0):\n",
    "    \"\"\"\n",
    "    This function pulls out the class == level1, Order == level2, Superfamily == leve3.\n",
    "    If SSR or noCat return these values.\n",
    "    \n",
    "    \"\"\"\n",
    "    if len(_id.split(':')) == 1:\n",
    "        return _id\n",
    "    if level == 0:\n",
    "        _class = _id.split(':')[0]\n",
    "        if _class == 'ClassI':\n",
    "            return 'Retrotransposon'\n",
    "        if _class == 'ClassII':\n",
    "            return 'DNA_transposon'\n",
    "    elif level == 1:\n",
    "        _order = _id.split(':')[1]\n",
    "        if _order == '?':\n",
    "            return 'noCat'\n",
    "        else:\n",
    "            return _order\n",
    "    elif level == 2:\n",
    "        _superfamily = _id.split(':')[2]\n",
    "        if _superfamily == '?':\n",
    "            return 'noCat'\n",
    "        else:\n",
    "            return _superfamily\n",
    "    else:\n",
    "        print('Something wrong! Check if level is 0, 1 or 2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-26T06:32:13.988308Z",
     "start_time": "2019-08-26T06:32:13.955476Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# subset the id and safe in specific folder\n",
    "# return the subsetted file as bedtool\n",
    "def subset_id(_id, bed_fh, repet_prefix, genome_file_fh):\n",
    "    '''A function that takes the a ID, e.g. from the ID column 9 of a gff,\n",
    "    a bed file handle, e.g. the gff frame, a certain file prefix, and a genome_file handle.\n",
    "    It saves out the coverage file and the gff file for the specific ID.'''\n",
    "    #ClassI are retrotransposon form blast\n",
    "    if 'ClassI:' in _id:\n",
    "        out_path = TE_path_dict['Retrotransposon']   \n",
    "    #ClassII are DNA_transponson\n",
    "    elif 'ClassII' in _id:\n",
    "        out_path = TE_path_dict['DNA_transposon'] \n",
    "    #The rest with '_' should be REPET_TEs\n",
    "    elif _id == 'noCat':\n",
    "        out_path = TE_path_dict['noCat']\n",
    "    #everything without '_' at the end should be SSR\n",
    "    elif _id == 'SSR':\n",
    "        out_path = TE_path_dict['SSR']\n",
    "    cov_fh = os.path.join(out_path,'%s.%s.cov' %(repet_prefix,_id))\n",
    "    gff_fh = cov_fh.replace('.cov', '.gff')\n",
    "    result = pybedtools.BedTool(bed_fh).filter(id_filter, _id).saveas(gff_fh)\n",
    "    result.genome_coverage(dz=True,g=genome_file_fh).saveas(cov_fh)\n",
    "    print('Done with callculating coverage of %s.'% _id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-26T06:32:14.826173Z",
     "start_time": "2019-08-26T06:32:14.819034Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Next, we create a function to pass only features for a particular\n",
    "# featuretype.  This is similar to a \"grep\" operation when applied to every\n",
    "# feature in a BedTool\n",
    "def id_filter(feature, _id):\n",
    "    if feature[8] == _id:\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concatfiles(out_fn, filenames):\n",
    "    with open(out_fn, 'w') as outfile:\n",
    "        for fname in filenames:\n",
    "            with open(fname) as infile:\n",
    "                for line in infile:\n",
    "                    outfile.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-26T06:32:15.780366Z",
     "start_time": "2019-08-26T06:32:15.703381Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def samcov_slurp(file_name, mean=False, fil=True):\n",
    "    \"\"\"\n",
    "    Function that slurps in the the file via the file_name and tests if looks a samcov file.\n",
    "    If this is the case it makes a dataframe out of the samcov file and calculates the following values.\n",
    "    Ave_cov per window, which is the average coverage for each genomic interval. \n",
    "    Norm_cov per window, is the normalized coverage for each genomic interavl. This\n",
    "    can be either calculated by via the mean coverage of the dataframe or via a provided mean.\n",
    "    \"\"\"\n",
    "    if file_name.endswith('.samcov') == False:\n",
    "        print(\"%s Might not be a samcov file. Please check\" % file_name)\n",
    "        return False\n",
    "        \n",
    "    samcov_header_bed_3 = ['contig', 'start', 'stop', 'total_cov']\n",
    "    samcov_header_bed_6 = ['contig', 'start', 'stop', 'ID', 'score', 'strand','total_cov']\n",
    "    df = pd.read_csv(file_name, sep='\\t', header=None)\n",
    "    if len(df.columns) == 4:\n",
    "        df.rename(columns=dict(zip(df.columns, samcov_header_bed_3)), inplace=True)\n",
    "    elif len(df.columns) == 7:\n",
    "        df.rename(columns=dict(zip(df.columns, samcov_header_bed_6)), inplace=True)\n",
    "    else:\n",
    "        print(\"%s Might not be a samcov file. Please check\" % file_name)\n",
    "        return False\n",
    "    \n",
    "    df['interval_size'] = (df.stop-df.start)\n",
    "    df['ave_cov'] = df.total_cov/df['interval_size']\n",
    "    if mean == False:\n",
    "        df_mean = sum(df.total_cov)/sum(df.interval_size)\n",
    "        df['norm_cov'] = df['ave_cov']/df_mean\n",
    "    else:\n",
    "        df['norm_cov'] = df['ave_cov']/mean\n",
    "    #rounder = pd.Series([0,0,0,0,2], index = df.columns)\n",
    "    df.ave_cov = df.ave_cov.round()\n",
    "    if fil == True:\n",
    "        low = 0 #these were defined empirical based on the iqr caculations using 0.01 \n",
    "        high = 400 #and 0.99 as cut off.\n",
    "        df = df[(df.ave_cov >= low) & (df.ave_cov <= high)]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-26T06:32:16.523459Z",
     "start_time": "2019-08-26T06:32:16.514846Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_samtools_bedcov(window_bed_fn, bam_fn, output_fh):\n",
    "    \"\"\"Runs samtools bedcov as a subprocess so we can paralize the different runs saving some time.\n",
    "    Input: \n",
    "    The window_bed fn for which the samtools bedcov should be calculated.\n",
    "    The bam_fn file that contains the read mapping.\n",
    "    The output_fn where the output is saved to.\n",
    "    These should be absolute path\"\"\"\n",
    "    cmd = r'samtools bedcov %s %s > %s' % (window_bed_fn, bam_fn,output_fh)\n",
    "    stderr = subprocess.check_output(cmd, shell=True, stderr=subprocess.STDOUT)\n",
    "    print('Done with %s' % cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cmap(n, name='hsv'):\n",
    "    '''Returns a function that maps each index in 0, 1, ..., n-1 to a distinct \n",
    "    RGB color; the keyword argument name must be a standard mpl colormap name.'''\n",
    "    return plt.cm.get_cmap(name, n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Description\n",
    "This notebook runs on myrtle rust genome MR_v01. The repeat database was \n",
    "MR_P2A_300Mb_denovoLibTEs_filtered_Blastclust.fa which was produced by running TEdenovo on a subsampled genome of 300Mb of the unscaffolded genome. The classif_table in the SQL was MR_P2A_300Mb_consensus_classif.\n",
    "\n",
    "All REPET gff files got combined as follows using the the naming convention GENOME.DENOVODATABASE.REPET.gff.  \n",
    "\n",
    "The local folder for this analysis is .\n",
    "\n",
    "\n",
    "APSI_primary_v1.MR_P2A_300Mb.REPET.gff3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change following input here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-26T06:32:20.027781Z",
     "start_time": "2019-08-26T06:32:20.016958Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "source_dir = '../../../genome_v03/genome/'\n",
    "genome = 'APSI_primary_v1'\n",
    "#in case the genome version for the REPET run had a different ID.\n",
    "genome_repet = 'MR_P2_a0'\n",
    "Tenovodb = 'MR_P2A_300Mb'\n",
    "out_dir = '../../TE_analysis/'\n",
    "repet_db_dir = '../../../../databases/REPET/'\n",
    "#This needs to be updated here according to genome\n",
    "TE_postanalysis_dir = '../../../genome_v03/REPET/TEannot/primary'\n",
    "#...\n",
    "input_dir = '../../REPET/TEannot/primary/MR_P2_a0_GFF3chr/'\n",
    "#threads to use for multithreading\n",
    "threads = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-26T06:32:23.463258Z",
     "start_time": "2019-08-26T06:32:23.458542Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##OUTPATH for figures\n",
    "OUTPATH='../../figures/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-26T06:32:24.160596Z",
     "start_time": "2019-08-26T06:32:24.155751Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(out_dir):\n",
    "    os.mkdir(out_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-27T01:29:46.676347Z",
     "start_time": "2019-08-27T01:29:46.661984Z"
    }
   },
   "outputs": [],
   "source": [
    "###here are some input files for the mapping rate coverage analysis using SRM\n",
    "genome_fh = os.path.join(source_dir, '%s.fa' %genome)\n",
    "genome_file_fh = os.path.join(source_dir, '%s.genome_file' %genome)\n",
    "TE_gff_fh = os.path.join(out_dir,'%s.%s.REPET.gff3' % (genome, Tenovodb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-26T06:32:49.403727Z",
     "start_time": "2019-08-26T06:32:49.397411Z"
    },
    "code_folding": [],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#now generate the genmoe files if not present yet\n",
    "if not os.path.exists(genome_file_fh):\n",
    "    !samtools faidx {genome_fh}\n",
    "    !cat {genome_fh}.fai | sort -k1,1n | cut -f 1,2 > {genome_file_fh}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-26T06:32:50.628607Z",
     "start_time": "2019-08-26T06:32:50.165161Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#remove all commenting lines from the initial repet file\n",
    "!grep -v \"^#\" {input_dir}/{genome}.{Tenovodb}.REPET.gff3 > {out_dir}/{genome}.{Tenovodb}.REPET.gff3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-26T06:33:18.919426Z",
     "start_time": "2019-08-26T06:33:18.909185Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../../TE_analysis/APSI_primary_v1.MR_P2A_300Mb.REPET.gff3'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.join(out_dir, '%s.%s.REPET.gff3'%(genome,Tenovodb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-26T06:32:56.781839Z",
     "start_time": "2019-08-26T06:32:54.389071Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#read in repet_gff file\n",
    "repet_gff = pd.read_csv(os.path.join(out_dir, '%s.%s.REPET.gff3'%(genome,Tenovodb)), sep='\\t', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-26T06:32:57.517873Z",
     "start_time": "2019-08-26T06:32:57.512549Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TE_post_analysis_p_header = 'TE      length  covg    frags   fullLgthFrags   copies  fullLgthCopies  meanId  sdId    minId   q25Id   medId   q75Id   maxId   meanLgth        sdLgth  minLgth q25Lgth medLgth q75Lgth maxLgth meanLgthPerc    sdLgthPerc      minLgthPerc  q25LgthPerc     medLgthPerc     q75LgthPerc     maxLgthPerc'.split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-26T06:32:58.295690Z",
     "start_time": "2019-08-26T06:32:58.290782Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TE_post_analysis_p_header = [x for x in TE_post_analysis_p_header if x != '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-26T06:33:44.422350Z",
     "start_time": "2019-08-26T06:33:44.280315Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blastclust.log\n",
      "error.log\n",
      "MR_P2_a0_chr_allTEs_nr_noSSR_join_path.annotStatsPerTE_FullLengthCopy.fa\n",
      "MR_P2_a0_chr_allTEs_nr_noSSR_join_path.annotStatsPerTE_FullLengthCopy.txt\n",
      "MR_P2_a0_chr_allTEs_nr_noSSR_join_path.annotStatsPerTE_FullLengthFrag.fa\n",
      "MR_P2_a0_chr_allTEs_nr_noSSR_join_path.annotStatsPerTE_FullLengthFrag.txt\n",
      "MR_P2_a0_chr_allTEs_nr_noSSR_join_path.annotStatsPerTE_OneCopyAndMore.fa\n",
      "MR_P2_a0_chr_allTEs_nr_noSSR_join_path.annotStatsPerTE_OneCopyAndMore.txt\n",
      "MR_P2_a0_chr_allTEs_nr_noSSR_join_path.annotStatsPerTE.tab\n",
      "MR_P2_a0_chr_allTEs_nr_noSSR_join_path.globalAnnotStatsPerTE.txt\n",
      "MR_P2_a0_chr_allTEs_path.annotStatsPerTE_FullLengthCopy.fa\n",
      "MR_P2_a0_chr_allTEs_path.annotStatsPerTE_FullLengthCopy.txt\n",
      "MR_P2_a0_chr_allTEs_path.annotStatsPerTE_FullLengthFrag.fa\n",
      "MR_P2_a0_chr_allTEs_path.annotStatsPerTE_FullLengthFrag.txt\n",
      "MR_P2_a0_chr_allTEs_path.annotStatsPerTE_OneCopyAndMore.fa\n",
      "MR_P2_a0_chr_allTEs_path.annotStatsPerTE_OneCopyAndMore.txt\n",
      "MR_P2_a0_chr_allTEs_path.annotStatsPerTE.tab\n",
      "MR_P2_a0_chr_allTEs_path.globalAnnotStatsPerTE.txt\n",
      "MR_P2_a0_chr_bankBLRtx_path.annotStatsPerTE_FullLengthCopy.fa\n",
      "MR_P2_a0_chr_bankBLRtx_path.annotStatsPerTE_FullLengthCopy.txt\n",
      "MR_P2_a0_chr_bankBLRtx_path.annotStatsPerTE_FullLengthFrag.fa\n",
      "MR_P2_a0_chr_bankBLRtx_path.annotStatsPerTE_FullLengthFrag.txt\n",
      "MR_P2_a0_chr_bankBLRtx_path.annotStatsPerTE_OneCopyAndMore.fa\n",
      "MR_P2_a0_chr_bankBLRtx_path.annotStatsPerTE_OneCopyAndMore.txt\n",
      "MR_P2_a0_chr_bankBLRtx_path.annotStatsPerTE.tab\n",
      "MR_P2_a0_chr_bankBLRtx_path.globalAnnotStatsPerTE.txt\n",
      "MR_P2_a0_chr_bankBLRx_path.annotStatsPerTE_FullLengthCopy.fa\n",
      "MR_P2_a0_chr_bankBLRx_path.annotStatsPerTE_FullLengthCopy.txt\n",
      "MR_P2_a0_chr_bankBLRx_path.annotStatsPerTE_FullLengthFrag.fa\n",
      "MR_P2_a0_chr_bankBLRx_path.annotStatsPerTE_FullLengthFrag.txt\n",
      "MR_P2_a0_chr_bankBLRx_path.annotStatsPerTE_OneCopyAndMore.fa\n",
      "MR_P2_a0_chr_bankBLRx_path.annotStatsPerTE_OneCopyAndMore.txt\n",
      "MR_P2_a0_chr_bankBLRx_path.annotStatsPerTE.tab\n",
      "MR_P2_a0_chr_bankBLRx_path.globalAnnotStatsPerTE.txt\n",
      "MR_P2_a0_db\n",
      "MR_P2_a0.fa\n",
      "MR_P2_a0.fa.NstretchStats.txt\n",
      "MR_P2_a0_GFF3chr\n",
      "MR_P2_a0_refTEs.fa\n",
      "MR_P2_a0_refTEs.fa_blastclust.classifStatsPerCluster.tab\n",
      "MR_P2_a0_refTEs.fa_blastclust.globalStatsPerCluster.txt\n",
      "MR_P2_a0_refTEs.fa_blastclust.statsPerCluster.tab\n",
      "MR_P2_a0_refTEs.fa_blastclust.tab\n",
      "MR_P2_a0_SSRdetect\n",
      "MR_P2_a0_TEdetect\n",
      "MR_P2_a0_TEdetect_rnd\n",
      "ProfilesBankForREPET_Pfam27.0_GypsyDB.hmm\n",
      "repbase20.05_aaSeq_cleaned_TE.fa\n",
      "repbase20.05_ntSeq_cleaned_TE.fa\n",
      "run_TEann01.sh\n",
      "SILVA_132_XSURef_tax_silva_trunc.fasta\n",
      "stderr.log\n",
      "stdout.log\n",
      "TEanno01.sh\n",
      "Teano0_MR_P2_a0.cfg\n"
     ]
    }
   ],
   "source": [
    "!ls {TE_postanalysis_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-26T06:33:48.115278Z",
     "start_time": "2019-08-26T06:33:48.080294Z"
    },
    "code_folding": [],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#this needs to be fixed up to pick the proper summary table\n",
    "#this reads in the REPET summary dataframe\n",
    "REPET_sdf = pd.read_csv(os.path.join(TE_postanalysis_dir,\\\n",
    "                    '%s_chr_allTEs_nr_noSSR_join_path.annotStatsPerTE.tab' % genome_repet),\\\n",
    "                        names = TE_post_analysis_p_header, header=None, sep='\\t', skiprows=1 )\n",
    "#this pulls out the TE classificaiton from the TE column\n",
    "REPET_sdf['Code'] = REPET_sdf['TE'].apply(lambda x: x.split('_')[0])\n",
    "code_keys = REPET_sdf['Code'].unique()\n",
    "code_keys.sort()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-26T06:33:48.828735Z",
     "start_time": "2019-08-26T06:33:48.822547Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#load the previous code_dict from file in the repet database folder\n",
    "with open(os.path.join(repet_db_dir, 'code_dict.dict'), 'r') as file:\n",
    "    code_dict = json.loads(file.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-26T06:33:50.930478Z",
     "start_time": "2019-08-26T06:33:50.919209Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#now check if all code keys to long classifications are already in the dict\n",
    "#if this isn't the case get the missing keys\n",
    "execute_cell = False\n",
    "if set(code_keys).issubset(set(code_dict.keys()))  == False:\n",
    "    execute_cell = True\n",
    "    missing_keys = []\n",
    "    for x in code_keys:\n",
    "        if x not in code_dict.keys():\n",
    "            missing_keys.append(x)\n",
    "            print('Please add the following key value pair to the dictionary and save it out: %s'%x)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-26T06:33:52.053973Z",
     "start_time": "2019-08-26T06:33:52.038368Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nothing new\n"
     ]
    }
   ],
   "source": [
    "#now get some user input for the missing code: long namenclature pairing via a widget\n",
    "dict_parings = 'Nothing new'\n",
    "if execute_cell == True:\n",
    "    dict_parings = widgets.Text()\n",
    "    print('These are the new required additions to the dictionary\\n\\n')\n",
    "    print(missing_keys)\n",
    "    print('Please enter as key:value, key:value') #define how the widget should be filled\n",
    "    ##TO DO, write a test for this being entered correctly###\n",
    "    print('\\n\\n')\n",
    "    print(code_dict)\n",
    "else:\n",
    "    print(dict_parings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dict_parings = {'DMX-incomp-chim' : 'DNA_transposon Maverick', 'RIX-comp-chim': 'Retrotransposon LINE'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-26T06:33:53.607875Z",
     "start_time": "2019-08-26T06:33:53.588519Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#now add the new key: value pair to the dictionary\n",
    "if dict_parings != 'Nothing new':\n",
    "    code_dict.update(dict_parings)\n",
    "    print(\"Updating the code_dict\")\n",
    "    with open(os.path.join(repet_db_dir, 'code_dict.dict'), 'w') as file:\n",
    "        file.write(json.dumps(code_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-26T06:33:54.479185Z",
     "start_time": "2019-08-26T06:33:54.415664Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quick summary for each category based on the REPET summary dataframe\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>copies</th>\n",
       "      <th>covg</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Code long</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DNA_transposon Helitron</th>\n",
       "      <td>1052</td>\n",
       "      <td>1130454</td>\n",
       "      <td>13225.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DNA_transposon MITE</th>\n",
       "      <td>452</td>\n",
       "      <td>146177</td>\n",
       "      <td>606.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DNA_transposon Maverick</th>\n",
       "      <td>11</td>\n",
       "      <td>459</td>\n",
       "      <td>12548.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DNA_transposon TIR</th>\n",
       "      <td>94989</td>\n",
       "      <td>140876202</td>\n",
       "      <td>9335.903226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DNA_transposon noCat</th>\n",
       "      <td>1018</td>\n",
       "      <td>1003818</td>\n",
       "      <td>8431.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Potential Host Gene</th>\n",
       "      <td>797</td>\n",
       "      <td>392965</td>\n",
       "      <td>4796.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Retrotransposon DIRS</th>\n",
       "      <td>17159</td>\n",
       "      <td>30208064</td>\n",
       "      <td>10018.401099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Retrotransposon LARD</th>\n",
       "      <td>29257</td>\n",
       "      <td>19080893</td>\n",
       "      <td>5835.588571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Retrotransposon LINE</th>\n",
       "      <td>2085</td>\n",
       "      <td>1933968</td>\n",
       "      <td>3673.809524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Retrotransposon LTR</th>\n",
       "      <td>446138</td>\n",
       "      <td>717320292</td>\n",
       "      <td>10133.750767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Retrotransposon SINE</th>\n",
       "      <td>250</td>\n",
       "      <td>86468</td>\n",
       "      <td>298.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Retrotransposon TRIM</th>\n",
       "      <td>14939</td>\n",
       "      <td>11510107</td>\n",
       "      <td>2359.628866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Retrotransposon noCat</th>\n",
       "      <td>3560</td>\n",
       "      <td>9483226</td>\n",
       "      <td>11128.153846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>noCat</th>\n",
       "      <td>4229</td>\n",
       "      <td>3603721</td>\n",
       "      <td>5611.410256</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         copies       covg        length\n",
       "Code long                                               \n",
       "DNA_transposon Helitron    1052    1130454  13225.500000\n",
       "DNA_transposon MITE         452     146177    606.900000\n",
       "DNA_transposon Maverick      11        459  12548.000000\n",
       "DNA_transposon TIR        94989  140876202   9335.903226\n",
       "DNA_transposon noCat       1018    1003818   8431.000000\n",
       "Potential Host Gene         797     392965   4796.500000\n",
       "Retrotransposon DIRS      17159   30208064  10018.401099\n",
       "Retrotransposon LARD      29257   19080893   5835.588571\n",
       "Retrotransposon LINE       2085    1933968   3673.809524\n",
       "Retrotransposon LTR      446138  717320292  10133.750767\n",
       "Retrotransposon SINE        250      86468    298.083333\n",
       "Retrotransposon TRIM      14939   11510107   2359.628866\n",
       "Retrotransposon noCat      3560    9483226  11128.153846\n",
       "noCat                      4229    3603721   5611.410256"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#quick summary for each category based on the REPET summary dataframe\n",
    "REPET_sdf['Code long'] = REPET_sdf['Code'].apply(lambda x: code_dict[x])\n",
    "REPET_sdf_sum_df = pd.pivot_table(REPET_sdf, values=['covg', 'copies'], index='Code long', aggfunc=np.sum)\n",
    "REPET_sdf_mean_df = pd.pivot_table(REPET_sdf, values='length', index='Code long', aggfunc=np.mean)\n",
    "print('quick summary for each category based on the REPET summary dataframe')\n",
    "pd.concat([REPET_sdf_sum_df,REPET_sdf_mean_df], axis=1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-26T06:34:32.764177Z",
     "start_time": "2019-08-26T06:34:29.864432Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#now read in all actuall REPET GFF file\n",
    "REPET_gff_df = pd.read_csv(os.path.join(out_dir,'%s.%s.REPET.gff3' % (genome, Tenovodb))\\\n",
    "                           , sep='\\t', header = None)\n",
    "#filter out host genes\n",
    "REPET_gff_df = REPET_gff_df[~REPET_gff_df[8].str.contains(\"Potential\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ApsiP_S0001</td>\n",
       "      <td>MR_P2_a0_REPET_TEs</td>\n",
       "      <td>match</td>\n",
       "      <td>97828741</td>\n",
       "      <td>97830112</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-</td>\n",
       "      <td>.</td>\n",
       "      <td>ID=ms524288_ApsiP_S0001_RLX-incomp-chim_Blc450...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ApsiP_S0001</td>\n",
       "      <td>MR_P2_a0_REPET_TEs</td>\n",
       "      <td>match_part</td>\n",
       "      <td>97828741</td>\n",
       "      <td>97830112</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-</td>\n",
       "      <td>.</td>\n",
       "      <td>ID=mp524288-1_ApsiP_S0001_RLX-incomp-chim_Blc4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ApsiP_S0001</td>\n",
       "      <td>MR_P2_a0_REPET_TEs</td>\n",
       "      <td>match</td>\n",
       "      <td>97895266</td>\n",
       "      <td>97896251</td>\n",
       "      <td>0.0</td>\n",
       "      <td>+</td>\n",
       "      <td>.</td>\n",
       "      <td>ID=ms524289_ApsiP_S0001_RLX-comp-chim_Blc462_M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ApsiP_S0001</td>\n",
       "      <td>MR_P2_a0_REPET_TEs</td>\n",
       "      <td>match_part</td>\n",
       "      <td>97895266</td>\n",
       "      <td>97896251</td>\n",
       "      <td>0.0</td>\n",
       "      <td>+</td>\n",
       "      <td>.</td>\n",
       "      <td>ID=mp524289-1_ApsiP_S0001_RLX-comp-chim_Blc462...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ApsiP_S0001</td>\n",
       "      <td>MR_P2_a0_REPET_TEs</td>\n",
       "      <td>match</td>\n",
       "      <td>97910753</td>\n",
       "      <td>97910863</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-</td>\n",
       "      <td>.</td>\n",
       "      <td>ID=ms524290_ApsiP_S0001_RLX-comp-chim_Blc479_M...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             0                   1           2         3         4    5  6  7  \\\n",
       "0  ApsiP_S0001  MR_P2_a0_REPET_TEs       match  97828741  97830112  0.0  -  .   \n",
       "1  ApsiP_S0001  MR_P2_a0_REPET_TEs  match_part  97828741  97830112  0.0  -  .   \n",
       "2  ApsiP_S0001  MR_P2_a0_REPET_TEs       match  97895266  97896251  0.0  +  .   \n",
       "3  ApsiP_S0001  MR_P2_a0_REPET_TEs  match_part  97895266  97896251  0.0  +  .   \n",
       "4  ApsiP_S0001  MR_P2_a0_REPET_TEs       match  97910753  97910863  0.0  -  .   \n",
       "\n",
       "                                                   8  \n",
       "0  ID=ms524288_ApsiP_S0001_RLX-incomp-chim_Blc450...  \n",
       "1  ID=mp524288-1_ApsiP_S0001_RLX-incomp-chim_Blc4...  \n",
       "2  ID=ms524289_ApsiP_S0001_RLX-comp-chim_Blc462_M...  \n",
       "3  ID=mp524289-1_ApsiP_S0001_RLX-comp-chim_Blc462...  \n",
       "4  ID=ms524290_ApsiP_S0001_RLX-comp-chim_Blc479_M...  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "REPET_gff_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-26T06:34:52.758461Z",
     "start_time": "2019-08-26T06:34:36.239301Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "REPET_gff_df['ID'] = REPET_gff_df.apply(lambda row: ID_filter_gff(row[1], row[8]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-26T06:34:56.538264Z",
     "start_time": "2019-08-26T06:34:55.891266Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aas\n"
     ]
    }
   ],
   "source": [
    "code_keys_gff = REPET_gff_df[REPET_gff_df[1].str.contains('REPET_TE')]['ID'].unique()\n",
    "code_keys_gff = list({x.split('_')[0] for x in code_keys_gff})\n",
    "three_letter_code = list({x for x in code_keys_gff})\n",
    "three_letter_code.sort()\n",
    "three_letter_values = []\n",
    "for x in three_letter_code:\n",
    "    if 'MITE' in x:\n",
    "        _value = \"ClassII:MITE:?\"\n",
    "        three_letter_values.append(_value)\n",
    "        continue\n",
    "    if 'LARD' in x:\n",
    "        _value = 'ClassI:LARD:?'\n",
    "        three_letter_values.append(_value)\n",
    "        continue\n",
    "    if 'TRIM' in x:\n",
    "        _value = 'ClassI:TRIM:?'\n",
    "        three_letter_values.append(_value)\n",
    "        continue\n",
    "    _value =''\n",
    "    if x[0] == 'D':\n",
    "        _value = _value + 'ClassII:'\n",
    "    if x[0] == 'R':\n",
    "        _value = _value + 'ClassI:'\n",
    "    if x[0] != 'D' and x[0] != 'R':\n",
    "        _value = 'noCat'\n",
    "        three_letter_values.append(_value)\n",
    "        continue\n",
    "    if x[1] == 'T':\n",
    "        _value = _value + 'TIR:?'\n",
    "    if x[1] == 'H':\n",
    "        _value = _value + 'Helitron:?'\n",
    "    if x[1] == 'M':\n",
    "        _value = _value + 'Maverick:?'\n",
    "    if x[0:2] == 'DY':\n",
    "        _value = _value + ':Crypton:?'\n",
    "    if x[1] == 'X':\n",
    "        _value = _value + '?:?'\n",
    "    if x[1] == 'I':\n",
    "        _value = _value + 'LINE:?'\n",
    "    if x[1] == 'L':\n",
    "        _value = _value + 'LTR:?'\n",
    "    if x[1] == 'P':\n",
    "        _value = _value + 'Penelope:?'\n",
    "    if x[1] == 'S':\n",
    "        _value = _value + 'SINE:?'\n",
    "    if x[0:2] == 'RY':\n",
    "        _value = _value + 'DIRS:?'    \n",
    "    three_letter_values.append(_value)\n",
    "\n",
    "if len(three_letter_code) == len(three_letter_values):\n",
    "    print(\"Aas\")\n",
    "    three_letter_dict = dict(zip(three_letter_code, three_letter_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-26T06:34:57.502788Z",
     "start_time": "2019-08-26T06:34:57.496178Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'DHX-incomp': 'ClassII:Helitron:?',\n",
       " 'DHX-incomp-chim': 'ClassII:Helitron:?',\n",
       " 'DMX-incomp-chim': 'ClassII:Maverick:?',\n",
       " 'DTX-comp': 'ClassII:TIR:?',\n",
       " 'DTX-comp-chim': 'ClassII:TIR:?',\n",
       " 'DTX-incomp': 'ClassII:TIR:?',\n",
       " 'DTX-incomp-chim': 'ClassII:TIR:?',\n",
       " 'DXX': 'ClassII:?:?',\n",
       " 'DXX-MITE': 'ClassII:MITE:?',\n",
       " 'DXX-MITE-chim': 'ClassII:MITE:?',\n",
       " 'RIX-comp-chim': 'ClassI:LINE:?',\n",
       " 'RIX-incomp': 'ClassI:LINE:?',\n",
       " 'RIX-incomp-chim': 'ClassI:LINE:?',\n",
       " 'RLX-comp': 'ClassI:LTR:?',\n",
       " 'RLX-comp-chim': 'ClassI:LTR:?',\n",
       " 'RLX-incomp': 'ClassI:LTR:?',\n",
       " 'RLX-incomp-chim': 'ClassI:LTR:?',\n",
       " 'RSX-incomp': 'ClassI:SINE:?',\n",
       " 'RXX': 'ClassI:?:?',\n",
       " 'RXX-LARD': 'ClassI:LARD:?',\n",
       " 'RXX-LARD-chim': 'ClassI:LARD:?',\n",
       " 'RXX-TRIM': 'ClassI:TRIM:?',\n",
       " 'RXX-TRIM-chim': 'ClassI:TRIM:?',\n",
       " 'RXX-chim': 'ClassI:?:?',\n",
       " 'RYX-incomp-chim': 'ClassI:DIRS:?',\n",
       " 'XXX-chim': 'noCat',\n",
       " 'noCat': 'noCat'}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#this three letter dict is required for the blast_hit_gff function to work and needs to be generated\n",
    "three_letter_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-26T06:35:21.521790Z",
     "start_time": "2019-08-26T06:35:03.131889Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "REPET_gff_df['Class:Order:Superfamily'] = REPET_gff_df.apply(lambda row: blast_hit_gff(row[1], row[8], row['ID']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-26T06:35:38.678685Z",
     "start_time": "2019-08-26T06:35:37.346956Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ClassII:?:Ginger2/TDD\n",
      "ClassII:?:Ginger2_TDD\n",
      "ClassII:?:Ginger2/TDD\n",
      "ClassII:?:Ginger2_TDD\n",
      "ClassII:?:Ginger2/TDD\n",
      "ClassII:?:Ginger2_TDD\n",
      "ClassII:?:Ginger2/TDD\n",
      "ClassII:?:Ginger2_TDD\n"
     ]
    }
   ],
   "source": [
    "#generate a dict that can be used to rename the Class:Order:Superfamily column \n",
    "#considering that partial matches ([2] == match_part) might contain different\n",
    "#IDs even though they are the same TE only partial.\n",
    "_tmp_subset = REPET_gff_df[~REPET_gff_df[1].str.contains('SSR')].loc[:, 'ID':].sort_values(by=['ID','Class:Order:Superfamily'])\\\n",
    ".drop_duplicates(subset='ID', keep ='last')\n",
    "\n",
    "TE_COS_dict = dict(zip(_tmp_subset.loc[:, 'ID'], _tmp_subset.loc[:, 'Class:Order:Superfamily' ]))\n",
    "\n",
    "_tmp_subset = REPET_gff_df[REPET_gff_df[1].str.contains('SSR')].loc[:, 'ID':].sort_values(by=['ID','Class:Order:Superfamily'])\\\n",
    ".drop_duplicates(subset='ID', keep ='last')\n",
    "\n",
    "_tmp_dict = dict(zip(_tmp_subset.loc[:, 'ID'], _tmp_subset.loc[:, 'Class:Order:Superfamily' ]))\n",
    "\n",
    "TE_COS_dict.update(_tmp_dict)\n",
    "#remove all backslashes from the values as this will conflict with the output later on\n",
    "for x in TE_COS_dict.keys():\n",
    "    if '/' in TE_COS_dict[x]:\n",
    "        value = TE_COS_dict[x]\n",
    "        print(value)\n",
    "        TE_COS_dict[x] = value.replace('/','_')\n",
    "        print(TE_COS_dict[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-26T06:35:43.312191Z",
     "start_time": "2019-08-26T06:35:38.680679Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "REPET_gff_df.to_csv(os.path.join(out_dir,'%s.%s.REPET.long.df' % (genome, Tenovodb)),\n",
    "                    sep='\\t', header = None, index=None )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-26T06:35:43.525616Z",
     "start_time": "2019-08-26T06:35:43.314893Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "REPET_gff_df['Class:Order:Superfamily'] = REPET_gff_df['ID'].apply(lambda x: TE_COS_dict[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-26T06:35:43.567490Z",
     "start_time": "2019-08-26T06:35:43.527663Z"
    }
   },
   "outputs": [],
   "source": [
    "print('These are the unique Class:Order:Superfamily classifiers of this dataframe:')\n",
    "print(REPET_gff_df['Class:Order:Superfamily'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-26T06:36:00.483071Z",
     "start_time": "2019-08-26T06:35:44.917709Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#have a rough summary of the coverage not considering overlaps.\n",
    "REPET_gff_df.drop_duplicates(subset=[3,4,'ID'], inplace =True) \n",
    "#this drops all duplicates in the df that completey overlap and have the same ID. Avoid double counting.\n",
    "REPET_gff_df['Length'] = REPET_gff_df[4] - REPET_gff_df[3]\n",
    "REPET_gff_df['Class'] = REPET_gff_df.apply(lambda row: TE_classification_filter(row['Class:Order:Superfamily'], 0), axis=1)\n",
    "REPET_gff_df['Order'] = REPET_gff_df.apply(lambda row: TE_classification_filter(row['Class:Order:Superfamily'], 1), axis=1)\n",
    "REPET_gff_df['Superfamily'] = REPET_gff_df.apply(lambda row: TE_classification_filter(row['Class:Order:Superfamily'], 2), axis=1)\n",
    "REPET_gff_df_COS = REPET_gff_df.groupby(by=['Class','Order','Superfamily'])['Length'].sum()\n",
    "REPET_gff_df_S = REPET_gff_df.groupby(by=['Class:Order:Superfamily'])['Length'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-26T06:36:04.293456Z",
     "start_time": "2019-08-26T06:36:04.283239Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"This is the summary of overlapping coverage according to Class, Order, Superfamily\")\n",
    "print(REPET_gff_df_COS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-26T06:36:27.160647Z",
     "start_time": "2019-08-26T06:36:27.067261Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"This is the summary of unqiue TE insertions for each Class, Order, Superfamily\")\n",
    "print(REPET_gff_df.groupby(by=['Class','Order','Superfamily'])['Length'].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-26T06:36:29.475932Z",
     "start_time": "2019-08-26T06:36:29.468350Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"This is the summary of overlapping coverage according to Superfamily\")\n",
    "print(REPET_gff_df_S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-26T06:36:30.866717Z",
     "start_time": "2019-08-26T06:36:30.323680Z"
    }
   },
   "outputs": [],
   "source": [
    "num_unique_TEs = len(REPET_gff_df[~REPET_gff_df[1].str.contains('SSR')]['ID'].unique())\n",
    "num_unique_TE_super = len(REPET_gff_df[~REPET_gff_df[1].str.contains('SSR')]['Class:Order:Superfamily'].unique())\n",
    "\n",
    "print('This is the number of unique TEs: %i\\nThis is the number of unique TE superfamilies: %i' % (num_unique_TEs, num_unique_TE_super))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-26T06:36:38.483680Z",
     "start_time": "2019-08-26T06:36:38.444799Z"
    }
   },
   "outputs": [],
   "source": [
    "print('This is the count of unique TEs in each category')\n",
    "print(REPET_gff_df.groupby(by=['Class:Order:Superfamily'])['Length'].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-26T06:36:43.501971Z",
     "start_time": "2019-08-26T06:36:43.213243Z"
    }
   },
   "outputs": [],
   "source": [
    "REPET_gff_wo_SSRs_df = REPET_gff_df[~REPET_gff_df[1].str.contains('SSR')]\n",
    "print('This is the relative number of identified element in each category')\n",
    "REPET_gff_wo_SSRs_df.groupby(by=['Class:Order:Superfamily'])['Length'].count()/REPET_gff_wo_SSRs_df.groupby(by=['Class:Order:Superfamily'])['Length'].count().sum()*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-26T06:37:06.462352Z",
     "start_time": "2019-08-26T06:37:03.263560Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "REPET_gff_df.to_csv(os.path.join(out_dir,'%s.%s.REPET.long_v2.df' % (genome, Tenovodb)),\\\n",
    "                    sep='\\t', header = None, index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-26T06:37:23.518314Z",
     "start_time": "2019-08-26T06:37:22.195143Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#make new gff files where the ID column is the superfamily level\n",
    "REPET_gff_superfamily = REPET_gff_df.iloc[:,:]\n",
    "REPET_gff_superfamily[8] = REPET_gff_df['Class:Order:Superfamily']\n",
    "REPET_gff_superfamily.iloc[:,0:9].to_csv(\\\n",
    "    os.path.join(out_dir,'%s.%s.REPET.superfamily.gff' % (genome, Tenovodb)),\\\n",
    "                                         sep='\\t', header = None, index=None,columns=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-26T06:37:25.990300Z",
     "start_time": "2019-08-26T06:37:24.529205Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#make new gff file where the ID column is the TE level\n",
    "REPET_gff_TE = REPET_gff_df.iloc[:,:]\n",
    "REPET_gff_TE[8] = REPET_gff_TE['ID']\n",
    "REPET_gff_TE.iloc[:,0:9].to_csv(\\\n",
    "    os.path.join(out_dir,'%s.%s.REPET.TE.gff' % (genome, Tenovodb)),\\\n",
    "    sep='\\t', header = None, index=None,columns=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-26T06:37:37.629745Z",
     "start_time": "2019-08-26T06:37:37.615529Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#generate the directory structure to safe specific coverage files\n",
    "TE_types = ['Retrotransposon', 'DNA_transposon', 'noCat', 'SSR']\n",
    "TE_path = [os.path.join(out_dir, x) for x in TE_types]\n",
    "TE_path_dict = dict(zip(TE_types, TE_path))\n",
    "for TE_type in TE_types:\n",
    "    new_path = os.path.join(out_dir, TE_type)\n",
    "    if not os.path.exists(new_path):\n",
    "        os.mkdir(new_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-26T06:37:40.679193Z",
     "start_time": "2019-08-26T06:37:40.673438Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "REPET_sf_gff_fh = os.path.join(out_dir,'%s.%s.REPET.superfamily.gff' % (genome, Tenovodb))\n",
    "REPET_TE_gff_fh = os.path.join(out_dir,'%s.%s.REPET.TE.gff' % (genome, Tenovodb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-26T06:37:52.658548Z",
     "start_time": "2019-08-26T06:37:52.640413Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#define some prefixes used to aggregate coverages\n",
    "#and the genome file for bedtools\n",
    "repet_prefix_TE = '%s.%s.REPET.TE' % (genome, Tenovodb)\n",
    "repet_prefix_S =  '%s.%s.REPET.superfamily' % (genome, Tenovodb)\n",
    "genome_file_fh = os.path.join(source_dir, '%s.genome_file' % genome)\n",
    "genome_df = pd.read_csv(genome_file_fh, sep='\\t', header=None,names=['contig', 'length'])\n",
    "genome_size = genome_df['length'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-26T06:38:00.184395Z",
     "start_time": "2019-08-26T06:38:00.177984Z"
    }
   },
   "outputs": [],
   "source": [
    "genome_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-26T06:38:36.459457Z",
     "start_time": "2019-08-26T06:38:27.441864Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#generate the bedobjects\n",
    "RE_TE_gff = pybedtools.BedTool(REPET_TE_gff_fh)\n",
    "g_TE = RE_TE_gff.remove_invalid().saveas(REPET_TE_gff_fh.replace('gff', 'bedobject'))\n",
    "#use the blast filtered dataframe as well\n",
    "RE_S_gff = pybedtools.BedTool(REPET_sf_gff_fh)\n",
    "g_S = RE_S_gff.remove_invalid().saveas(REPET_sf_gff_fh.replace('gff', 'bedobject'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genome_file_fh.replace('.genome_file', '.REPET.genome_file')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genome_file_REPET_fh = genome_file_fh.replace('.genome_file', '.REPET.genome_file')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(genome_file_fh) as infile:\n",
    "    with open(genome_file_REPET_fh, 'w') as outfile:\n",
    "        for line in infile:\n",
    "            line =line.rstrip()\n",
    "            line = line.replace('APSI_P0', 'ApsiP_S00')\n",
    "            print(line, file=outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-26T06:39:46.853206Z",
     "start_time": "2019-08-26T06:38:39.984915Z"
    }
   },
   "outputs": [],
   "source": [
    "#use simple loop to loop over the bedcov genome coverage per classification. Keep track if everything is already done.\n",
    "jobs = []\n",
    "superfamily_bed_fh = REPET_sf_gff_fh.replace('gff', 'bedobject')\n",
    "superfamilies = REPET_gff_df['Class:Order:Superfamily'].unique()\n",
    "Parallel(n_jobs=threads)(delayed(subset_id)(ID, superfamily_bed_fh, repet_prefix_S, genome_file_REPET_fh)\\\n",
    "                      for ID in superfamilies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_gff_files = []\n",
    "for path in TE_path:\n",
    "    gff_files = [os.path.join(path, x) for x in os.listdir(path) if x.endswith('.gff') and x.startswith(genome)]\n",
    "    for file in gff_files:\n",
    "        class_gff_files.append(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "superfamilies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_cov_dict = {}\n",
    "order_cov_dict = {}\n",
    "superfamily_cov_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [os.path.basename(x) for x in TE_path]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TE_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _class in classes:\n",
    "    _class_df_list = []\n",
    "    tmp_path = [x for x in TE_path if x.endswith(_class)][0]\n",
    "    gff_files = [os.path.join(tmp_path, x) for x in os.listdir(tmp_path) if x.endswith('.gff')]\n",
    "    orders = []\n",
    "    \n",
    "    if _class == 'SSR' or _class == 'noCat':\n",
    "        tmp_bed = pybedtools.BedTool(gff_files[0]).sort().merge()\n",
    "        tmp_df = tmp_bed.to_dataframe()\n",
    "        tmp_df['cov'] = tmp_df['end'] - tmp_df['start']\n",
    "        coverage = tmp_df['cov'].sum()\n",
    "        class_cov_dict[_class] = [coverage]\n",
    "        \n",
    "    else:    \n",
    "    \n",
    "        for gff_file in gff_files:\n",
    "            #sort out the superfamilies\n",
    "            tmp_bed = pybedtools.BedTool(gff_file).sort().merge()\n",
    "            tmp_df = tmp_bed.to_dataframe()\n",
    "            tmp_df['cov'] = tmp_df['end'] - tmp_df['start']\n",
    "            coverage = tmp_df['cov'].sum()\n",
    "            superfamily = os.path.basename(gff_file).split('.')[-2]\n",
    "            superfamily_cov_dict[superfamily] = [coverage]\n",
    "            orders.append(superfamily.split(':')[1])        \n",
    "            tmp_bed.saveas(gff_file.replace('.gff', '.nr.bed'))\n",
    "\n",
    "        #now look into orders but don't take previous generarted 'order' and 'class' files.\n",
    "        nr_gff_files = [os.path.join(tmp_path, x) for x in os.listdir(tmp_path) if x.endswith('.nr.bed') and x.split(\".\")[3] != 'order' and x.split(\".\")[3] != 'class']\n",
    "\n",
    "        for order in set(orders):\n",
    "            print(_class)\n",
    "            print(nr_gff_files)\n",
    "            order_files = [x for x in nr_gff_files if os.path.basename(x).split('.')[4].split(':')[1] == order]\n",
    "            out_fn = order_files[0]\n",
    "            out_fn = '%s%s%s%s' % (out_fn[:out_fn.index('superfamily')], 'order.', order, '.bed')\n",
    "\n",
    "            concatfiles(out_fn, order_files)\n",
    "\n",
    "            tmp_bed = pybedtools.BedTool(out_fn).sort().merge()\n",
    "            tmp_df = tmp_bed.to_dataframe()\n",
    "            tmp_df['cov'] = tmp_df['end'] - tmp_df['start']\n",
    "            coverage = tmp_df['cov'].sum()\n",
    "            order_cov_dict[order] = [coverage]\n",
    "\n",
    "\n",
    "            tmp_bed.saveas(out_fn.replace('.bed', '.nr.bed'))\n",
    "\n",
    "\n",
    "        nr_gff_files = [os.path.join(tmp_path, x) for x in os.listdir(tmp_path) if x.endswith('.nr.bed') and os.path.basename(x).split('.')[3] == 'order']\n",
    "\n",
    "        out_fn = nr_gff_files[0]\n",
    "        out_fn = '%s%s%s%s' % (out_fn[:out_fn.index('order')], 'class.', _class, '.bed')\n",
    "        concatfiles(out_fn, nr_gff_files)\n",
    "        tmp_bed = pybedtools.BedTool(out_fn).sort().merge()\n",
    "        tmp_df = tmp_bed.to_dataframe()\n",
    "        tmp_df['cov'] = tmp_df['end'] - tmp_df['start']\n",
    "        coverage = tmp_df['cov'].sum()\n",
    "        class_cov_dict[_class] = [coverage]\n",
    "        tmp_bed.saveas(out_fn.replace('.bed', '.nr.bed'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#total coverage\n",
    "tmp_bed = pybedtools.BedTool(TE_gff_fh).sort().merge()\n",
    "tmp_df = tmp_bed.to_dataframe()\n",
    "tmp_df['cov'] = tmp_df['end'] - tmp_df['start']\n",
    "total_TE_coverage = tmp_df['cov'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_cov_dict['cov_all_TEs'] = total_TE_coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(superfamilies) - set(superfamily_cov_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "order_cov_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_cov_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### need complete coverage of TEs based on repet_gff with sort merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov_per_superfamily_df = pd.DataFrame.from_dict(superfamily_cov_dict).T\n",
    "cov_per_superfamily_df = cov_per_superfamily_df.append(pd.DataFrame.from_dict(class_cov_dict).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov_per_superfamily_df.rename(columns={0: 'bp'}, inplace=True)\n",
    "cov_per_superfamily_df['%'] = cov_per_superfamily_df['bp']/genome_size*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov_per_superfamily_df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov_per_superfamily_df['Class:Order:Superfamily'] = cov_per_superfamily_df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov_per_superfamily_df.index.rename('Class:Order:Superfamily', inplace = True)\n",
    "cov_per_superfamily_df['Class'] = cov_per_superfamily_df.apply(lambda row: TE_classification_filter(row['Class:Order:Superfamily'], 0), axis=1)\n",
    "cov_per_superfamily_df['Order'] = cov_per_superfamily_df.apply(lambda row: TE_classification_filter(row['Class:Order:Superfamily'], 1), axis=1)\n",
    "cov_per_superfamily_df['Superfamily'] = cov_per_superfamily_df.apply(lambda row: TE_classification_filter(row['Class:Order:Superfamily'], 2), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov_per_class_df = pd.DataFrame.from_dict(class_cov_dict).T\n",
    "cov_per_class_df.rename(columns={0: 'bp'}, inplace=True)\n",
    "cov_per_class_df['%'] = cov_per_class_df['bp']/genome_size*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov_per_superfamily_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov_per_superfamily_df.to_csv(out_dir+'/'+repet_prefix_S+'.tab', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-26T07:07:37.456004Z",
     "start_time": "2019-08-26T07:07:35.880263Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.style.use('seaborn-talk')\n",
    "fig, (ax0, ax1, ax2) = plt.subplots(nrows=3, ncols=1, figsize=(12,15))\n",
    "fig.suptitle(\"Repetitive elements in  %s\" % genome, fontsize=14, fontweight = 'bold')\n",
    "\n",
    "#color cycle from color blind people \n",
    "CB_color_cycle = ['#377eb8', '#ff7f00', '#4daf4a',\n",
    "                  '#f781bf', '#a65628', '#984ea3',\n",
    "'#999999', '#e41a1c', '#dede00']\n",
    "\n",
    "#plot the overall genome coverage by repetitive element category\n",
    "cov_per_class_df.sort_values(['%'], inplace=True)\n",
    "cov_per_class_df.plot(kind='barh', y='%', ax=ax0,  color='r')\n",
    "ax0.set_xlim([-5,100])\n",
    "ax0.legend().set_visible(False)\n",
    "ax0.set_yticklabels(list(cov_per_class_df.index),fontsize=10, fontweight='bold')\n",
    "ax0.set_ylabel(ylabel='RE categories', fontsize=14, fontweight='bold')\n",
    "\n",
    "#plot class I \n",
    "classI_df = cov_per_superfamily_df[cov_per_superfamily_df['Class'] == 'Retrotransposon'].sort_values('%',\\\n",
    "                                                            ascending=True)\n",
    "classI_df.drop('Retrotransposon', inplace = True)\n",
    "#pick out the colors to do color matching on the order level\n",
    "tmp_cn = len(classI_df['Order'].unique())\n",
    "tmp_colors = CB_color_cycle[0:tmp_cn]\n",
    "tmp_col_dict = dict(zip(classI_df['Order'].unique(), tmp_colors))\n",
    "classI_df['Color'] = classI_df['Order'].apply(lambda x: tmp_col_dict[x])\n",
    "ax1.barh(np.arange(len(classI_df.index)), classI_df['%'],\n",
    "        color=classI_df['Color'], ecolor='black')\n",
    "ax1.set_yticks(np.arange(len(classI_df.index)))\n",
    "ax1.set_xlim([-2,90])\n",
    "ax1.set_yticklabels(list(classI_df.index),fontsize=10, fontweight='bold')\n",
    "ax1.set_ylabel(ylabel='Class:Order:Superfamily', fontsize=14, fontweight='bold')\n",
    "ax1.set_title('ClassI: Retrotransposons', fontsize=14, fontweight='bold')\n",
    "\n",
    "#add tick lables\n",
    "\n",
    "for p, value in zip(ax1.patches, classI_df['%']):\n",
    "    ax1.annotate('{0:.3f}'.format(value), (80,p.get_y() * 1.005),fontsize=10, fontweight='bold' )\n",
    "\n",
    "#plot class II\n",
    "classII_df = cov_per_superfamily_df[cov_per_superfamily_df['Class'] == 'DNA_transposon'].sort_values('%',\\\n",
    "                                                                                        ascending=True)\n",
    "classII_df.drop('DNA_transposon', inplace = True)\n",
    "\n",
    "#pick out the colors to do color matching on the order level\n",
    "tmp_cn = len(classII_df['Order'].unique())\n",
    "tmp_colors = CB_color_cycle[0:tmp_cn]\n",
    "tmp_col_dict = dict(zip(classII_df['Order'].unique(), tmp_colors))\n",
    "classII_df['Color'] = classII_df['Order'].apply(lambda x: tmp_col_dict[x])\n",
    "\n",
    "#plot the class II out\n",
    "\n",
    "ax2.barh(np.arange(len(classII_df.index)), classII_df['%'],\n",
    "        color=classII_df['Color'], ecolor='black')\n",
    "\n",
    "ax2.set_xlim([-2, 90])\n",
    "ax2.set_yticks(np.arange(len(classII_df.index)))\n",
    "\n",
    "ax2.set_yticklabels(list(classII_df.index),fontsize=10, fontweight='bold')\n",
    "ax2.set_ylabel(ylabel='Class:Order:Superfamily', fontsize=14, fontweight='bold')\n",
    "ax2.set_title('ClassII: DNA transposons', fontsize=14, fontweight='bold')\n",
    "ax2.set_xlabel('% genome coverage', fontsize=14, fontweight='bold')\n",
    "\n",
    "#add tick lables\n",
    "\n",
    "for p, value in zip(ax2.patches, classII_df['%']):\n",
    "    ax2.annotate('{0:.3f}'.format(value), (80 ,p.get_y() * 1.005),fontsize=10, fontweight='bold' )\n",
    "\n",
    "    \n",
    "##OUTPATH for figures\n",
    "   \n",
    "#fig.savefig(os.path.join(out_dir, genome+'.REPET_summary_pc.seaborn-talk.png'), dpi=600, bbox_inches=\"tight\")\n",
    "outfn = os.path.join(OUTPATH, genome+'.REPET_summary_pc.seaborn-talk.tiff')\n",
    "#fig.savefig(outfn, dpi=600, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-26T07:09:51.489226Z",
     "start_time": "2019-08-26T07:09:18.032575Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.style.use('seaborn-talk')\n",
    "fig, (ax0, ax1, ax2) = plt.subplots(nrows=3, ncols=1, figsize=(12,15))\n",
    "fig.suptitle(\"Repetitive elements in P. striformis f. sp. tritici %s\" % genome, fontsize=14, fontweight = 'bold')\n",
    "\n",
    "#color cycle from color blind people \n",
    "CB_color_cycle = ['#377eb8', '#ff7f00', '#4daf4a',\n",
    "                  '#f781bf', '#a65628', '#984ea3',\n",
    "'#999999', '#e41a1c', '#dede00']\n",
    "\n",
    "#plot the overall genome coverage by repetitive element category\n",
    "cov_per_class_df.plot(kind='barh', y='bp', ax=ax0,  color='r')\n",
    "ax0.set_xlim([-5,50000000])\n",
    "ax0.legend().set_visible(False)\n",
    "ax0.set_yticklabels(list(cov_per_class_df.index),fontsize=10, fontweight='bold')\n",
    "ax0.set_ylabel(ylabel='RE categories', fontsize=14, fontweight='bold')\n",
    "\n",
    "#plot class I \n",
    "classI_df = cov_per_superfamily_df[cov_per_superfamily_df['Class'] == 'Retrotransposon'].sort_values('%',\\\n",
    "                                                            ascending=True)\n",
    "#pick out the colors to do color matching on the order level\n",
    "tmp_cn = len(classI_df['Order'].unique())\n",
    "tmp_colors = CB_color_cycle[0:tmp_cn]\n",
    "tmp_col_dict = dict(zip(classI_df['Order'].unique(), tmp_colors))\n",
    "classI_df['Color'] = classI_df['Order'].apply(lambda x: tmp_col_dict[x])\n",
    "ax1.barh(np.arange(len(classI_df.index)), classI_df['bp'],\n",
    "        color=classI_df['Color'], ecolor='black')\n",
    "ax1.set_yticks(np.arange(len(classI_df.index)))\n",
    "ax1.set_xlim([-2,14000000])\n",
    "ax1.set_yticklabels(list(classI_df.index),fontsize=10, fontweight='bold')\n",
    "ax1.set_ylabel(ylabel='Class:Order:Superfamily', fontsize=14, fontweight='bold')\n",
    "ax1.set_title('ClassI: Retrotransposons', fontsize=14, fontweight='bold')\n",
    "\n",
    "#add tick lables\n",
    "\n",
    "for p, value in zip(ax1.patches, classI_df['bp']):\n",
    "    ax1.annotate('{0:.2E}'.format(value), (14000000,p.get_y() * 1.005),fontsize=10, fontweight='bold' )\n",
    "\n",
    "#plot class II\n",
    "classII_df = cov_per_superfamily_df[cov_per_superfamily_df['Class'] == 'DNA_transposon'].sort_values('%',\\\n",
    "                                                                                        ascending=True)\n",
    "\n",
    "#pick out the colors to do color matching on the order level\n",
    "tmp_cn = len(classII_df['Order'].unique())\n",
    "tmp_colors = CB_color_cycle[0:tmp_cn]\n",
    "tmp_col_dict = dict(zip(classII_df['Order'].unique(), tmp_colors))\n",
    "classII_df['Color'] = classII_df['Order'].apply(lambda x: tmp_col_dict[x])\n",
    "\n",
    "#plot the class II out\n",
    "\n",
    "ax2.barh(np.arange(len(classII_df.index)), classII_df['bp'],\n",
    "        color=classII_df['Color'], ecolor='black')\n",
    "\n",
    "ax2.set_xlim([-2,14000000])\n",
    "ax2.set_yticks(np.arange(len(classII_df.index)))\n",
    "\n",
    "ax2.set_yticklabels(list(classII_df.index),fontsize=10, fontweight='bold')\n",
    "ax2.set_ylabel(ylabel='Class:Order:Superfamily', fontsize=14, fontweight='bold')\n",
    "ax2.set_title('ClassII: DNA transposons', fontsize=14, fontweight='bold')\n",
    "ax2.set_xlabel('bp genome coverage', fontsize=14, fontweight='bold')\n",
    "\n",
    "#add tick lables\n",
    "\n",
    "for p, value in zip(ax2.patches, classII_df['bp']):\n",
    "    ax2.annotate('{0:.2E}'.format(value), (14000000 ,p.get_y() * 1.005),fontsize=10, fontweight='bold' )\n",
    "    \n",
    "fig.savefig(os.path.join(out_dir, genome+'.REPET_summary_bpcov.seaborn-talk.png'), dpi=600, bbox_inches=\"tight\")\n",
    "\n",
    "outfn = os.path.join(OUTPATH, genome+'.REPET_summary_bpcov.seaborn-talk.tiff')\n",
    "fig.savefig(outfn, dpi=600, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now some analysis of the divergence of the TEs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-26T07:05:27.278615Z",
     "start_time": "2019-08-26T07:05:26.991766Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#now get the summary of allTEs == TEs specificaly identified by TEdenovo from REPET\n",
    "REPET_denovoTEs_df = pd.read_csv(\\\n",
    "        os.path.join(TE_postanalysis_dir, '%s_chr_allTEs_nr_noSSR_join_path.annotStatsPerTE.tab' % genome_repet),\\\n",
    "                                names = TE_post_analysis_p_header, header=None, sep='\\t', skiprows=1 )\n",
    "\n",
    "#now get in the summary of all bankBLRx TEs == TEs identified by repbase20.05_ntSeq_cleaned_TE\n",
    "REPET_nt_repbase_df = pd.read_csv(\\\n",
    "    os.path.join(TE_postanalysis_dir, '%s_chr_bankBLRx_path.annotStatsPerTE.tab' % genome_repet) ,\\\n",
    "    names = TE_post_analysis_p_header, header=None, sep='\\t', skiprows=1 )\n",
    "\n",
    "#now get in the summary of all bankBLRtx TEs == TEs identified by repbase20.05_aaSeq_cleaned_TE\n",
    "REPET_aa_repbase_df = pd.read_csv(\\\n",
    "    os.path.join(TE_postanalysis_dir, '%s_chr_bankBLRtx_path.annotStatsPerTE.tab' % genome_repet) ,\\\n",
    "    names = TE_post_analysis_p_header, header=None, sep='\\t', skiprows=1 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-26T07:05:28.200215Z",
     "start_time": "2019-08-26T07:05:28.178349Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#generate a df that contains all TEs: TEdenovo, blastx, blastn\n",
    "REPET_all_TEs_df = pd.concat([REPET_denovoTEs_df ,REPET_nt_repbase_df,\\\n",
    "                                       REPET_aa_repbase_df], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-26T07:05:29.092590Z",
     "start_time": "2019-08-26T07:05:29.056652Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "REPET_all_TEs_df = REPET_all_TEs_df[REPET_all_TEs_df.copies > 0]\n",
    "REPET_all_TEs_df = REPET_all_TEs_df[~REPET_all_TEs_df.TE.str.startswith(\"Potential\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-26T07:05:30.098882Z",
     "start_time": "2019-08-26T07:05:30.048396Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'TE_COS_dict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-13f4e3c3148f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#update the TE_COS_dict with missing values that come mostly from blastx and blastn searches.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmissing_TE_keys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mREPET_all_TEs_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTE\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTE_COS_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mmissing_TE_values\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m':'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmissing_TE_keys\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mTE_COS_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing_TE_keys\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mmissing_TE_values\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'TE_COS_dict' is not defined"
     ]
    }
   ],
   "source": [
    "#update the TE_COS_dict with missing values that come mostly from blastx and blastn searches.\n",
    "missing_TE_keys = list(set(REPET_all_TEs_df.TE.unique())- set(TE_COS_dict.keys()))\n",
    "missing_TE_values  = [x[x.find(':')+1:] for x in missing_TE_keys]\n",
    "TE_COS_dict.update(dict(zip(missing_TE_keys ,missing_TE_values )))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-26T07:05:31.094809Z",
     "start_time": "2019-08-26T07:05:30.910808Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get the Class/order/superfamily column to the dataframe based on the TE_COS_dict\n",
    "REPET_all_TEs_df[\"COS\"] = REPET_all_TEs_df[\"TE\"].apply(lambda x: TE_COS_dict[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-26T07:05:32.080202Z",
     "start_time": "2019-08-26T07:05:32.047468Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#using the formula T=D/t in arXiv:1209.0176 [q-bio] to approximate TE age\n",
    "# where D = (100-meanId)/100 and \n",
    "# t the substitution rate per site per year\n",
    "# generations per year are estimate at 15 10.1111/j.1365-294X.2007.03513.x\n",
    "# estimate of subsitution rate per year = 2 * 10-9 10.1093/oxfordjournals.molbev.a004056 and\n",
    "# 10.1016/j.fbr.2010.03.001\n",
    "REPET_all_TEs_df['TE_age_Mya'] = (((100-REPET_all_TEs_df.meanId)/100)\\\n",
    "                                        /(2*10**-9))/10**6\n",
    "REPET_all_TEs_df['TE_age'] = (((100-REPET_all_TEs_df.meanId)/100)\\\n",
    "                                        /(2*10**-9))\n",
    "REPET_all_TEs_df = REPET_all_TEs_df[REPET_all_TEs_df.copies > 5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-26T07:05:33.220792Z",
     "start_time": "2019-08-26T07:05:33.201220Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "REPET_ClassI_TEs_df = REPET_all_TEs_df[REPET_all_TEs_df.COS.str.startswith('ClassI:')]\n",
    "REPET_ClassII_TEs_df = REPET_all_TEs_df[REPET_all_TEs_df.COS.str.startswith('ClassII:')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-26T07:05:34.889667Z",
     "start_time": "2019-08-26T07:05:34.880081Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "font = {'family' : 'normal',\n",
    "        'weight' : 'bold',\n",
    "        'size'   : 20}\n",
    "label_config_x = {'fontsize'            : 'large',\n",
    "      'verticalalignment'   : 'top',\n",
    "      'horizontalalignment' : 'center'\n",
    "      }\n",
    "label_config_y = {'fontsize'            : 'large',\n",
    "      'verticalalignment'   : 'bottom',\n",
    "      'horizontalalignment' : 'center'\n",
    "      }\n",
    "matplotlib.rc('font', **font)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "REPET_ClassI_TEs_df.sort_values(by='COS', inplace=True)\n",
    "sns.boxplot(x='meanId', y='COS', data=REPET_ClassI_TEs_df,palette=\"vlag\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-26T07:05:36.939338Z",
     "start_time": "2019-08-26T07:05:35.685419Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.set(style=\"ticks\")\n",
    "\n",
    "# Initialize the figure with a logarithmic x axis\n",
    "f, ax = plt.subplots(figsize=(7, 6))\n",
    "ax.set_xscale(\"log\")\n",
    "\n",
    "REPET_ClassI_TEs_df.sort_values(by='COS', inplace=True)\n",
    "sns.boxplot(x='TE_age', y='COS', data=REPET_ClassI_TEs_df,palette=\"vlag\")\n",
    "\n",
    "plt.xlim(5*10**4, 10**9)\n",
    "plt.ylabel(\"Class:Order:Superfamily\",fontsize = 12, weight= 'bold')\n",
    "plt.xlabel(\"Age [years]\",fontsize = 12, weight= 'bold')\n",
    "\n",
    "ax.xaxis.grid(True)\n",
    "sns.despine(trim=True, left=True)\n",
    "out_fn = os.path.join(out_dir, '%s_%s_ClassI_age.png' % (genome, Tenovodb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-26T07:05:48.299483Z",
     "start_time": "2019-08-26T07:05:39.985585Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.set(style=\"ticks\")\n",
    "\n",
    "# Initialize the figure with a logarithmic x axis\n",
    "f, ax = plt.subplots(figsize=(7, 6))\n",
    "ax.set_xscale(\"log\")\n",
    "\n",
    "REPET_ClassI_TEs_df.sort_values(by='COS', inplace=True)\n",
    "sns.boxplot(x='TE_age', y='COS', data=REPET_ClassI_TEs_df,palette=\"vlag\")\n",
    "\n",
    "plt.xlim(5*10**6, 10**9)\n",
    "plt.ylabel(\"Class:Order:Superfamily\",fontsize = 12, weight= 'bold')\n",
    "plt.xlabel(\"Age [years]\",fontsize = 12, weight= 'bold')\n",
    "\n",
    "ax.xaxis.grid(True)\n",
    "sns.despine(trim=True, left=True)\n",
    "out_fn = os.path.join(out_dir, '%s_%s_ClassI_age.png' % (genome, Tenovodb))\n",
    "#f.savefig(out_fn, dpi=600,bbox_inches=\"tight\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "REPET_ClassII_TEs_df.sort_values(by='COS', inplace=True)\n",
    "sns.boxplot(x='meanId', y='COS', data=REPET_ClassII_TEs_df,palette=\"vlag\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-26T07:05:56.224097Z",
     "start_time": "2019-08-26T07:05:48.301791Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.set(style=\"ticks\")\n",
    "\n",
    "# Initialize the figure with a logarithmic x axis\n",
    "f, ax = plt.subplots(figsize=(7, 6))\n",
    "ax.set_xscale(\"log\")\n",
    "\n",
    "REPET_ClassII_TEs_df.sort_values(by='COS', inplace=True)\n",
    "sns.boxplot(x='TE_age', y='COS', data=REPET_ClassII_TEs_df,palette=\"vlag\")\n",
    "\n",
    "plt.xlim(5*10**6, 10**9)\n",
    "plt.ylabel(\"Class:Order:Superfamily\",fontsize = 12, weight= 'bold')\n",
    "plt.xlabel(\"Age [years]\",fontsize = 12, weight= 'bold')\n",
    "\n",
    "ax.xaxis.grid(True)\n",
    "sns.despine(trim=True, left=True)\n",
    "out_fn = os.path.join(out_dir, '%s_%s_ClassII_age.png' % (genome, Tenovodb))\n",
    "#f.savefig(out_fn, dpi=600,bbox_inches=\"tight\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-26T07:06:05.526292Z",
     "start_time": "2019-08-26T07:06:04.564158Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.set(style=\"ticks\")\n",
    "\n",
    "# Initialize the figure with a logarithmic x axis\n",
    "f, ax = plt.subplots(figsize=(7, 6))\n",
    "ax.set_xscale(\"log\")\n",
    "\n",
    "REPET_ClassII_TEs_df.sort_values(by='COS', inplace=True)\n",
    "sns.boxplot(x='TE_age', y='COS', data=REPET_ClassII_TEs_df,palette=\"vlag\")\n",
    "\n",
    "plt.xlim(5*10**4, 10**9)\n",
    "plt.ylabel(\"Class:Order:Superfamily\",fontsize = 12, weight= 'bold')\n",
    "plt.xlabel(\"Age [years]\",fontsize = 12, weight= 'bold')\n",
    "\n",
    "ax.xaxis.grid(True)\n",
    "sns.despine(trim=True, left=True)\n",
    "out_fn = os.path.join(out_dir, '%s_%s_ClassII_age.png' % (genome, Tenovodb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-26T07:06:10.870203Z",
     "start_time": "2019-08-26T07:06:10.802438Z"
    }
   },
   "outputs": [],
   "source": [
    "sub_df_young_many = REPET_all_TEs_df[(REPET_all_TEs_df.copies > 50) &( REPET_all_TEs_df.meanId > 75)]\n",
    "\n",
    "sub_df_young_many_by_COS_sum = sub_df_young_many.groupby('COS').sum()\n",
    "\n",
    "sub_df_young_many_by_COS_sum['Class'] = 'noCat'\n",
    "sub_df_young_many_by_COS_sum[\"Index\"] = sub_df_young_many_by_COS_sum.index\n",
    "sub_df_young_many_by_COS_sum['Order'] = 'noCat'\n",
    "sub_df_young_many_by_COS_sum['Class:Order'] = 'noCat'\n",
    "\n",
    "#generate Class column or noCat\n",
    "sub_df_young_many_by_COS_sum.loc[\\\n",
    "sub_df_young_many_by_COS_sum[sub_df_young_many_by_COS_sum.index.str.contains(':')].index\\\n",
    "                                 , \"Class\"] =\\\n",
    "sub_df_young_many_by_COS_sum[sub_df_young_many_by_COS_sum.index.str.contains(':')].Index.apply\\\n",
    "(lambda x: x.split(':')[0])\n",
    "\n",
    "#generate Order column or noCat\n",
    "sub_df_young_many_by_COS_sum.loc[\\\n",
    "sub_df_young_many_by_COS_sum[sub_df_young_many_by_COS_sum.index.str.contains(':')].index\\\n",
    "                                 , \"Order\"] =\\\n",
    "sub_df_young_many_by_COS_sum[sub_df_young_many_by_COS_sum.index.str.contains(':')].Index.apply\\\n",
    "(lambda x: x.split(':')[1])\n",
    "\n",
    "\n",
    "#generate Class order column\n",
    "sub_df_young_many_by_COS_sum.loc[\\\n",
    "sub_df_young_many_by_COS_sum[sub_df_young_many_by_COS_sum.index.str.contains(':')].index\\\n",
    "                                 , \"Class:Order\"] =\\\n",
    "sub_df_young_many_by_COS_sum[sub_df_young_many_by_COS_sum.index.str.contains(':')]['Class']\\\n",
    "+ ':' +\\\n",
    "sub_df_young_many_by_COS_sum[sub_df_young_many_by_COS_sum.index.str.contains(':')]['Order']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-26T07:06:12.346169Z",
     "start_time": "2019-08-26T07:06:12.320964Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get color column sorted\n",
    "colors = sns.color_palette('cubehelix', n_colors=\\\n",
    "                           len(sub_df_young_many_by_COS_sum['Class:Order'].unique()))\n",
    "color_dict = dict(zip(sub_df_young_many_by_COS_sum['Class:Order'].unique(), colors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-26T07:06:12.864770Z",
     "start_time": "2019-08-26T07:06:12.856284Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub_df_young_many_by_COS_sum['color'] = sub_df_young_many_by_COS_sum['Class:Order'].apply(\\\n",
    "        lambda x: color_dict[x])\n",
    "color_index_dict = dict(zip(sub_df_young_many_by_COS_sum.Index, sub_df_young_many_by_COS_sum.color))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-26T07:06:31.061043Z",
     "start_time": "2019-08-26T07:06:29.397369Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.set(style=\"ticks\")\n",
    "#sns.set_style(\"whitegrid\")\n",
    "# Initialize the figure with a logarithmic x axis\n",
    "f, ax = plt.subplots(figsize=(7, 6))\n",
    "sns.barplot(sub_df_young_many_by_COS_sum.index, sub_df_young_many_by_COS_sum.covg/10**6,\\\n",
    "           palette=color_index_dict)\n",
    "plt.ylim(0, 700)\n",
    "plt.ylabel(\"Coverage [Mb]\",**font)\n",
    "plt.xlabel(\"\",**font)\n",
    "sns.despine(trim=True)\n",
    "\n",
    "#change the colors of the legend\n",
    "key_list = list(color_dict.keys())\n",
    "key_list.sort()\n",
    "plt.legend(key_list, loc=(1, 0.1))\n",
    "leg = ax.get_legend()\n",
    "for (x,y) in zip(key_list, leg.legendHandles):\n",
    "    y.set_color(color_dict[x])\n",
    "    \n",
    "\n",
    "\n",
    "for l in ax.get_xticklabels():\n",
    "    l.set_rotation(90)\n",
    "    l.set_fontsize(16)\n",
    "for l in ax.get_yticklabels():\n",
    "    l.set_fontsize(16)\n",
    "    \n",
    "plt.legend(frameon=False)\n",
    "#['top','bottom','left','right']\n",
    "for axis in ['bottom','left']:\n",
    "    ax.spines[axis].set_linewidth(2)\n",
    "for axis in ['top','right']:\n",
    "    ax.spines[axis].set_linewidth(0)\n",
    "ax.tick_params(width=2)    \n",
    "    \n",
    "out_fn = os.path.join(OUTPATH, 'SF2C_%s_%s_TEs_young_and_plenty.tiff'  % (genome, Tenovodb))\n",
    "#f.savefig(out_fn, dpi=600, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df_young_many_by_COS_sum.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df_young_many.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "young_cov_TE = sub_df_young_many[sub_df_young_many.meanId > 75].groupby('TE')['covg'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "young_cov_TE.sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reusing above\n",
    "sub_df_young_many = REPET_all_TEs_df[(REPET_all_TEs_df.copies > 10) &( REPET_all_TEs_df.meanId > 10)]\n",
    "\n",
    "sub_df_young_many_by_COS_sum = sub_df_young_many.groupby('COS').sum()\n",
    "\n",
    "sub_df_young_many_by_COS_sum['Class'] = 'noCat'\n",
    "sub_df_young_many_by_COS_sum[\"Index\"] = sub_df_young_many_by_COS_sum.index\n",
    "sub_df_young_many_by_COS_sum['Order'] = 'noCat'\n",
    "sub_df_young_many_by_COS_sum['Class:Order'] = 'noCat'\n",
    "\n",
    "#generate Class column or noCat\n",
    "sub_df_young_many_by_COS_sum.loc[\\\n",
    "sub_df_young_many_by_COS_sum[sub_df_young_many_by_COS_sum.index.str.contains(':')].index\\\n",
    "                                 , \"Class\"] =\\\n",
    "sub_df_young_many_by_COS_sum[sub_df_young_many_by_COS_sum.index.str.contains(':')].Index.apply\\\n",
    "(lambda x: x.split(':')[0])\n",
    "\n",
    "#generate Order column or noCat\n",
    "sub_df_young_many_by_COS_sum.loc[\\\n",
    "sub_df_young_many_by_COS_sum[sub_df_young_many_by_COS_sum.index.str.contains(':')].index\\\n",
    "                                 , \"Order\"] =\\\n",
    "sub_df_young_many_by_COS_sum[sub_df_young_many_by_COS_sum.index.str.contains(':')].Index.apply\\\n",
    "(lambda x: x.split(':')[1])\n",
    "\n",
    "\n",
    "#generate Class order column\n",
    "sub_df_young_many_by_COS_sum.loc[\\\n",
    "sub_df_young_many_by_COS_sum[sub_df_young_many_by_COS_sum.index.str.contains(':')].index\\\n",
    "                                 , \"Class:Order\"] =\\\n",
    "sub_df_young_many_by_COS_sum[sub_df_young_many_by_COS_sum.index.str.contains(':')]['Class']\\\n",
    "+ ':' +\\\n",
    "sub_df_young_many_by_COS_sum[sub_df_young_many_by_COS_sum.index.str.contains(':')]['Order']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df_young_many.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intervals = pd.interval_range(start=20, end=100, closed='right', periods=80)\n",
    "sub_df_young_many['Intervals'] = pd.cut(sub_df_young_many.meanId, intervals)\n",
    "\n",
    "grouped = sub_df_young_many.groupby(['COS','Intervals'])\n",
    "sum_df = grouped.agg({'meanId': 'mean', 'covg': 'sum'})\n",
    "#sum_df['Interval_edge'] = intervals.right\n",
    "sum_df['freq_covg'] = sum_df.covg / sum_df.covg.sum()\n",
    "#sum_df[\"re_cumsum_covg\"] = sum_df.sort_values('Interval_edge', ascending='False')['covg'].cumsum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_freq_covg_df = sum_df.unstack()['freq_covg'].T\n",
    "sum_freq_covg_df['Interval_edge'] = [x.right for x in sum_freq_covg_df.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sum_freq_covg_df.drop('RLX-incomp_Blc2748_MR_P2A_300Mb-L-B3707-Map1', axis=1, inplace=True)\n",
    "sum_freq_covg_df.sort_values('Interval_edge', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_filter = sum_freq_covg_df.sum()*100 > 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_filter.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.interpolate import interp1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.color_palette('colorblind')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(8,8))\n",
    "\n",
    "df = sum_freq_covg_df.loc[:, column_filter]\n",
    "\n",
    "superfamilies = [x for x in sum_freq_covg_df.loc[:, column_filter].columns if not x == 'Interval_edge']\n",
    "\n",
    "col_n = len(sum_freq_covg_df.loc[:, column_filter].columns)\n",
    "\n",
    "pallete = sns.color_palette('colorblind')\n",
    "\n",
    "\n",
    "for sf, color in zip(superfamilies, pallete):\n",
    "    x, y = df['Interval_edge'], df[sf]\n",
    "    f2 = interp1d(x, y)\n",
    "    xnew = np.linspace(x.min(), x.max(), num=80, endpoint=True)\n",
    "    ax.plot(xnew, f2(xnew), '-', color=color, label = sf,  linewidth=3, alpha = 0.7)\n",
    "ax.legend()\n",
    "ax.set_ylabel('Relative frequency', **font)\n",
    "ax.set_xlabel('TE superfamily % identity', **font)\n",
    "#outfn = os.path.join(OUTPATH, 'SF2A_TE_variation.tiff')\n",
    "plt.legend(loc='upper left', frameon=False)\n",
    "#['top','bottom','left','right']\n",
    "for axis in ['bottom','left']:\n",
    "    ax.spines[axis].set_linewidth(2)\n",
    "for axis in ['top','right']:\n",
    "    ax.spines[axis].set_linewidth(0)\n",
    "ax.tick_params(width=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df[df.Interval_edge > 50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intervals = pd.interval_range(start=20, end=100, closed='right', periods=80)\n",
    "sub_df_young_many['Intervals'] = pd.cut(sub_df_young_many.meanId, intervals)\n",
    "\n",
    "grouped = sub_df_young_many.groupby(['TE','Intervals'])\n",
    "sum_df = grouped.agg({'meanId': 'mean', 'covg': 'sum'})\n",
    "#sum_df['Interval_edge'] = intervals.right\n",
    "sum_df['freq_covg'] = sum_df.covg / sum_df.covg.sum()\n",
    "#sum_df[\"re_cumsum_covg\"] = sum_df.sort_values('Interval_edge', ascending='False')['covg'].cumsum()\n",
    "sum_freq_covg_df = sum_df.unstack()['freq_covg'].T\n",
    "sum_freq_covg_df['Interval_edge'] = [x.right for x in sum_freq_covg_df.index]\n",
    "sum_freq_covg_df.sort_values('Interval_edge', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_filter = sum_freq_covg_df.sum()*100 > 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_filter.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df_young_many[sub_df_young_many.TE == 'RLX-incomp-chim_Blc22_MR_P2A_300Mb-L-B1-Map20_reversed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df_young_many[sub_df_young_many.TE.isin(superfamilies)]['COS'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.lines import Line2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "legend_elements = []\n",
    "for x, y in color_dict.items():\n",
    "    legend_elements.append(Line2D([0], [0], marker='o', color=y, label=x,\n",
    "                          markerfacecolor=y, markersize=10, lw=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#color code dots by TE COS\n",
    "f, ax = plt.subplots(figsize=(8,8))\n",
    "\n",
    "df = sum_freq_covg_df.loc[:, column_filter]\n",
    "\n",
    "superfamilies = [x for x in sum_freq_covg_df.loc[:, column_filter].columns if not x == 'Interval_edge']\n",
    "\n",
    "col_n = len(sum_freq_covg_df.loc[:, column_filter].columns)\n",
    "\n",
    "\n",
    "color_dict = {}\n",
    "cmap = get_cmap(col_n)\n",
    "for n, x in enumerate(sub_df_young_many[sub_df_young_many.TE.isin(superfamilies)]['COS'].unique()):\n",
    "    color_dict[x] = sns.color_palette('colorblind')[n]\n",
    "    \n",
    "\n",
    "\n",
    "pallete = sns.color_palette('colorblind')\n",
    "\n",
    "df.fillna(0)\n",
    "\n",
    "for sf in superfamilies:\n",
    "    x, y = df['Interval_edge'], df[sf]\n",
    "    #f2 = interp1d(x, y)\n",
    "    #xnew = np.linspace(x.min(), x.max(), num=80, endpoint=True)\n",
    "    ax.scatter(x, y, label = sf, color=color_dict[sub_df_young_many[sub_df_young_many.TE == sf]['COS'].tolist()[0]], linewidth=3, alpha = 0.5)\n",
    "ax.legend(handles=legend_elements, loc='best')\n",
    "ax.set_ylabel('Relative frequency', **font)\n",
    "ax.set_xlabel('TE family % identity', **font)\n",
    "#outfn = os.path.join(OUTPATH, 'SF2A_TE_variation.tiff')\n",
    "#plt.legend(loc='upper left', frameon=False)\n",
    "#['top','bottom','left','right']\n",
    "for axis in ['bottom','left']:\n",
    "    ax.spines[axis].set_linewidth(2)\n",
    "for axis in ['top','right']:\n",
    "    ax.spines[axis].set_linewidth(0)\n",
    "ax.tick_params(width=2)\n",
    "ax.set_ylim(0, 0.1)\n",
    "ax.set_xlim(15, 105)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['RLX-incomp-chim_Blc22_MR_P2A_300Mb-L-B1-Map20_reversed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For haplotigs run up to here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-26T06:51:47.730247Z",
     "start_time": "2019-08-26T06:51:47.726270Z"
    }
   },
   "source": [
    "### Now on to do the coverage analysis for the TEs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-08-27T01:29:55.297Z"
    }
   },
   "outputs": [],
   "source": [
    "g_window_1k200_bed = BedTool().window_maker(g=genome_file_fh, w=window_size, s=slide_size)\n",
    "\n",
    "#sort the TE gff file for easier handling with bedtools and convert some to bed files\n",
    "TE_gff_sorted_fh = TE_gff_fh.replace('.gff3', '.sorted.gff3')\n",
    "TE_gff_superfamily_fh = os.path.join(out_dir,'%s.%s.REPET.superfamily.gff' % (genome, Tenovodb))\n",
    "TE_gff_superfamily_sorted_fh = TE_gff_superfamily_fh.replace('.gff', '.sorted.bed')\n",
    "TE_gff_TEfamily_fh = os.path.join(out_dir,'%s.%s.REPET.TE.gff' % (genome, Tenovodb))\n",
    "TE_gff_TEfamily_sorted_fh = TE_gff_TEfamily_fh.replace('.gff', '.sorted.bed') \n",
    "\n",
    "gff3sort_pl = '/home/benjamin/genome_assembly/PST79/FALCON/p_assemblies/v9_1/Pst_104E_v12/get_homologues/gff3sort/gff3sort.pl'\n",
    "cmd1 = 'perl %s %s > %s' %(gff3sort_pl, TE_gff_fh , TE_gff_sorted_fh)\n",
    "cmd2 = \"perl %s %s | awk -v OFS='\\t' '{print $1, $4, $5, $9, $8, $7 }' > %s \" % (gff3sort_pl, TE_gff_superfamily_fh,TE_gff_superfamily_sorted_fh )\n",
    "cmd3 = \"perl %s %s | awk -v OFS='\\t' '{print $1, $4, $5, $9, $8, $7 }' > %s \" % (gff3sort_pl, TE_gff_TEfamily_fh ,TE_gff_TEfamily_sorted_fh )\n",
    "\n",
    "\n",
    "subprocess.check_output(cmd1, shell=True, stderr=subprocess.STDOUT)\n",
    "subprocess.check_output(cmd2, shell=True, stderr=subprocess.STDOUT)\n",
    "subprocess.check_output(cmd3, shell=True, stderr=subprocess.STDOUT)\n",
    "\n",
    "#generate the bed objects that are windows that will be used for the coverage analysis\n",
    "TE_bed = BedTool(fn=TE_gff_sorted_fh)\n",
    "g_TE_1k200_bed = g_window_1k200_bed.intersect(TE_bed)\n",
    "g_noTE_1k200_bed = g_window_1k200_bed.subtract(TE_bed)\n",
    "\n",
    "#now read in the bam files as beds\n",
    "pbam_bed = BedTool(fn=pbam_fh)\n",
    "\n",
    "#define outfile names to write out the coverage files\n",
    "TE_cov_dir = os.path.join(out_dir, 'TE_COV')\n",
    "if not os.path.exists(TE_cov_dir):\n",
    "    os.mkdir(TE_cov_dir)\n",
    "#really we want to do samtools bedcov    \n",
    "g_TE_1k200_samcovfh = os.path.join(TE_cov_dir, '%s.%s.g_TE_%ik%i.samcov' % (genome, Tenovodb, window_size/1000, slide_size ))\n",
    "g_noTE_1k200_samcovfh = os.path.join(TE_cov_dir, '%s.%s.g_noTE_%ik%i.samcov' % (genome, Tenovodb, window_size/1000, slide_size ))\n",
    "g_window_1k200_samcovfh = os.path.join(TE_cov_dir, '%s.%s.g_window_%ik%i.samcov' % (genome, Tenovodb, window_size/1000, slide_size ))\n",
    "TE_gff_superfamily_samcovfh = os.path.join(TE_cov_dir, TE_gff_superfamily_sorted_fh.split('/')[-1].replace('.bed','.samcov'))\n",
    "TE_gff_TEfamily_samcovfh = os.path.join(TE_cov_dir,TE_gff_TEfamily_sorted_fh.split('/')[-1].replace('.bed','.samcov'))\n",
    "\n",
    "g_window_1k200_bed.saveas(g_window_1k200_samcovfh.replace('.samcov', '.bed'))\n",
    "g_TE_1k200_bed.saveas(g_TE_1k200_samcovfh.replace('.samcov', '.bed'))\n",
    "g_noTE_1k200_bed.saveas(g_noTE_1k200_samcovfh.replace('.samcov', '.bed'))\n",
    "\n",
    "#make the BUSCOs bed file\n",
    "busco_df = pd.read_csv(protein_busco_fh, comment='#', header=None, sep='\\t')\n",
    "single_buscos = busco_df[busco_df[1] == 'Complete'][2].tolist()\n",
    "gene_bed_fh = os.path.join(source_dir, 'DK_0911_v04LT_p_ctg.gene.bed')\n",
    "gene_bed_df = pd.read_csv(gene_bed_fh, sep='\\t', header=None)\n",
    "single_busco_bed_fh = os.path.join(out_dir, '%s.sBUSCO.bed'%genome)\n",
    "single_busco_samcov_fh = os.path.join(TE_cov_dir, single_busco_bed_fh.split('/')[-1].replace('bed', 'samcov'))\n",
    "gene_bed_df[gene_bed_df[3].isin(single_buscos)].to_csv(single_busco_bed_fh, sep='\\t', header=None, index=None)\n",
    "\n",
    "beds = [g_TE_1k200_samcovfh.replace('.samcov', '.bed'),\\\n",
    "        g_noTE_1k200_samcovfh.replace('.samcov', '.bed'),\\\n",
    "        g_window_1k200_samcovfh.replace('.samcov', '.bed') ,\\\n",
    "       single_busco_bed_fh,\\\n",
    "       TE_gff_superfamily_sorted_fh,\\\n",
    "        TE_gff_TEfamily_sorted_fh]\n",
    "outs = [g_TE_1k200_samcovfh, g_noTE_1k200_samcovfh, g_window_1k200_samcovfh,\\\n",
    "        single_busco_samcov_fh, TE_gff_superfamily_samcovfh,  TE_gff_TEfamily_samcovfh]\n",
    "Parallel(n_jobs=len(beds))(delayed(run_samtools_bedcov)(bed, pbam_fh, out)\\\n",
    "                      for bed, out in zip(beds, outs))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-27T03:24:03.323295Z",
     "start_time": "2019-08-27T03:21:56.198611Z"
    }
   },
   "outputs": [],
   "source": [
    "#now make the BUSCO dataframe\n",
    "sBUSCO_df = samcov_slurp( single_busco_samcov_fh, fil=False)\n",
    "\n",
    "sBUSCO_df['contig_number'] = [int(x[-1]) for x in sBUSCO_df.contig.str.split('_')]\n",
    "\n",
    "sBUSCO_df.plot(x='contig_number', y='norm_cov', kind='scatter')\n",
    "\n",
    "sBUSCO_df['norm_cov'].plot(kind='kde')\n",
    "\n",
    "sBUSCO_mean = sum(sBUSCO_df.total_cov)/sum(sBUSCO_df.interval_size)\n",
    "print('The single BUSCO mean coverage is %0.2f.' % sBUSCO_mean)\n",
    "\n",
    "g_TE_1k200_samcov_df = samcov_slurp(g_TE_1k200_samcovfh, mean=sBUSCO_mean ,fil=False)\n",
    "g_noTE_1k200_samcov_df = samcov_slurp(g_noTE_1k200_samcovfh,mean=sBUSCO_mean, fil=False)\n",
    "g_window_1k200_samcov_df = samcov_slurp(g_window_1k200_samcovfh,mean=sBUSCO_mean,fil=False)\n",
    "TE_gff_superfamily_samcov_df = samcov_slurp(TE_gff_superfamily_samcovfh,mean=sBUSCO_mean,fil=False)\n",
    "TE_gff_TEfamily_samcov_df = samcov_slurp(TE_gff_TEfamily_samcovfh,mean=sBUSCO_mean,fil=False)\n",
    "\n",
    "sBUSCO_df['norm_cov'].plot(kind='kde',color='k')\n",
    "g_TE_1k200_samcov_df['norm_cov'].plot(kind='kde',color='r')\n",
    "g_window_1k200_samcov_df['norm_cov'].plot(kind='kde')\n",
    "\n",
    "sBUSCO_df['norm_cov'].plot(kind='hist',color='k', bins=100)\n",
    "\n",
    "TE_gff_superfamily_samcov_df['log10_ncov'] = np.log10(TE_gff_superfamily_samcov_df['norm_cov'])\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(12,15))\n",
    "order = pd.concat([classI_df.sort_values('bp', ascending=False)['Class:Order:Superfamily'],  \\\n",
    "                   classII_df.sort_values('bp', ascending=False)['Class:Order:Superfamily']])\n",
    "sns.boxplot(x='ID', y='log10_ncov', data=TE_gff_superfamily_samcov_df, ax=ax, order=order)\n",
    "plt.xticks(rotation=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-27T03:24:39.900635Z",
     "start_time": "2019-08-27T03:24:39.303472Z"
    }
   },
   "outputs": [],
   "source": [
    "genome_size = pd.read_csv(genome_file_fh, sep='\\t',header=None)[1].sum()\n",
    "mean_genome = sum(g_window_1k200_samcov_df.total_cov)/sum(g_window_1k200_samcov_df.interval_size)\n",
    "\n",
    "print(genome_size)\n",
    "\n",
    "print(int(genome_size *(mean_genome/sBUSCO_mean)))\n",
    "\n",
    "mean_TEs = sum(g_TE_1k200_samcov_df.total_cov)/sum(g_TE_1k200_samcov_df.interval_size)\n",
    "\n",
    "mean_sfamily_TEs = sum(TE_gff_superfamily_samcov_df.total_cov)/sum(TE_gff_superfamily_samcov_df.interval_size)\n",
    "\n",
    "print(mean_sfamily_TEs)\n",
    "\n",
    "print(mean_TEs)\n",
    "\n",
    "print(sBUSCO_mean)\n",
    "\n",
    "print(mean_genome)\n",
    "\n",
    "print(sum(g_noTE_1k200_samcov_df.total_cov)/sum(g_noTE_1k200_samcov_df.interval_size))\n",
    "\n",
    "print(sum(g_TE_1k200_samcov_df.total_cov)/sum(g_TE_1k200_samcov_df.interval_size))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-27T03:25:21.839579Z",
     "start_time": "2019-08-27T03:25:21.699508Z"
    }
   },
   "outputs": [],
   "source": [
    "TE_gff_superfamily_samcov_df.pivot_table(values='norm_cov', columns='ID', aggfunc=[np.mean, np.count_nonzero])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
