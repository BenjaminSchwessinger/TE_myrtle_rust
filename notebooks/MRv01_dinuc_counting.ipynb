{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/benjamin/anaconda3/bin:/home/benjamin/anaconda3/ensembl-vep:/home/benjamin/anaconda3/mummer-4.0.0/bin:/home/benjamin/anaconda3/bin:/usr/local/bioinfo/tcoffee11/bin:/home/benjamin/bin:/home/benjamin/anaconda3/ensembl-vep:/home/benjamin/anaconda3/mummer-4.0.0/bin:/home/benjamin/anaconda3/bin:/usr/local/bioinfo/tcoffee11/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/snap/bin:/usr/local/bioinfo/a5/bin:/usr/local/bioinfo/aragorn1.2.38:/usr/local/bioinfo/barrnap-0.7/bin:/usr/local/bioinfo/ca/bin:/usr/local/bioinfo/canu/bin:/usr/local/bioinfo/cap3:/usr/local/bioinfo/hisat2:/usr/local/bioinfo/kraken-0.10.5-beta:/usr/local/bioinfo/nanopolish:/usr/local/bioinfo/NOVOPlasty:/usr/local/bioinfo/Organelle_PBA:/usr/local/bioinfo/PASApipeline/bin:/usr/local/bioinfo/phylip:/usr/local/bioinfo/pilon:/usr/local/bioinfo/Platypus_0.8.1:/usr/local/bioinfo/prokka/bin:/usr/local/bioinfo/prottest3:/usr/local/bioinfo/signalp-4.1:/usr/local/bioinfo/soap:/usr/local/bioinfo/SPAdes/bin:/usr/local/bioinfo/sprai/bin:/usr/local/bioinfo/SSPACE-LongRead_v1-1:/usr/local/bioinfo/stacks-1.41:/usr/local/bioinfo/subread/bin:/usr/local/bioinfo/Unicycler:/usr/local/bioinfo/velvet:/usr/local/bioinfo/samtools/bin:/usr/local/bioinfo/Salmon-0.9.1/bin:/usr/local/bioinfo/plink-1.07-x86_64:/usr/local/bioinfo/snippy/bin\n"
     ]
    }
   ],
   "source": [
    "!echo $PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pybedtools'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-ff467bc7697f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpybedtools\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBedTool\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpybedtools\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pybedtools'"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "from pybedtools import BedTool\n",
    "import numpy as np\n",
    "import pybedtools\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import matplotlib\n",
    "import subprocess\n",
    "import numpy as np\n",
    "import shutil\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define your input folders\n",
    "#define your input folders updated for haplotigs\n",
    "EFFECTORP_FOLDER = '../../../genome_v03/annotation/functional/'\n",
    "BUSCO_FOLDER = '../../../genome_v03/annotation/BUSCO/'\n",
    "GFF_FOLDER = '../../../genome_v03/annotation/structural/'\n",
    "GENOME_FOLDER = '../../genome/'\n",
    "TE_FOLDER = '../../TE_analysis/'\n",
    "EFFECTOR_FOLDER = '../../../genome_v03/effector_analysis'\n",
    "PROTEIN_ANNO_FOLDER = '../../annotation/functional/'\n",
    "AT_analysis = '../../AT_analysis'\n",
    "OUT_FOLDER = os.path.join(AT_analysis, 'Dinucl')\n",
    "TMP_FOLDER = os.path.join(OUT_FOLDER, 'difacount')\n",
    "CONTROL_FOLDER = os.path.join(AT_analysis, 'control_samples')\n",
    "OUT_FOLDER_FIG = '../../figures/'\n",
    "TMP_FIG_PATH = '../../../genome_v03/tmp_figures'\n",
    "genome = 'APSI_primary_v1'\n",
    "REPET_genome = 'MR_P2_a0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(OUT_FOLDER):\n",
    "    os.mkdir(OUT_FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(TMP_FOLDER):\n",
    "    os.mkdir(TMP_FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now get all the file names\n",
    "genome_fn = os.path.join(GENOME_FOLDER, '%s.fa' %genome)\n",
    "test_fn = os.path.join(TMP_FOLDER, 'test.fa')\n",
    "!head {genome_fn} > {test_fn}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!head {test_fn}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def facount(in_fn, out_fn):\n",
    "    cmd = 'faCount -dinuc %s > %s' % \\\n",
    "    (os.path.abspath(in_fn), os.path.abspath(out_fn))\n",
    "    output = subprocess.run(cmd, shell=True)\n",
    "    return output.returncode"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def do_RIP_call(fac_fn):\n",
    "    \"Return pandas dataframe with caculations reading in the faCount outfile.\"\n",
    "    faC_header = ['seqID','len','A','C','G','T','N','cpg','AA','AC','AG',\n",
    "                 'AT','CA','CC','CG','CT','GA','GC','GG','GT','TA','TC','TG','TT']\n",
    "    count_dict = {}\n",
    "    for n_pattern in faC_header:\n",
    "        count_dict[n_pattern] = []\n",
    "    dtypes = {}\n",
    "    for x in faC_header:\n",
    "        dtypes[x] = 'int'\n",
    "    dtypes['seqID'] = 'str'\n",
    "    with open(fac_fn) as fh: \n",
    "        for line in fh:\n",
    "            line = line.rstrip()\n",
    "            split_line = re.split(pattern, line)\n",
    "            if not line.startswith('#'):\n",
    "                #if len(split_line) > len(faC_header):\n",
    "                  #  split_line = split_line[0:len(faC_header)+1]\n",
    "\n",
    "                for n_pattern, value in zip(faC_header, split_line):\n",
    "                    count_dict[n_pattern].append(value)\n",
    "    df = pd.DataFrame.from_dict(count_dict)\n",
    "    df = df.astype(dtypes)\n",
    "    df['TpA/ApT'] = df['TA']/df['AT']\n",
    "    df['CpA + TpG/ApC + GpT'] = (df['CA'] + df['TG'])/(df['AC']+df['GT'])\n",
    "    df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_RIP_call(fac_fn):\n",
    "    \"Return pandas dataframe with caculations reading in the faCount outfile.\"\n",
    "    faC_header = ['seqID','len','A','C','G','T','N','cpg','AA','AC','AG',\n",
    "                 'AT','CA','CC','CG','CT','GA','GC','GG','GT','TA','TC','TG','TT']\n",
    "    count_dict = {}\n",
    "    for n_pattern in faC_header:\n",
    "        count_dict[n_pattern] = []\n",
    "    dtypes = {}\n",
    "    for x in faC_header:\n",
    "        dtypes[x] = 'int'\n",
    "    dtypes['seqID'] = 'str'\n",
    "    with open(fac_fn) as fh: \n",
    "        for line in fh:\n",
    "            line = line.rstrip()\n",
    "            split_line = re.split('\\t', line)\n",
    "            if not line.startswith('#'):\n",
    "                #if len(split_line) > len(faC_header):\n",
    "                  #  split_line = split_line[0:len(faC_header)+1]\n",
    "\n",
    "                for n_pattern, value in zip(faC_header, split_line):\n",
    "                    count_dict[n_pattern].append(value)\n",
    "    df = pd.DataFrame.from_dict(count_dict)\n",
    "    df = df.astype(dtypes)\n",
    "    df['TpA/ApT'] = df['TA']/df['AT']\n",
    "    df['CpA + TpG/ApC + GpT'] = (df['CA'] + df['TG'])/(df['AC']+df['GT'])\n",
    "    df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AT_content_df(bed_fn, contig_fn, intervals, merge=True):\n",
    "    \"\"\"Caculate the %AT for contigs and group %AT in specific intervals.\"\"\"\n",
    "    bed = BedTool(bed_fn)\n",
    "    if merge == True:\n",
    "        bed.sort().merge()\n",
    "    #specify datatypes if possible\n",
    "    tmp_fn = bed_fn.replace('.bed', '.AT.bed.tmp')\n",
    "    dtype_dict = {0:str, 1:np.int32, 2:np.int32, 3:str, 4:str, 5:str, 6:float}\n",
    "    bed.nucleotide_content(fi=contig_fn).saveas(tmp_fn)\n",
    "    #bedtools nuc -fi {contig_fn} -bed {bed_fn} > {tmp_fn}\n",
    "    \n",
    "    if len(bed.to_dataframe().columns) == 6:\n",
    "        dtype_dict = {0:str, 1:np.int32, 2:np.int32, 3:str, 4:str, 5:str, 6:float}\n",
    "        df = pd.read_csv( tmp_fn, sep='\\t',header=None,dtype=dtype_dict, usecols=[0,1,2,3,6], skiprows=1)\n",
    "        df.rename(columns={6:'%AT'}, inplace=True)\n",
    "    elif len(bed.to_dataframe().columns) == 3:\n",
    "        dtype_dict = {0:str, 1:np.int32, 2:np.int32, 3:float}\n",
    "        df = pd.read_csv( tmp_fn, sep='\\t',header=None,dtype=dtype_dict, usecols=[0,1,2,3], skiprows=1)\n",
    "        df.rename(columns={3:'%AT'}, inplace=True)\n",
    "    df['%AT'] = df['%AT'].astype('float')\n",
    "    df['W_Len'] = df[2] - df[1]\n",
    "    \n",
    "    df['Intervals'] = pd.cut(df['%AT'], intervals)\n",
    "    grouped = df.groupby('Intervals')\n",
    "    ###group by the edge\n",
    "    ####get the length of the intervals and plot the sum for each interval\n",
    "    ###edge\n",
    "    \n",
    "    \n",
    "    sum_df = grouped.agg({'%AT': 'count', 'W_Len': 'sum'})\n",
    "    sum_df['Interval_edge'] = intervals.right\n",
    "    sum_df.fillna(0, inplace=True)\n",
    "    sum_df['norm_count_AT'] = sum_df['%AT']/sum_df['%AT'].sum()\n",
    "    sum_df['norm_W_Len'] = sum_df['W_Len']/sum_df['W_Len'].sum()\n",
    "    os.remove(tmp_fn)\n",
    "    return df, sum_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-11-ce144e255aba>, line 8)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-11-ce144e255aba>\"\u001b[0;36m, line \u001b[0;32m8\u001b[0m\n\u001b[0;31m    tmp_out_fn = RM_fn.replace('.gff', F'.{select}.gff')\u001b[0m\n\u001b[0m                                                      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def RM_subset(RM_fn, selection):\n",
    "    \"\"\"Pulls in the the RM gff and subsets it for the selected\n",
    "    features entered as lis.\"\"\"\n",
    "    df = pd.read_csv(RM_fn, header = None, comment='#', sep = '\\t')\n",
    "    tmp_fn_list = []\n",
    "    for select in selection:\n",
    "        tmp_df = df[df[8].str.contains(select)]\n",
    "        tmp_out_fn = RM_fn.replace('.gff', F'.{select}.gff')\n",
    "        tmp_df.to_csv(tmp_out_fn, header = None, index = None, sep = '\\t')\n",
    "        tmp_fn_list.append(tmp_out_fn)\n",
    "    return tmp_fn_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reverse_bed(genome_fn, gff_fn):\n",
    "    \"\"\"A bit of a hack to get the reverse of \n",
    "    a gff_fn\"\"\"\n",
    "    !samtools faidx {genome_fn}\n",
    "    tmp_fn = genome_fn + '.genome_file'\n",
    "    !cut -f1,2 {genome_fn}.fai | sort -k 1,1 > {tmp_fn}\n",
    "    tmp_out_fn = gff_fn.replace('.gff', '.reverse.nr.bed')\n",
    "    pybedtools.BedTool(gff_fn).sort()\\\n",
    "    .merge().complement(g=tmp_fn).saveas(tmp_out_fn)\n",
    "    return tmp_out_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename some of the genome headers as the initial genome had different contig names as the recent genome\n",
    "repet_genome_fn = os.path.join(AT_analysis, '%s.repet.fa' % genome)\n",
    "with open(genome_fn, 'r') as g_fh:\n",
    "    with open(repet_genome_fn, 'w') as rg_fh:\n",
    "        for line in g_fh:\n",
    "            line = line.rstrip('\\n')\n",
    "            if line.startswith(\">\"):\n",
    "                line = line.replace('APSI_P0','ApsiP_S00')\n",
    "                print(line, file = rg_fh)\n",
    "            else:\n",
    "                print(line, file = rg_fh)\n",
    "#do some indexing of genome and generate the genome file\n",
    "!samtools faidx {repet_genome_fn}\n",
    "!cut -f1,2 {repet_genome_fn}.fai > {repet_genome_fn.replace('.fa', '.genome')}\n",
    "repet_genome_index_fn = os.path.abspath(repet_genome_fn.replace('.fa', '.genome'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate the non-TE genome bedfile\n",
    "repet_gff_fn = os.path.join(TE_FOLDER, 'APSI_primary_v1.MR_P2A_300Mb.REPET.gff3' )\n",
    "repet_bed_reverse_fn = repet_gff_fn.replace('.gff3', '.reverse.nr.bed')\n",
    "pybedtools.BedTool(repet_gff_fn).sort().merge().\\\n",
    "complement(g=repet_genome_index_fn).saveas(repet_bed_reverse_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#collect all the non-redundant bed files for the RNA and DNA transposons annotated in the myrtle rust genome\n",
    "###consider not to use the nr bed but look at strand specific sequences####\n",
    "###This can be done by subsetting the GFF3 dataframe by specific column###\n",
    "###Thinking about this I don't think the strand matters as the revers complement of TA is TA###\n",
    "repet_bed_flies = []\n",
    "for folder in ['Retrotransposon', 'DNA_transposon']:\n",
    "    for file in os.listdir(os.path.join(TE_FOLDER, folder)):\n",
    "        if file.endswith('.nr.bed') and file.split('.')[3] == 'superfamily':\n",
    "            repet_bed_flies.append(os.path.join(TE_FOLDER, folder, file))\n",
    "repet_bed_flies.append(repet_bed_reverse_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#collect all the DNA sequences for the repet bedfiles to do the facount on them\n",
    "###consider not to use the nr bed but look at strand specific sequences####\n",
    "facount_fa_files = []\n",
    "for tmp_bed_fn in repet_bed_flies:\n",
    "    tmp_bed = BedTool(tmp_bed_fn)\n",
    "    tmp_out_fn = os.path.join(TMP_FOLDER, os.path.basename(tmp_bed_fn)\\\n",
    "                              .replace('.bed', '.fa'))\n",
    "    tmp_bed.sequence(fi=repet_genome_fn).save_seqs(tmp_out_fn)\n",
    "    facount_fa_files.append(tmp_out_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pulling in the AT files based on occulter_cut and saving out the files\n",
    "#and saving out the regions that are higher and lower 61% AT\n",
    "intervals = pd.interval_range(start=0.2, end=1.0, closed='right', periods=80)\n",
    "oc_bed_fn = os.path.join(AT_analysis, 'regions.bed')\n",
    "\n",
    "oc_df, oc_sum_df = AT_content_df(oc_bed_fn, genome_fn, intervals)\n",
    "oc_greater_fn = os.path.join(AT_analysis, 'Greater_61%AT_regions.bed')\n",
    "oc_smaller_fn = os.path.join(AT_analysis, 'Smaller_61%AT_regions.bed')\n",
    "\n",
    "oc_df[oc_df['%AT'] > 0.61].iloc[:, 0:3].to_csv(oc_greater_fn, index=None, header=None, sep='\\t')\n",
    "oc_df[(oc_df['%AT'] < 0.61)|(oc_df['%AT'] == 0.61)].iloc[:, 0:3].to_csv(oc_smaller_fn, index=None, header=None, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#collect some more bedfiles of interest and get the sequences for \n",
    "#facount\n",
    "bed_files = []\n",
    "bed_files.append(os.path.join(EFFECTOR_FOLDER, 'APSI_primary_v1.transcript.genes.bed'))\n",
    "bed_files.append(oc_greater_fn)\n",
    "bed_files.append(oc_smaller_fn)\n",
    "\n",
    "for tmp_bed_fn in bed_files:\n",
    "    tmp_bed = BedTool(tmp_bed_fn)\n",
    "    tmp_out_fn = os.path.join(TMP_FOLDER, os.path.basename(tmp_bed_fn)\\\n",
    "                              .replace('.bed', '.fa'))\n",
    "    tmp_bed.sequence(fi=genome_fn).save_seqs(tmp_out_fn)\n",
    "    facount_fa_files.append(tmp_out_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#also add the genome file to the mix\n",
    "tmp_repet_genome_fn = os.path.join(TMP_FOLDER, os.path.basename(repet_genome_fn))\n",
    "shutil.copyfile(repet_genome_fn, tmp_repet_genome_fn)\n",
    "facount_fa_files.append(tmp_repet_genome_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "facount_fa_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cacluate the dinucleodite frequencies for all the given fa files\n",
    "#store the counts and sequence lenght in three dictionaries\n",
    "facount_fac_files = []\n",
    "#'TpA/ApT'\n",
    "dicount_dict_S = {}\n",
    "#'CpA + TpG/ApC + GpT'\n",
    "dicount_dict_L = {}\n",
    "#length\n",
    "dicount_dict_length = {}\n",
    "for file in facount_fa_files:\n",
    "    tmp_out_fn = file.replace('.fa', '.fac')\n",
    "    facount(file, tmp_out_fn)\n",
    "    facount_fac_files.append(tmp_out_fn)\n",
    "    tmp_df = do_RIP_call(tmp_out_fn)\n",
    "    if 'superfamily' in file:\n",
    "        name = os.path.basename(file).split('.')[4]\n",
    "    elif 'REPET.reverse.nr.' in file:\n",
    "        name = 'non_TE'\n",
    "    elif 'transcript.genes' in file:\n",
    "        name = 'genes'\n",
    "    elif '%AT_regions' in file:\n",
    "        name = os.path.basename(file).split('.')[0]\n",
    "    elif 'APSI_primary_v1.repet.fa' in file:\n",
    "        name = os.path.basename(file)[:-3]\n",
    "    dicount_dict_S[name] = tmp_df['TpA/ApT'].values\n",
    "    dicount_dict_L[name] = tmp_df['CpA + TpG/ApC + GpT'].values\n",
    "    dicount_dict_length[name] = tmp_df['len'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reminder of how to filter things\n",
    "dicount_dict_S['APSI_primary_v1.repet'][dicount_dict_length['APSI_primary_v1.repet'] > 100000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#'CpA + TpG/ApC + GpT: dicount_dict_L\n",
    "for x in dicount_dict_L.keys():\n",
    "    print(x, ': ', np.median(dicount_dict_L[x][(dicount_dict_length[x] > 1000)&(~np.isnan(dicount_dict_L[x]))][:-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#'TpA/ApT': dicount_dict_S increases due to RIP\n",
    "for x in  dicount_dict_S.keys():\n",
    "    print(x, ': ', np.median(dicount_dict_S[x][(dicount_dict_length[x] > 500)&(~np.isnan(dicount_dict_S[x]))][:-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_interest = ['non_TE', 'genes', 'ClassI:LTR:Gypsy','ClassI:LTR:Copia', 'Greater_61%AT_regions', 'Smaller_61%AT_regions', 'APSI_primary_v1.repet']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff = 500\n",
    "col = 4\n",
    "rows = len(list_of_interest) // col\n",
    "if len(list_of_interest) % col > 0:\n",
    "    rows +=1\n",
    "print(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#'TpA/ApT': dicount_dict_S increases due to RIP\n",
    "fig, ax = plt.subplots(rows, col, figsize = (20, 10), sharey=True)\n",
    "gene_mean = np.median(dicount_dict_S['genes']\\\n",
    "                      [(dicount_dict_length['genes'] > cutoff)&(~np.isnan(dicount_dict_S['genes']))][:-1])\n",
    "non_TE_mean = np.median(dicount_dict_S['non_TE']\\\n",
    "                      [(dicount_dict_length['non_TE'] > cutoff)&(~np.isnan(dicount_dict_S['non_TE']))][:-1])\n",
    "for n, key in enumerate(list_of_interest):\n",
    "    r = n // col\n",
    "    c = n % col\n",
    "    ax[r,c].boxplot(dicount_dict_S[key][(dicount_dict_length[key] > cutoff)&(~np.isnan(dicount_dict_S[key]))][:-1])\n",
    "    ax[r,c].set_title(key)\n",
    "    ax[r,c].set_ylim(0,2)\n",
    "    ax[r,c].axhline(gene_mean, c='r', ls='--')\n",
    "    ax[r,c].axhline(non_TE_mean, c='g', ls='--')\n",
    "    #ax[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#maybe do the rip analysis by family instead\n",
    "#maybe consider doing reverse complements as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now pull in the control files\n",
    "GENOME_NAME_DICT = {}\n",
    "GENOME_NAME_DICT['Blumeria graminis f. sp. hordei'] = 'Blumeria_graminis_f.sp.hordei_DH14__GCA_900239735.1_BGH_DH14_v4_genomic'\n",
    "GENOME_NAME_DICT['Marssonina brunnea'] = 'Marssonina_brunnea_GCF_000298775.1_ASM29877v1_genomic'\n",
    "GENOME_NAME_DICT['Rhynchosporium commune'] = 'Rhynchosporium_commune__GCA_900074885.1_version_1_genomic'\n",
    "GENOME_NAME_DICT['Parauncinula polyspora'] = 'parauncinula_polyspora.scaffolds'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first pull in the genome files\n",
    "#then pull in the gff files and subset them\n",
    "GENOME_FN_DICT = {}\n",
    "for key, value in GENOME_NAME_DICT.items():\n",
    "    if key != 'Parauncinula polyspora':\n",
    "        GENOME_FN_DICT[key] = os.path.join(CONTROL_FOLDER, value + '.fna')\n",
    "    else:\n",
    "        GENOME_FN_DICT[key] = os.path.join(CONTROL_FOLDER, value + '.fa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GFF_FN_DICT = {}\n",
    "for key, value in GENOME_FN_DICT.items():\n",
    "    GFF_FN_DICT[key] = value + '.out.gff'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SUB_GFF_FN_DICT = {}\n",
    "selection = ['Tad1', 'Gypsy', 'Copia']\n",
    "for key, value in GFF_FN_DICT.items():\n",
    "    SUB_GFF_FN_DICT[key] = RM_subset(value, selection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Generate the non-TE GFF/bed which requires \n",
    "### the genome file as well\n",
    "selection.append('non_TE')\n",
    "for key, value in SUB_GFF_FN_DICT.items():\n",
    "    tmp_fn = reverse_bed(GENOME_FN_DICT[key], GFF_FN_DICT[key])\n",
    "    #print(value.append(tmp_fn))\n",
    "    SUB_GFF_FN_DICT[key].append(tmp_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#next steps is to generate the whole counting\n",
    "#and result dicts followed by plotting.\n",
    "SUB_GFF_FN_DICT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the fa and fac count done.\n",
    "SUB_FA_FN_DICT = {}\n",
    "SUB_FAC_FN_DICT = {}\n",
    "for key, bed_files in SUB_GFF_FN_DICT.items():\n",
    "    tmp_fa_list = []\n",
    "    tmp_fac_list = []\n",
    "    for tmp_bed_file in bed_files:\n",
    "        #get the fa files from the bedfiles\n",
    "        ending = os.path.basename(tmp_bed_file).split('.')[-1]\n",
    "        tmp_fa_out_fn = os.path.join(TMP_FOLDER, os.path.basename(tmp_bed_file)\\\n",
    "                              .replace(ending, 'fa'))\n",
    "        tmp_bed = BedTool(tmp_bed_file)\n",
    "        tmp_bed.sequence(fi=GENOME_FN_DICT[key]).save_seqs(tmp_fa_out_fn)\n",
    "        tmp_fa_list.append(tmp_fa_out_fn)\n",
    "        #now do the fac count\n",
    "        tmp_fac_out_fn = tmp_fa_out_fn.replace('.fa' , '.fac')\n",
    "        facount(tmp_fa_out_fn, tmp_fac_out_fn)\n",
    "        tmp_fac_list.append(tmp_fac_out_fn)\n",
    "    SUB_FA_FN_DICT[key] = tmp_fa_list\n",
    "    SUB_FAC_FN_DICT[key] = tmp_fac_list    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##rename things to be name compatible with the upstream part ['Tad1', 'Gypsy', 'Copia', 'non_TE']\n",
    "new_selection = ['Tad1', 'ClassI:LTR:Gypsy','ClassI:LTR:Copia', 'non_TE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SUB_S_DICT = {}\n",
    "SUB_L_DICT = {}\n",
    "SUB_length_DICT = {}\n",
    "\n",
    "for key, fac_list in SUB_FAC_FN_DICT.items():\n",
    "    #now get the different dictionaries\n",
    "    #'TpA/ApT'\n",
    "    tmp_S = {}\n",
    "    #'CpA + TpG/ApC + GpT'\n",
    "    tmp_L = {}\n",
    "    #length\n",
    "    tmp_length = {}\n",
    "    for name, tmp_fac_fn in zip(new_selection, fac_list):\n",
    "        print(name)\n",
    "        \n",
    "        tmp_df = do_RIP_call(tmp_fac_fn)\n",
    "        #selection would be the keys\n",
    "        tmp_S[name] = tmp_df['TpA/ApT'].values\n",
    "        tmp_L[name] = tmp_df['CpA + TpG/ApC + GpT'].values\n",
    "        tmp_length[name] = tmp_df['len'].values\n",
    "    SUB_S_DICT[key] = tmp_S\n",
    "    SUB_L_DICT[key] = tmp_L\n",
    "    SUB_length_DICT[key] = tmp_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('#TpA/ApT')\n",
    "for key, tmp_dict in SUB_S_DICT.items():\n",
    "    print(F'\\n\\n#####{key}####')\n",
    "    for name in new_selection[1:]:\n",
    "        tmp_x = np.median(tmp_dict[name][(SUB_length_DICT[key][name] > 500)&(~np.isnan(tmp_dict[name]))][:-1])\n",
    "        print(F'This is the median for {name}: {tmp_x}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('CpA + TpG/ApC + GpT')\n",
    "for key, tmp_dict in SUB_L_DICT.items():\n",
    "    print(F'\\n\\n#####{key}####')\n",
    "    for name in new_selection[1:]:\n",
    "        tmp_x = np.median(tmp_dict[name][(SUB_length_DICT[key][name] > 500)&(~np.isnan(tmp_dict[name]))][:-1])\n",
    "        print(F'This is the median for {name}: {tmp_x}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now the plotting\n",
    "cutoff = 500\n",
    "col = 5\n",
    "rows = 5 // col\n",
    "if 5 % col > 0:\n",
    "    rows +=1\n",
    "print(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordered_keys = [ 'Marssonina brunnea', 'Rhynchosporium commune', 'Parauncinula polyspora', 'Blumeria graminis f. sp. hordei']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('#TpA/ApT')\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context(\"poster\")\n",
    "boxprops = dict(linewidth=3, color='b')\n",
    "medianprops = dict(linestyle='-', linewidth=2.5, color='firebrick')\n",
    "whiskerprops = dict(linewidth=1.5, color='b')\n",
    "\n",
    "fig, ax = plt.subplots(rows, col, figsize = (20, 6), sharey=True)\n",
    "new_selection = ['non_TE','ClassI:LTR:Gypsy','ClassI:LTR:Copia']\n",
    "\n",
    "#do AP first\n",
    "non_TE_mean = np.median(dicount_dict_S['non_TE']\\\n",
    "                      [(dicount_dict_length['non_TE'] > cutoff)&(~np.isnan(dicount_dict_S['non_TE']))][:-1])\n",
    "tmp_data = []\n",
    "for n, key in enumerate(new_selection):\n",
    "    tmp_val = dicount_dict_S[key][(dicount_dict_length[key] > cutoff)&(~np.isnan(dicount_dict_S[key]))][:-1]\n",
    "    tmp_data.append(tmp_val)\n",
    "\n",
    "tmp_box = ax[0].boxplot(tmp_data, vert=True,  # vertical box alignment\n",
    "                         patch_artist=False,\n",
    "             widths=0.8,\n",
    "            boxprops=boxprops,\n",
    "            medianprops=medianprops,\n",
    "            whiskerprops = whiskerprops)\n",
    "ax[0].axhline(non_TE_mean, c='black', ls='--', linewidth = 4)\n",
    "ax[0].set_title('Austropuccinia psidii', pad = 20)\n",
    "ax[0].set_xticklabels(new_selection, rotation = 70)\n",
    "ax[0].set_ylim(-0.1, 4)\n",
    "#tmp_box = \n",
    "\n",
    "count = 1\n",
    "\n",
    "for key in ordered_keys:\n",
    "    tmp_non_TE_mean = np.median(SUB_S_DICT[key]['non_TE'][(SUB_length_DICT[key]['non_TE'] > cutoff)\\\n",
    "                                               &(~np.isnan(SUB_S_DICT[key]['non_TE']))][:-1])\n",
    "    tmp_data = []\n",
    "    for name in new_selection:\n",
    "        tmp_val  = SUB_S_DICT[key][name][(SUB_length_DICT[key][name] > cutoff)\\\n",
    "                                               &(~np.isnan(SUB_S_DICT[key][name]))][:-1]\n",
    "        tmp_data.append(tmp_val)\n",
    "    ax[count].boxplot(tmp_data, vert=True,  # vertical box alignment\n",
    "                         patch_artist=False,\n",
    "             widths=0.8,\n",
    "            boxprops=boxprops,\n",
    "            medianprops=medianprops,\n",
    "            whiskerprops = whiskerprops)\n",
    "    \n",
    "\n",
    "    ax[count].axhline(tmp_non_TE_mean, c='black', ls='--', linewidth = 4)\n",
    "    ax[count].set_title(key, pad= (20 + 30 * (count%2)))\n",
    "    ax[count].set_xticklabels(new_selection, rotation = 70)\n",
    "    count += 1\n",
    "out_fn = os.path.join(OUT_FOLDER_FIG, 'TpA_etal_ratio.png')\n",
    "fig.tight_layout()\n",
    "fig.savefig(out_fn, dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('CpA + TpG/ApC + GpT')\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context(\"poster\")\n",
    "boxprops = dict(linewidth=3, color='b')\n",
    "medianprops = dict(linestyle='-', linewidth=2.5, color='firebrick')\n",
    "whiskerprops = dict(linewidth=1.5, color='b')\n",
    "\n",
    "fig, ax = plt.subplots(rows, col, figsize = (20, 6), sharey=True)\n",
    "new_selection = ['non_TE','ClassI:LTR:Gypsy','ClassI:LTR:Copia']\n",
    "\n",
    "#do AP first\n",
    "non_TE_mean = np.median(dicount_dict_L['non_TE']\\\n",
    "                      [(dicount_dict_length['non_TE'] > cutoff)&(~np.isnan(dicount_dict_L['non_TE']))][:-1])\n",
    "tmp_data = []\n",
    "for n, key in enumerate(new_selection):\n",
    "    tmp_val = dicount_dict_L[key][(dicount_dict_length[key] > cutoff)&(~np.isnan(dicount_dict_L[key]))][:-1]\n",
    "    tmp_data.append(tmp_val)\n",
    "\n",
    "tmp_box = ax[0].boxplot(tmp_data, vert=True,  # vertical box alignment\n",
    "                         patch_artist=False,\n",
    "             widths=0.8,\n",
    "            boxprops=boxprops,\n",
    "            medianprops=medianprops,\n",
    "            whiskerprops = whiskerprops)\n",
    "ax[0].axhline(non_TE_mean, c='black', ls='--', linewidth = 4)\n",
    "ax[0].set_title('Austropuccinia psidii', pad = 20)\n",
    "ax[0].set_xticklabels(new_selection, rotation = 70)\n",
    "ax[0].set_ylim(-0.1, 4)\n",
    "#tmp_box = \n",
    "\n",
    "count = 1\n",
    "\n",
    "for key in ordered_keys:\n",
    "    tmp_non_TE_mean = np.median(SUB_L_DICT[key]['non_TE'][(SUB_length_DICT[key]['non_TE'] > cutoff)\\\n",
    "                                               &(~np.isnan(SUB_L_DICT[key]['non_TE']))][:-1])\n",
    "    tmp_data = []\n",
    "    for name in new_selection:\n",
    "        tmp_val  = SUB_L_DICT[key][name][(SUB_length_DICT[key][name] > cutoff)\\\n",
    "                                               &(~np.isnan(SUB_L_DICT[key][name]))][:-1]\n",
    "        tmp_data.append(tmp_val)\n",
    "    ax[count].boxplot(tmp_data, vert=True,  # vertical box alignment\n",
    "                         patch_artist=False,\n",
    "             widths=0.8,\n",
    "            boxprops=boxprops,\n",
    "            medianprops=medianprops,\n",
    "            whiskerprops = whiskerprops)\n",
    "    \n",
    "\n",
    "    ax[count].axhline(tmp_non_TE_mean, c='black', ls='--', linewidth = 4)\n",
    "    ax[count].set_title(key, pad= (20 + 30 * (count%2)))\n",
    "    ax[count].set_xticklabels(new_selection, rotation = 70)\n",
    "    count += 1\n",
    "out_fn = os.path.join(OUT_FOLDER_FIG, 'CpA_etal_ratio.png')\n",
    "fig.tight_layout()\n",
    "fig.savefig(out_fn, dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "/home/benjamin/myrtle_rust/genome_v03/scripts/notebooks\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py36]",
   "language": "python",
   "name": "conda-env-py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
